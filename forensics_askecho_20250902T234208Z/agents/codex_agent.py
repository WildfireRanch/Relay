# File: codex_agent.py
# Directory: agents
# Purpose: # Purpose: Manages interactions with the OpenAI Codex model, handling prompt creation, response parsing, and streaming data for code generation tasks.
#
# Upstream:
#   - ENV: —
#   - Imports: agents.critic_agent, core.logging, dotenv, json, openai, os, re, typing, utils.openai_client, utils.patch_utils
#
# Downstream:
#   - agents.mcp_agent
#   - routes.ask
#
# Contents:
#   - CodexAgent()
#   - _build_prompt()
#   - _parse_codex_response()
#   - handle()
#   - stream()



import os
from typing import Dict, Any, Optional, AsyncGenerator, Tuple
from openai import AsyncOpenAI, OpenAIError

from utils.openai_client import create_openai_client
from utils.patch_utils import validate_patch_format
from core.logging import log_event
from dotenv import load_dotenv
from agents.critic_agent import run_critics

load_dotenv()
client = create_openai_client()

RELAY_SYSTEM_PROMPT = """
You are Relay — a surgical, code-focused agent in a multi-agent system.

Your primary role is execution: refactoring, repairing, generating, or editing code with precision. 
You respond only with valid, well-formed code (or JSON patches), and include comments only when essential.

Behavior traits:
- Precision: Your edits are exact, minimal, and correct.
- Context-aware: You understand surrounding code, file structure, and architecture.
- Silent confidence: No chatter, no disclaimers — just clean execution.
- Cooperation: Incorporate critic feedback. Escalate with clarity if blocked.

You are not chatty. You do not explain unless asked. You do not hallucinate code. You do not guess blindly.

Always return code that’s safe to commit or review.
""".strip()


class CodexAgent:
    """
    CodexAgent:
        - Handles natural language requests for code editing
        - Returns both a user-friendly summary and a structured patch object
        - All patch actions are validated and critiqued before returning
    """

    async def handle(
        self, query: str, context: str, user_id: Optional[str] = None
    ) -> Dict[str, Any]:
        if not query or not context:
            raise ValueError("Both 'query' and 'context' must be provided.")

        prompt = self._build_prompt(query, context)

        try:
            completion = await client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": RELAY_SYSTEM_PROMPT},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3
            )
            content = completion.choices[0].message.content.strip()
        except OpenAIError as e:
            log_event("codex_agent_error", {"error": str(e), "user_id": user_id})
            raise RuntimeError("Codex agent failed to respond.") from e

        response, action = self._parse_codex_response(content)

        if not validate_patch_format(action):
            log_event("codex_patch_invalid", {"content": content, "user_id": user_id})
            raise ValueError("Invalid patch format returned from Codex.")

        pseudo_plan = {
            "objective": action.get("reason", ""),
            "steps": [f"Apply patch to {action.get('target_file', 'unknown file')}"],
            "recommendation": "Generated by CodexAgent"
        }

        try:
            critics = await run_critics(pseudo_plan, context)
            action["critics"] = critics
            log_event("codex_patch_critique", {
                "file": action.get("target_file", "unknown"),
                "user_id": user_id,
                "critics": critics
            })
        except Exception as critic_error:
            log_event("codex_critic_fail", {
                "error": str(critic_error),
                "user_id": user_id,
                "target_file": action.get("target_file", "unknown")
            })
            action["critics"] = [{"name": "system", "passes": False, "issues": ["Critic system failed"]}]

        log_event("codex_agent_success", {"action": action, "user_id": user_id})

        return {
            "response": response,
            "action": action
        }

    async def stream(
        self, query: str, context: str, user_id: Optional[str] = None
    ) -> AsyncGenerator[str, None]:
        if not query or not context:
            yield "[Error] Missing query or context."
            return

        prompt = self._build_prompt(query, context)

        try:
            openai_stream = await client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": RELAY_SYSTEM_PROMPT},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                stream=True
            )
            async for chunk in openai_stream:
                delta = getattr(chunk.choices[0].delta, "content", None)
                if delta:
                    yield delta
        except Exception as e:
            yield f"[Error] Codex stream failed: {str(e)}"

    def _build_prompt(self, query: str, context: str) -> str:
        return (
            "You will receive a code editing request from a user, along with the relevant code context.\n\n"
            f"Task: {query}\n\n"
            "Code Context:\n"
            "```python\n"
            f"{context}\n"
            "```\n"
            "Respond with a natural language summary, and a JSON object patch in this format:\n"
            '{\n'
            '  "target_file": "<file path>",\n'
            '  "start_line": <int>,\n'
            '  "end_line": <int>,\n'
            '  "replacement": "<new code>",\n'
            '  "reason": "<why this patch>"\n'
            '}\n'
        )

    def _parse_codex_response(self, content: str) -> Tuple[str, Dict[str, Any]]:
        import json, re
        json_match = re.search(r'({[\s\S]+})', content)
        if not json_match:
            raise ValueError("Codex did not return a valid patch JSON block.")

        summary = content[:json_match.start()].strip()
        action_json = content[json_match.start():json_match.end()].strip()

        try:
            action = json.loads(action_json)
        except Exception as e:
            raise ValueError(f"Codex patch JSON could not be parsed: {e}\nRaw: {action_json}")

        return summary, action


# Singleton export for app-wide import
codex_agent = CodexAgent()
handle = codex_agent.handle
stream = codex_agent.stream
