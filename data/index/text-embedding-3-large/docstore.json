{"docstore/ref_doc_info": {"e5efd9bb-a805-4b5c-a100-d1392d256f8f": {"node_ids": ["14f65c6d-c5b1-4b1f-b1e4-26258b42f6d7"], "metadata": {"tier": "global", "file_path": "/app/docs/generated/global_context.md", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "98bf680b-f373-4726-8a44-1c3164beb546": {"node_ids": ["91528f11-0ed2-49d3-b5da-1e1b630f8388"], "metadata": {"file_path": "/app/docs/imported/relay_code_update_250603.md", "file_name": "relay_code_update_250603.md", "file_size": 1982, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "70d7a252-e285-453b-a42c-c0b6c60ae7a2": {"node_ids": ["71fd5e87-f0af-47de-9eaf-e7c746755676"], "metadata": {"file_path": "/app/docs/imported/relay_code_update_250605.md", "file_name": "relay_code_update_250605.md", "file_size": 2876, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "ede8dcfa-1809-4e28-a83f-ea01166d4f5a": {"node_ids": ["df242dce-083a-4c83-bacc-66420b5f4941"], "metadata": {"file_path": "/app/docs/imported/relay_code_update_250606.md", "file_name": "relay_code_update_250606.md", "file_size": 3248, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "89382837-662b-4520-b66b-a2c9c78eccb5": {"node_ids": ["af1348d7-dafe-4b9c-b1c3-741d82c9dc1a", "a45f5cca-c770-48de-944e-21946c4e54c6"], "metadata": {"file_path": "/app/docs/imported/repository_overview_250606.md", "file_name": "repository_overview_250606.md", "file_size": 7775, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "0c5bffea-629f-41a4-98aa-62251d0a9904": {"node_ids": ["735c5632-2eef-4267-9f01-d844c9b3b5b4"], "metadata": {"file_path": "/app/docs/imported/test_placeholder.md", "file_name": "test_placeholder.md", "file_size": 0, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "61560e80-1b0c-48b7-837c-d00a6483902c": {"node_ids": ["72c154dd-bd22-44d6-8548-502f450f53b2", "3b22dafb-6cb3-414f-8e41-9b32debdb0b0", "c4f918e2-abb0-4d87-8024-3abdafb9d222"], "metadata": {"file_path": "/app/docs/imported/v1_documentation_250606.md", "file_name": "v1_documentation_250606.md", "file_size": 9879, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "a4fae8b6-ccef-469c-b9fa-81a9ada5221c": {"node_ids": ["6a3302e9-260f-47df-b87f-7b7ba002a0b7"], "metadata": {"file_path": "/app/docs/imported/\ud83d\udd27_google_docs_sync_integration.md", "file_name": "\ud83d\udd27_google_docs_sync_integration.md", "file_size": 3065, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "ce8dd2aa-4aca-4a2d-bfd4-ecd95dd6534b": {"node_ids": ["0396bf68-47e3-4645-b9ad-86d41ed947ee"], "metadata": {"tier": "project_docs", "file_path": "/app/docs/readme.md", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "1afc5ca0-4c7b-480a-9dd2-51727be5e050": {"node_ids": ["d7aee2c7-6a7a-49b1-8bad-90a31384ed21"], "metadata": {"file_path": "/app/frontend/components.json", "file_name": "components.json", "file_type": "application/json", "file_size": 428, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "7abf54dc-8e4b-4450-a843-80baa48ff48d": {"node_ids": ["0214fbe3-c1ac-4690-a528-7a5d9e10594f"], "metadata": {"file_path": "/app/frontend/next-env.d.ts", "file_name": "next-env.d.ts", "file_size": 211, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "538826c7-a4f6-4df5-ae99-73f5e50bb87c": {"node_ids": ["266592df-d32c-4574-b809-453b78331782"], "metadata": {"file_path": "/app/frontend/next.config.ts", "file_name": "next.config.ts", "file_size": 133, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "3818a848-5c42-489d-a6d2-1d25329bbf48": {"node_ids": ["2c111119-5b15-478d-98d1-90b94cb8b263"], "metadata": {"file_path": "/app/frontend/package.json", "file_name": "package.json", "file_type": "application/json", "file_size": 1627, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "30ea6c55-ffa0-44b0-a5e3-618525cc661f": {"node_ids": ["55f227b3-cf30-4a32-9876-61f7aad6c659"], "metadata": {"file_path": "/app/frontend/postcss.config.js", "file_name": "postcss.config.js", "file_type": "application/javascript", "file_size": 110, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "0d494dc8-7d07-4c44-801e-d86762f915a2": {"node_ids": ["9f8cef8f-3aa5-4a12-b248-851f2ba670a1"], "metadata": {"file_path": "/app/frontend/src/app/action-queue/page.tsx", "file_name": "page.tsx", "file_size": 286, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "56d5a150-2b90-4300-b501-9725759db856": {"node_ids": ["a21b51f9-d1f2-43f1-8b24-28ecedf723fc"], "metadata": {"file_path": "/app/frontend/src/app/api/docs/list/route.ts", "file_name": "route.ts", "file_size": 215, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "0307c0df-1e29-4696-8d03-e196b7e67638": {"node_ids": ["c19dadd7-258c-4d87-b394-681a39aebac2"], "metadata": {"file_path": "/app/frontend/src/app/api/docs/view/route.ts", "file_name": "route.ts", "file_size": 358, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "43a338b7-920a-4c9a-a700-092e1dfdd77f": {"node_ids": ["86275b3f-d56e-4714-9817-48fcde921c58"], "metadata": {"file_path": "/app/frontend/src/app/api/kb/search/route.ts", "file_name": "route.ts", "file_size": 389, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "cf0a1220-6211-45fa-924e-e5ad10012b0a": {"node_ids": ["21026d6e-054f-4bd7-8039-f58dd0ecc07d"], "metadata": {"file_path": "/app/frontend/src/app/api/status/summary/route.ts", "file_name": "route.ts", "file_size": 220, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "9c13ef1d-7370-4e01-9b40-f1c9ae69a010": {"node_ids": ["50a43997-5821-404a-8fb7-1f5d9754d2b9", "1ee72952-cc6b-4f42-935d-1c818f435999"], "metadata": {"file_path": "/app/frontend/src/app/ask/page.tsx", "file_name": "page.tsx", "file_size": 5898, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "b7b0b669-7e2e-4c36-bb02-b63d4ab74bc1": {"node_ids": ["b6f8c778-ce5f-4381-875b-56fd57d7d3c6"], "metadata": {"file_path": "/app/frontend/src/app/audit/page.tsx", "file_name": "page.tsx", "file_size": 261, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "0f0c8f2d-d9a2-4d17-971f-10b704acebfa": {"node_ids": ["169d6cd7-1764-4a73-8087-a2489c879090"], "metadata": {"file_path": "/app/frontend/src/app/codex/page.tsx", "file_name": "page.tsx", "file_size": 3861, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "084fd30d-cb52-42a1-96a1-8dfbdf044117": {"node_ids": ["9ff60f9e-9fb9-4443-96b9-ad4d016a0c75"], "metadata": {"file_path": "/app/frontend/src/app/control/page.tsx", "file_name": "page.tsx", "file_size": 893, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "79388ba0-f2e0-4d4d-9d06-c0fcfcc9693c": {"node_ids": ["a02055be-f10d-4d4a-ba5f-aaba1cdb9a4d"], "metadata": {"file_path": "/app/frontend/src/app/dashboard/page.tsx", "file_name": "page.tsx", "file_size": 173, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "72a7d590-6854-46a3-81dd-1fe3c2a66dd2": {"node_ids": ["80f9cb49-d9a3-47c4-8bc6-23531d4561de"], "metadata": {"file_path": "/app/frontend/src/app/docs/page.tsx", "file_name": "page.tsx", "file_size": 231, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "bd8404cc-a24b-4070-bfba-aaf44f3b1c25": {"node_ids": ["168ba6fe-c97e-4277-b311-ef14f3708261"], "metadata": {"file_path": "/app/frontend/src/app/layout.tsx", "file_name": "layout.tsx", "file_size": 514, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "b3b15f81-73e1-4060-89ce-b7889cdc75b8": {"node_ids": ["2b52d66a-71c7-4892-b9c1-e5d6c53acff9"], "metadata": {"file_path": "/app/frontend/src/app/logs/page.tsx", "file_name": "page.tsx", "file_size": 482, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "f8b3b48d-520d-4795-87a7-ad007a31be3d": {"node_ids": ["25d92bbf-5613-483c-ba02-fc330476fbad"], "metadata": {"file_path": "/app/frontend/src/app/metricschart/page.tsx", "file_name": "page.tsx", "file_size": 271, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "799e5c43-9902-4e43-be76-114a338d915a": {"node_ids": ["ffd9b4bc-b29e-4ac7-a5c2-4accf1a8a6d0"], "metadata": {"file_path": "/app/frontend/src/app/page.tsx", "file_name": "page.tsx", "file_size": 1969, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "0d9492d0-368b-4d83-841d-9dbf1f0ec05a": {"node_ids": ["1a01ca20-d51c-4323-8003-178197279757"], "metadata": {"file_path": "/app/frontend/src/app/settings/page.tsx", "file_name": "page.tsx", "file_size": 353, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "db5ec47e-45bc-4a07-aed9-aa600aa420e0": {"node_ids": ["97b597d8-b8c7-4da6-9750-3aae1f481788"], "metadata": {"file_path": "/app/frontend/src/app/status/page.tsx", "file_name": "page.tsx", "file_size": 284, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "ff46f666-a791-4054-b5a3-427bcc10fad8": {"node_ids": ["83b68592-9154-4fa9-8b24-ddf74037695b", "dfe8c128-0999-4355-9c64-c06cf45cb4b6", "81b6ddca-d136-40de-8fac-3957ac39b391", "3218b662-4297-472b-820a-57e402a0495b"], "metadata": {"file_path": "/app/frontend/src/components/ActionQueue/ActionQueuePanel.tsx", "file_name": "ActionQueuePanel.tsx", "file_size": 12602, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "9d161425-b64a-45c6-a03e-fc42d622814e": {"node_ids": ["5a0289f4-6019-4bf7-8327-9bb50aebfd55"], "metadata": {"file_path": "/app/frontend/src/components/AskAgent/ChatMessage.tsx", "file_name": "ChatMessage.tsx", "file_size": 894, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "3eafdc2e-75e9-49c8-8bc3-d517186c369b": {"node_ids": ["df5f57c9-ffa8-4ecc-a2af-ccad2855d00c"], "metadata": {"file_path": "/app/frontend/src/components/AskAgent/ChatWindow.tsx", "file_name": "ChatWindow.tsx", "file_size": 1683, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "d8e830eb-78b8-46ce-b5c5-fdad03186e2a": {"node_ids": ["675fef89-ecfe-45c4-98e7-fcf80449f3be"], "metadata": {"file_path": "/app/frontend/src/components/AskAgent/InputBar.tsx", "file_name": "InputBar.tsx", "file_size": 1460, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "21bb60dc-2ddc-433f-909a-df6d6cd7fe8b": {"node_ids": ["1a54d072-d80b-4e68-a9f2-0fd5a17c2185"], "metadata": {"file_path": "/app/frontend/src/components/AskAgent/hooks.ts", "file_name": "hooks.ts", "file_size": 3620, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "b96e5856-0579-45a4-bb2d-fe1a6415db66": {"node_ids": ["d833d335-b802-46b7-9b92-565823cf6e3a", "7151be5b-5504-45ba-8071-ed4658f816f4"], "metadata": {"file_path": "/app/frontend/src/components/AskAgent/useAskEcho.ts", "file_name": "useAskEcho.ts", "file_size": 5907, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "4c35eb16-b549-439c-9138-dcbe2dca99c0": {"node_ids": ["507c082f-4284-4889-84a4-6cea0ae01d1a", "92b71366-6182-4452-9371-72eff4fce54a", "83084774-e814-4af2-9f7c-82382d96fec6", "0760576a-0de7-420e-b981-724ffe2446fa", "6f388a35-5a14-4ecc-9238-0c22a65d89ab"], "metadata": {"file_path": "/app/frontend/src/components/AuditPanel/AuditPanel.tsx", "file_name": "AuditPanel.tsx", "file_size": 14146, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "3e243e36-20c9-4ecd-8b9b-cffb62d32eb6": {"node_ids": ["cd5ff8b5-cd7e-4804-82ea-16ee49dd56d1"], "metadata": {"file_path": "/app/frontend/src/components/Codex/CodexEditor.tsx", "file_name": "CodexEditor.tsx", "file_size": 842, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "a24b5ce2-14d6-49a9-8ebb-c0f3d828830e": {"node_ids": ["7c4bede4-75ae-457f-a157-3ff01b6d6282"], "metadata": {"file_path": "/app/frontend/src/components/Codex/CodexPatchView.tsx", "file_name": "CodexPatchView.tsx", "file_size": 1321, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "5c2d9799-5099-4430-9244-b3e62272fe40": {"node_ids": ["31b283cb-c9c1-48f7-ba3a-4ec0fab1020f"], "metadata": {"file_path": "/app/frontend/src/components/Codex/CodexPromptBar.tsx", "file_name": "CodexPromptBar.tsx", "file_size": 1423, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "37ac9e21-28d5-4e6c-8632-187cec50ef3b": {"node_ids": ["1a4f8f48-9a4f-4fd0-b9b9-6fea3a3780f3"], "metadata": {"file_path": "/app/frontend/src/components/Codex/index.ts", "file_name": "index.ts", "file_size": 277, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "b4c7cdf6-3d8f-421a-ad1e-e02af1abdb9b": {"node_ids": ["877860cb-6eb5-4f1a-a141-0e17af9b763f"], "metadata": {"file_path": "/app/frontend/src/components/Codex/page.tsx", "file_name": "page.tsx", "file_size": 2108, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "d44bd992-6ce4-40f7-ae55-7b28865993ab": {"node_ids": ["26c90ccc-285c-47f4-8666-51aabf6550dd", "11682fed-6d09-48b0-86e0-5a1dde7b4733"], "metadata": {"file_path": "/app/frontend/src/components/DocsSyncPanel.tsx", "file_name": "DocsSyncPanel.tsx", "file_size": 5158, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "23799d7c-22c2-480e-ae05-ff4ec90a60e5": {"node_ids": ["d1c4300f-73ed-49bd-be00-ba6a0e0a18f7", "61d504e1-9a69-4c1c-88a1-a952e3e9e59c", "1b1ef0a5-8ca0-4c55-9fad-ec209b4db9dd"], "metadata": {"file_path": "/app/frontend/src/components/DocsViewer/DocsViewer.tsx", "file_name": "DocsViewer.tsx", "file_size": 8731, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "0266c43c-8f5d-47fa-9597-4d31d98e5c50": {"node_ids": ["fed6c76e-7e0c-4e4c-8dc2-6e48f4df0e2f"], "metadata": {"file_path": "/app/frontend/src/components/GmailOps/GmailOpsPanel.tsx", "file_name": "GmailOpsPanel.tsx", "file_size": 3509, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "f9372f71-cf56-4421-b94b-ba81ef2c132c": {"node_ids": ["14ab5de3-8e58-47f3-9063-fce033c5b9da", "70f2aa1c-d8c2-45dd-9f59-f7ca7088654b", "724a395a-dc03-412b-9572-e697902c6a5c"], "metadata": {"file_path": "/app/frontend/src/components/LogsPanel/LogsPanel.tsx", "file_name": "LogsPanel.tsx", "file_size": 7092, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "1ea75db3-ccf0-490f-9fa0-7f528c129dc2": {"node_ids": ["2477c90a-7e6a-4ffc-81f9-8942ab49f8e9", "82d59c41-dafb-4aae-abd0-88f8cd260700", "cdce9102-8e6a-4cfc-aa04-258a04a71219", "4e6a7fcb-5ccd-4ef6-83b6-ce73a987e15a", "77f18924-adc5-47c4-bc6b-2a5ec6aeffde"], "metadata": {"file_path": "/app/frontend/src/components/MemoryPanel.tsx", "file_name": "MemoryPanel.tsx", "file_size": 13812, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "5643dab0-45f8-4c41-b78a-fca414a354c6": {"node_ids": ["f8b64aea-132c-40b4-b925-d7753a67d6c2"], "metadata": {"file_path": "/app/frontend/src/components/MetricsCharts/MetricsCharts.tsx", "file_name": "MetricsCharts.tsx", "file_size": 902, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "98fdd749-5a87-4246-9e2d-b9c2f7997d58": {"node_ids": ["89e003f8-e791-4464-9ffa-6eacebdb5f94"], "metadata": {"file_path": "/app/frontend/src/components/SafeMarkdown.tsx", "file_name": "SafeMarkdown.tsx", "file_size": 3365, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "ac2489c1-6d3a-4391-90f3-5db4c484f169": {"node_ids": ["11b7e9a9-11fd-4f96-acf4-4939c974ac2f", "a1a25284-7106-470a-949c-50839f94ab3c"], "metadata": {"file_path": "/app/frontend/src/components/SearchPanel.tsx", "file_name": "SearchPanel.tsx", "file_size": 4672, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "26c218d2-3074-4e2a-9772-4bd6ae4dc5fb": {"node_ids": ["124435f4-5701-402d-862a-47a47217a8ac"], "metadata": {"file_path": "/app/frontend/src/components/Sidebar/Sidebar.tsx", "file_name": "Sidebar.tsx", "file_size": 1646, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "d7df79dc-de66-4319-8914-e9b72e5df240": {"node_ids": ["0b4412da-676c-476f-94af-df70d44f29de", "e2044897-6135-4bfa-b4fe-ea03cd6c9922"], "metadata": {"file_path": "/app/frontend/src/components/StatusPanel.tsx", "file_name": "StatusPanel.tsx", "file_size": 4399, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "433ab2a3-5ecf-409e-ac00-682d56a21a64": {"node_ids": ["d72cc094-ebab-44f8-81db-92b574bd3244"], "metadata": {"file_path": "/app/frontend/src/components/dashboard/Dashboard.stories.tsx", "file_name": "Dashboard.stories.tsx", "file_size": 152, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "bfcafffd-c14c-49e3-bc43-7fd2a57124b3": {"node_ids": ["49d0e78b-8af4-4c08-b32e-2c5e2a51572b"], "metadata": {"file_path": "/app/frontend/src/components/dashboard/Dashboard.tsx", "file_name": "Dashboard.tsx", "file_size": 3449, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "66032114-aa83-410c-a4ea-b13cd1ac8f08": {"node_ids": ["ebaa16d1-8c31-457e-90b6-e912c8414fde"], "metadata": {"file_path": "/app/frontend/src/components/index.ts", "file_name": "index.ts", "file_size": 717, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "1b5114c6-13e2-4479-946d-d8e868c8fc43": {"node_ids": ["4e253827-2c05-4c0b-91ce-82f9db3e36d6"], "metadata": {"file_path": "/app/frontend/src/components/ui/AskAgent/AskAgent.tsx", "file_name": "AskAgent.tsx", "file_size": 1644, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "591b4637-9116-4e8b-83c3-154868eee270": {"node_ids": ["cfc672c9-0db9-4c2b-ae02-3b017d00f511"], "metadata": {"file_path": "/app/frontend/src/components/ui/badge.tsx", "file_name": "badge.tsx", "file_size": 882, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "8c1db525-1b5d-4ce2-90ff-e70cfe87c4a1": {"node_ids": ["a5bc80a9-1439-4160-876c-624bb21367a3"], "metadata": {"file_path": "/app/frontend/src/components/ui/button.tsx", "file_name": "button.tsx", "file_size": 2123, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "4fa9bee7-0cf6-4ec6-a89d-eb255aaeb26e": {"node_ids": ["307a6ef7-2e63-41f0-9662-7ac9e0289bcb"], "metadata": {"file_path": "/app/frontend/src/components/ui/card.tsx", "file_name": "card.tsx", "file_size": 1989, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "00ff82b5-d559-4ef4-8119-3deb2f8f9feb": {"node_ids": ["d0348d51-019a-4f99-a9c8-5f4c1698aef5"], "metadata": {"file_path": "/app/frontend/src/components/ui/input.tsx", "file_name": "input.tsx", "file_size": 967, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "412d6596-d33d-4645-9608-c6dea466fa43": {"node_ids": ["696a9378-9277-4319-8067-5185c013aced"], "metadata": {"file_path": "/app/frontend/src/components/ui/label.tsx", "file_name": "label.tsx", "file_size": 611, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "1aba31d0-7e4c-4c00-92dd-8e52e83b03ba": {"node_ids": ["60bc89f8-d107-4216-99f7-5a3ed3c69400"], "metadata": {"file_path": "/app/frontend/src/components/ui/progress.tsx", "file_name": "progress.tsx", "file_size": 698, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "6b01b50d-f743-464f-8591-ff57ce92874b": {"node_ids": ["2bb0b62f-efc2-42fa-835f-c4f9bd4e307e"], "metadata": {"file_path": "/app/frontend/src/components/ui/textarea.tsx", "file_name": "textarea.tsx", "file_size": 759, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "a79f9fad-846d-42a7-a1ed-841576ea7cc7": {"node_ids": ["583e20fa-797d-4063-9035-2ff6c215a5cb"], "metadata": {"file_path": "/app/frontend/src/lib/api.ts", "file_name": "api.ts", "file_size": 278, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "e3d56383-8ec4-4f60-a1d6-55af0efb02da": {"node_ids": ["f2029156-4a07-4dba-b7fa-2ac17095c6f7"], "metadata": {"file_path": "/app/frontend/src/lib/toMDString.ts", "file_name": "toMDString.ts", "file_size": 422, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "51ed9f1a-5cb1-4abe-8a10-6b80c989e0be": {"node_ids": ["2ae03bcc-cfe6-41bc-9cad-1321dce29faf"], "metadata": {"file_path": "/app/frontend/src/lib/utils.ts", "file_name": "utils.ts", "file_size": 196, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "c3e48bdd-d448-4c6b-8eb0-9318f858698a": {"node_ids": ["81a8ad59-0214-493c-a562-d21ec84f393c"], "metadata": {"file_path": "/app/frontend/src/types/react-syntax-highlighter.d.ts", "file_name": "react-syntax-highlighter.d.ts", "file_size": 173, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "4702d470-b5e3-423d-98b4-b8ce9496c83e": {"node_ids": ["f4f632a4-96cd-4add-a588-5af2bdd9f062", "352c48a0-8fda-44d2-8de7-781cea9bc56f"], "metadata": {"file_path": "/app/frontend/sync/sync_google_docs.py", "file_name": "sync_google_docs.py", "file_type": "text/x-python", "file_size": 4982, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "23bfc72b-9aa6-429c-a479-4f297d928fdc": {"node_ids": ["8378ca07-03b3-4bd5-85d2-2c017fc57bd8"], "metadata": {"file_path": "/app/frontend/tailwind.config.js", "file_name": "tailwind.config.js", "file_type": "application/javascript", "file_size": 907, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "66cc2062-33de-4764-b8c6-e57609ddd7be": {"node_ids": ["a7a8c658-3b25-45ac-908b-4a4d99608463"], "metadata": {"file_path": "/app/frontend/types/next-auth.d.ts", "file_name": "next-auth.d.ts", "file_size": 655, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "01473aef-6ebb-4465-8de0-bbdef5c0964f": {"node_ids": ["effa620f-ffcb-41e7-9c3c-fd3b4001d9d1"], "metadata": {"file_path": "/app/frontend/vitest.config.ts", "file_name": "vitest.config.ts", "file_size": 1230, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "7c7fe7f9-a8a9-4aae-9e35-58d2e32568e0": {"node_ids": ["ba2dd8af-7a91-4c38-a6d2-d4f3d5ab4090"], "metadata": {"file_path": "/app/frontend/vitest.shims.d.ts", "file_name": "vitest.shims.d.ts", "file_size": 62, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "2a2604b2-0de1-4e80-b035-0bfbba879412": {"node_ids": ["dab8d5be-21c9-4a78-b599-01e15649ab96"], "metadata": {"file_path": "/app/services/_init_.py", "file_name": "_init_.py", "file_type": "text/x-python", "file_size": 98, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "ce8f1b4e-6cc0-4865-9ae3-88b8482ddb4e": {"node_ids": ["b285176c-bfd4-4d9f-a14e-92f8b102764e", "1e58e16c-0829-4ef3-812a-b296fff5d56b", "1290e127-c2c0-480b-9a25-9ec9598b3cf0"], "metadata": {"file_path": "/app/services/agent.py", "file_name": "agent.py", "file_type": "text/x-python", "file_size": 9196, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "db1c1dd4-e446-4a36-bbeb-6f062184d226": {"node_ids": ["ba9efcf4-99fd-4857-ac01-9535326e112b"], "metadata": {"file_path": "/app/services/config.py", "file_name": "config.py", "file_type": "text/x-python", "file_size": 541, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "1935e98d-a918-4965-aa8c-42100ea35d84": {"node_ids": ["576cae6c-ea8a-438a-97b1-48378a4fa730"], "metadata": {"file_path": "/app/services/context_engine.py", "file_name": "context_engine.py", "file_type": "text/x-python", "file_size": 864, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "a117da46-3a36-43ae-ba92-2cd106769ebb": {"node_ids": ["e255bed3-abfc-491a-8360-7f037dcd93b0", "d7c1ed8d-42ac-466a-88b5-b53ffdf3a1ad"], "metadata": {"file_path": "/app/services/context_injector.py", "file_name": "context_injector.py", "file_type": "text/x-python", "file_size": 6823, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "4abdbf37-7742-4096-afdb-0dac6aef33d3": {"node_ids": ["c48f4f8a-f3fb-469b-8256-4c6c789f28ef"], "metadata": {"file_path": "/app/services/delete_embeddings.py", "file_name": "delete_embeddings.py", "file_type": "text/x-python", "file_size": 2361, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "0ef2a7dd-3795-467d-b5d3-6d04b8b239c9": {"node_ids": ["63157a55-9fe6-4b76-bfdb-dad8893079e3"], "metadata": {"file_path": "/app/services/docs_utils.py", "file_name": "docs_utils.py", "file_type": "text/x-python", "file_size": 4321, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "a08d3dd5-68ad-4891-b394-d319d909c70c": {"node_ids": ["e89b2379-ba7b-41f8-9105-6b7b0c46745b"], "metadata": {"file_path": "/app/services/env_checker.py", "file_name": "env_checker.py", "file_type": "text/x-python", "file_size": 1231, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "56e75de5-4d2b-4e1b-a4ab-978a1ae93d10": {"node_ids": ["6a788492-a0a2-4470-8ef2-44554310a889"], "metadata": {"file_path": "/app/services/gmail.py", "file_name": "gmail.py", "file_type": "text/x-python", "file_size": 2867, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "2e8a5bb5-6e7a-45e5-9e14-0972f9d30772": {"node_ids": ["3b2a14f9-d284-42da-ab8d-a7acc0f767dc"], "metadata": {"file_path": "/app/services/google.py", "file_name": "google.py", "file_type": "text/x-python", "file_size": 1139, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "959b81b8-ef4f-4389-89e3-027ea2780c94": {"node_ids": ["f7764192-f68e-4f6b-9f32-1be6e7fc23b1", "fc8b4473-afdc-4c68-b503-e5d5fd355710"], "metadata": {"file_path": "/app/services/google_docs_sync.py", "file_name": "google_docs_sync.py", "file_type": "text/x-python", "file_size": 6032, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "c5b1e32c-db86-4e4b-9bee-8e859bb390ae": {"node_ids": ["377808f0-1771-452a-a38a-24ec23b99988"], "metadata": {"file_path": "/app/services/graph.py", "file_name": "graph.py", "file_type": "text/x-python", "file_size": 3089, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "9f263501-0017-4b4f-8785-7a61dddd3e72": {"node_ids": ["332d7869-5785-40ec-ad68-1d40d369be26", "5fe08f27-8fcc-4d85-ba32-a009510eb810"], "metadata": {"file_path": "/app/services/indexer.py", "file_name": "indexer.py", "file_type": "text/x-python", "file_size": 6973, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "d7bf643d-235d-4a2f-a75b-e873a491dbf7": {"node_ids": ["9dc94475-a6bd-427d-98ae-6f8b8e488e01", "131049c8-831a-4900-a463-2b9ea6c7cce4", "bc971bf8-7112-406c-884d-149e509337b0", "f9f4c5a0-8a79-404f-b02d-7fdb43490628", "7749f07e-fa8a-4393-9208-7e2017335135"], "metadata": {"file_path": "/app/services/kb.py", "file_name": "kb.py", "file_type": "text/x-python", "file_size": 14796, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "7c8d4488-eb87-4860-b29b-b5b89fb20648": {"node_ids": ["b24154f2-2a02-49cc-bb2f-30d43e44d0b6"], "metadata": {"file_path": "/app/services/logger.py", "file_name": "logger.py", "file_type": "text/x-python", "file_size": 546, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "602f5530-509c-4fcc-aa3f-c88265be5e34": {"node_ids": ["af68c9d7-b876-4933-94a2-e2f06269304b"], "metadata": {"file_path": "/app/services/logs.py", "file_name": "logs.py", "file_type": "text/x-python", "file_size": 1687, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "b2d6d84a-5f71-4edf-adfa-9ad02b15c391": {"node_ids": ["dc66ab2b-ab0f-496c-9942-aa4e8bde009c"], "metadata": {"file_path": "/app/services/memory.py", "file_name": "memory.py", "file_type": "text/x-python", "file_size": 2117, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "ab8a1d89-290c-442d-bcec-6f85597bcb05": {"node_ids": ["f18d7aa4-7b03-4185-9271-50379c7a331a"], "metadata": {"file_path": "/app/services/mqtt_client.py", "file_name": "mqtt_client.py", "file_type": "text/x-python", "file_size": 0, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "e42008b8-f2d0-4f7f-9bef-2726ab6e8774": {"node_ids": ["8e83629c-5b77-4256-88fc-51b973dd64ca"], "metadata": {"file_path": "/app/services/neo4j_driver.py", "file_name": "neo4j_driver.py", "file_type": "text/x-python", "file_size": 2143, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "a7ed14a0-2fd9-4cfe-b0eb-ef3d8459d285": {"node_ids": ["b332a5ed-e458-4928-890e-0cbd2164efc3"], "metadata": {"file_path": "/app/services/queue.py", "file_name": "queue.py", "file_type": "text/x-python", "file_size": 169, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "caa94eed-711c-481b-8ef0-1ca1636f6ff5": {"node_ids": ["63cd2d92-dfe7-4b81-9d8f-2a88c4636228"], "metadata": {"file_path": "/app/services/semantic_retriever.py", "file_name": "semantic_retriever.py", "file_type": "text/x-python", "file_size": 1407, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "dc5e4917-dfc6-464f-bd61-4f49fd1aef98": {"node_ids": ["bb0cc5e0-a490-4853-ac65-4cf35b4810d6"], "metadata": {"file_path": "/app/services/settings.py", "file_name": "settings.py", "file_type": "text/x-python", "file_size": 793, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "956a5115-cce5-4de4-9c62-aa6fa3b399d3": {"node_ids": ["ba274e0a-cb33-4acc-b71f-7243301cdf10"], "metadata": {"file_path": "/app/services/summarize_memory.py", "file_name": "summarize_memory.py", "file_type": "text/x-python", "file_size": 818, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "8f62a157-0cf3-4f1f-89a8-79e7c9baab88": {"node_ids": ["8494e05b-2944-486a-8016-3493332c19db"], "metadata": {"file_path": "/app/routes/__init__.py", "file_name": "__init__.py", "file_type": "text/x-python", "file_size": 0, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "10507fa1-9b3e-423c-a097-6704ad6dbf00": {"node_ids": ["64b45a3c-7c71-4332-8eaf-8001094f7c2e", "f2f9f571-7f9f-4630-b433-e64566a577e4"], "metadata": {"file_path": "/app/routes/admin.py", "file_name": "admin.py", "file_type": "text/x-python", "file_size": 7292, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "51d3239f-b8a4-47d4-bf6a-60311009920a": {"node_ids": ["3d949099-99e4-40d5-9993-b40571a91910"], "metadata": {"file_path": "/app/routes/admin_routes.py", "file_name": "admin_routes.py", "file_type": "text/x-python", "file_size": 750, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "95eae29a-cc96-4b4c-8e6e-30b4c6a4ab5d": {"node_ids": ["792dbdcd-b20b-463b-9d84-f672bf7de6b0", "af50a720-637e-4f2a-af24-086c1d19e15b"], "metadata": {"file_path": "/app/routes/ask.py", "file_name": "ask.py", "file_type": "text/x-python", "file_size": 7881, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "7b1ec6a5-a75b-47ec-9e66-f73a87b0083e": {"node_ids": ["1fe50337-9315-46f0-a46a-3f31e2d56b28"], "metadata": {"file_path": "/app/routes/codex.py", "file_name": "codex.py", "file_type": "text/x-python", "file_size": 1956, "creation_date": "2025-06-28", "last_modified_date": "2025-06-28", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "c93701a2-a156-450e-a8d1-92e39416a595": {"node_ids": ["93765477-4e06-4799-af5e-f6de66fe639a"], "metadata": {"file_path": "/app/routes/context.py", "file_name": "context.py", "file_type": "text/x-python", "file_size": 4064, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "09ec149a-3e21-409a-8651-57a52d3530ee": {"node_ids": ["4e860305-eff2-4fa6-a0f4-a44c64d4eb2d", "b7f36b73-9f56-40ea-8f6d-f324d8d19565", "0e26de10-885c-4310-8460-3a23312ec452"], "metadata": {"file_path": "/app/routes/control.py", "file_name": "control.py", "file_type": "text/x-python", "file_size": 7803, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "60b5ba83-0e9a-4e8d-8502-53cdc5db4df4": {"node_ids": ["042a2091-7b01-404a-bb08-dbc24b7c8dbe"], "metadata": {"file_path": "/app/routes/debug.py", "file_name": "debug.py", "file_type": "text/x-python", "file_size": 342, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "b0cbb453-9d7f-48aa-a87c-3b71bb8db6b8": {"node_ids": ["ce3f04da-e475-4100-9ea5-63513b6c945a", "e6c6648a-fd25-492a-9231-27fd07ee7467"], "metadata": {"file_path": "/app/routes/docs.py", "file_name": "docs.py", "file_type": "text/x-python", "file_size": 8487, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "a9af4860-3709-4426-98e6-a13c1e1d66cd": {"node_ids": ["e3756285-316d-4169-af73-7cf91b109b87"], "metadata": {"file_path": "/app/routes/embeddings.py", "file_name": "embeddings.py", "file_type": "text/x-python", "file_size": 1611, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "61259ec3-cd95-4e4d-b215-b73e25366f15": {"node_ids": ["24b9cb94-0312-42a8-99c1-116027148a56"], "metadata": {"file_path": "/app/routes/index.py", "file_name": "index.py", "file_type": "text/x-python", "file_size": 1283, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "bfd9ac9a-cc40-43ea-a592-12dcac061a38": {"node_ids": ["83fc7e65-a33b-4a96-8a97-24433ce0cd12"], "metadata": {"file_path": "/app/routes/kb.py", "file_name": "kb.py", "file_type": "text/x-python", "file_size": 3005, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "888173d7-1fb9-404d-9f59-bea71addb73a": {"node_ids": ["fa4799e7-d420-4148-afaf-ef6211988516"], "metadata": {"file_path": "/app/routes/logs_sessions.py", "file_name": "logs_sessions.py", "file_type": "text/x-python", "file_size": 774, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "3d3248c5-f501-4acb-8c53-1f291fb9328c": {"node_ids": ["facb9b5c-ee05-4853-b307-0d111ec63245"], "metadata": {"file_path": "/app/routes/mcp.py", "file_name": "mcp.py", "file_type": "text/x-python", "file_size": 2007, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "a4024c57-c722-4f9b-8eda-17ce04be1d15": {"node_ids": ["0300e3bc-6d7e-406e-a6bd-fb265f1f521f", "4315ed6f-6d93-4f56-bfd0-432b1ed6e8ca"], "metadata": {"file_path": "/app/routes/oauth.py", "file_name": "oauth.py", "file_type": "text/x-python", "file_size": 4788, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "f72281f2-9b23-49b2-b048-17227125f7e0": {"node_ids": ["13f0c1d0-d581-48eb-85b5-04c291fad720"], "metadata": {"file_path": "/app/routes/search.py", "file_name": "search.py", "file_type": "text/x-python", "file_size": 2750, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "0bb7f586-e48e-49ba-a87e-f970df9d294f": {"node_ids": ["b240fd01-4306-48b1-bf59-0a7139afdea9"], "metadata": {"file_path": "/app/routes/status.py", "file_name": "status.py", "file_type": "text/x-python", "file_size": 3986, "creation_date": "2025-06-29", "last_modified_date": "2025-06-29", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "a6af3722-6c3b-441d-ac6c-75944529afe7": {"node_ids": ["d4b8ec1d-afcc-4a0f-b3cb-a663c9ba07f3"], "metadata": {"file_path": "/app/routes/status_code.py", "file_name": "status_code.py", "file_type": "text/x-python", "file_size": 1548, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}, "d885c313-e146-4f85-b967-2c7c5d088fef": {"node_ids": ["0f7496f4-e9cf-46d1-8666-84664a886a79"], "metadata": {"file_path": "/app/routes/webhook.py", "file_name": "webhook.py", "file_type": "text/x-python", "file_size": 0, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}}}, "docstore/data": {"14f65c6d-c5b1-4b1f-b1e4-26258b42f6d7": {"__data__": {"id_": "14f65c6d-c5b1-4b1f-b1e4-26258b42f6d7", "embedding": null, "metadata": {"tier": "global", "file_path": "/app/docs/generated/global_context.md", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e5efd9bb-a805-4b5c-a100-d1392d256f8f", "node_type": "4", "metadata": {"tier": "global", "file_path": "/app/docs/generated/global_context.md", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "4b5364b0127588065a2cde56ae59ded233d65119b49c81db57aa4f017aa31a78", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# Global Project Context\n\nRelay uses this file as a sample manual context. Replace this text with your own project notes.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 121, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "91528f11-0ed2-49d3-b5da-1e1b630f8388": {"__data__": {"id_": "91528f11-0ed2-49d3-b5da-1e1b630f8388", "embedding": null, "metadata": {"file_path": "/app/docs/imported/relay_code_update_250603.md", "file_name": "relay_code_update_250603.md", "file_size": 1982, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "98bf680b-f373-4726-8a44-1c3164beb546", "node_type": "4", "metadata": {"file_path": "/app/docs/imported/relay_code_update_250603.md", "file_name": "relay_code_update_250603.md", "file_size": 1982, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "542886d4bf3835d0013213143af840e57f952e29e5f282e2b08f23aeb4781b61", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\u2705 Relay Project Summary \u2013 Status as of Commit\n\ud83d\ude80 Frontend (Next.js + React)\npage.tsx\nServes as the homepage\u000b\nIncludes:\u000b\nAskAgent \u2013 GPT-powered interaction module\u000b\nSearchPanel \u2013 semantic search into synced docs\u000b\nLink to /docs route with DocsViewer\u000b\nSearchPanel.tsx\nPOSTs to /api/kb/search\u000b\nDisplays top-k semantic matches with:\u000b\ntitle\u000b\nsnippet\u000b\nsimilarity score\u000b\nDocsViewer.tsx\nFetches file list from /api/docs/list\u000b\nLoads content from /api/docs/view?path=...\u000b\nClean 2-panel layout for viewing Markdown files\u000b\nScrollable, responsive, and client-friendly\u000b\n\ud83e\udde0 Backend (FastAPI + LangChain)\nCore Routes\n/kb/search\nAccepts { query: string, k: int }\u000b\nReturns top-k cosine similarity matches from kb.sqlite3\u000b\n/docs/list, /docs/view\nLists and returns content of .md or .txt files in /docs\u000b\n/docs/sync\\_google\nTriggers sync from Google Drive \u2192 Markdown files under /docs/imported\u000b\n/check/env\\_keys\nScans services/ for os.getenv(...) calls\u000b\nVerifies existence in .env\u000b\nFlags missing, unused, or stale keys\u000b\n\ud83d\udcc1 Backend Modules\nservices/kb.py\nEmbeds .md docs using OpenAIEmbeddings\u000b\nStores chunks + vectors + metadata in SQLite\u000b\nUses cosine similarity to power semantic search\u000b\nStores title, last\\_updated, and embedding for each chunk\u000b\nservices/settings.py\nCentralized config loader\u000b\nCalls load\\_dotenv() at startup\u000b\nProvides assert\\_env(...) for safe env enforcement\u000b\nservices/google\\_docs\\_sync.py\nAuths with Google via OAuth\u000b\nLocates your Command\\_Center folder\u000b\nPulls .gdoc content \u2192 Markdown\u000b\nSaves to docs/imported/\\*.md\u000b\nRebuilt from scratch after Codespace reset\u000b\n\ud83e\udde0 AI Readiness\nLangChain + OpenAI fully integrated\u000b\ntext-embedding-3-small model powering embeddings\u000b\nGPT-4o agent available via /ask route\u000b\nModular structure ready for more agents or chain workflows\u000b\n\ud83e\udde9 Final Touches Before Commit\nAll code saved and updated\u000b\nFixed missing file (google\\_docs\\_sync.py)\u000b\nFully documented .env structure and validation\u000b\nReact panels: Search + DocsViewer operational", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1954, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "71fd5e87-f0af-47de-9eaf-e7c746755676": {"__data__": {"id_": "71fd5e87-f0af-47de-9eaf-e7c746755676", "embedding": null, "metadata": {"file_path": "/app/docs/imported/relay_code_update_250605.md", "file_name": "relay_code_update_250605.md", "file_size": 2876, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "70d7a252-e285-453b-a42c-c0b6c60ae7a2", "node_type": "4", "metadata": {"file_path": "/app/docs/imported/relay_code_update_250605.md", "file_name": "relay_code_update_250605.md", "file_size": 2876, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "687220e3450cc466f085d98a22c285d1160aa973d202b09a9bea1ed35768b2c4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\u2705 Relay Project Summary \u2013 Updated (As of Today)\n\ud83d\ude80 Frontend (Next.js + React)\npage.tsx\n\u2705 GET /api/docs/list \u2192 returns `{ \"files\": [...] }`\n\ud83d\udd01 /docs/sync\\_google is deprecated \u2014 replaced by `/docs/sync` (returns `{ \"synced_docs\": [...] }`)\nAskAgent.tsx\n\u2705 Sends GET requests to /ask (CORS-safe, no preflight)\u000b\n\u2705 Displays GPT-4o output with loading state\u000b\n\u2705 Stripped headers to eliminate CORS preflight errors\u000b\n\u2705 Uses process.env.NEXT\\_PUBLIC\\_RELAY\\_KEY for dev logs only\u000b\nSearchPanel.tsx\n\u2705 POST /api/kb/search\u000b\n\u2705 Displays top-k semantic matches from FastAPI:\u000b\nTitle\u000b\nSnippet\u000b\nSimilarity score\u000b\n\u2705 Type-safe with KBResult\u000b\n\u2705 Includes enter key trigger and loading spinner\u000b\nDocsViewer.tsx\n\u2705 GET /api/docs/list\u000b\n\u2705 GET /api/docs/view?path=...\u000b\n\u2705 Two-panel native layout (left = file list, right = scrollable viewer)\u000b\n\u2705 Pulls from /docs/imported/ and /docs/generated/\u000b\n\ud83e\udde0 Backend (FastAPI + LangChain)\nCore Routes\n\ud83d\udd01 /docs/sync\\_google is deprecated \u2014 replaced by /docs/sync with better logging\n\ud83d\udcc1 Backend Modules\nservices/kb.py\n\u2705 Embeds docs using text-embedding-3-small\u000b\n\u2705 SQLite stores: path, chunks, cosine sim metadata\u000b\n\u2705 KB result scoring used in /api/kb/search\u000b\nservices/settings.py\n\u2705 .env loaded early via load\\_dotenv()\u000b\n\u2705 assert\\_env() enforces critical keys (OPENAI\\_API\\_KEY, etc.)\u000b\nservices/google\\_docs\\_sync.py\n\u2705 Uses run\\_console() for CLI OAuth\u000b\n\u2705 Pulls .gdoc from Command\\_Center/\u000b\n\u2705 Converts to Markdown, saved to /docs/imported/\\*.md\u000b\n\u26a0\ufe0f Requires token.json (manual upload to Railway)\u000b\nservices/agent.py\n\u2705 Handles GPT query routing, context building\u000b\n\u2705 read\\_source\\_files() now honors RELAY\\_PROJECT\\_ROOT \u2705\u000b\n\u2705 Logs missing folders, loads code/doc context dynamically\u000b\n\u2705 Queues patch suggestions via /control/queue\\_action\u000b\n\u2705 GPT answers: human-like, citation-aware, can trigger actions\u000b\n\ud83e\udde0 AI Integration\n\u2705 GPT-4o for natural language responses, summaries, patch generation\u000b\n\u2705 LangChain + OpenAI embeddings for search\u000b\n\u2705 .env includes:\u000b\nOPENAI\\_API\\_KEY\u000b\nAPI\\_KEY\u000b\nRELAY\\_PROJECT\\_ROOT=/app \u2705\u000b\n\ud83e\udde9 Project Infrastructure & Reliability\n\u2705 FastAPI runs on port 8080\u000b\n\u2705 CORS fully configured (wildfire + localhost + vercel) \u2705\u000b\n\u2705 /ask OPTIONS issue solved (wildcard + no custom headers) \u2705\u000b\n\u2705 All doc folders created at boot (/docs/imported, /docs/generated)\u000b\n\u2705 Canvas patch system live (tracked in Vercel + Railway)\u000b\n\u2705 .env.example documents required keys\u000b\n\u2705 API keys now redacted in logs\u000b\n\ud83d\udd27 Remaining TODOs\nAdd same env-root logic to read\\_docs() function\u000b\nReinstate X-API-Key support securely (via Vercel backend proxy or signed tokens)\u000b\nEnable patch approval UI in control panel\u000b\nOptionally add /status/version route for deploy traceability\u000b\nLet me know if you\u2019d like this saved to /docs/generated/relay\\_status.md or queued to /control/queue\\_action.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2756, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "df242dce-083a-4c83-bacc-66420b5f4941": {"__data__": {"id_": "df242dce-083a-4c83-bacc-66420b5f4941", "embedding": null, "metadata": {"file_path": "/app/docs/imported/relay_code_update_250606.md", "file_name": "relay_code_update_250606.md", "file_size": 3248, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ede8dcfa-1809-4e28-a83f-ea01166d4f5a", "node_type": "4", "metadata": {"file_path": "/app/docs/imported/relay_code_update_250606.md", "file_name": "relay_code_update_250606.md", "file_size": 3248, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "0672faefef0d1929fe56a694cd91027e2034bc36dfed0c8b77a9c2f10ebc2005", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Relay Command Center \u2013 Version 1\nOverview\nRelay Command Center is a modular, full-stack AI-enabled backend and frontend platform designed to control, synchronize, and observe your solar-powered infrastructure, miner operations, and external documents via GPT-based interactions and automation.\nThis document summarizes Version 1 (V1) of the system, covering all features implemented across the project folder, including backend API, frontend controls, OAuth integration, and document synchronization logic.\n\u2705 Backend (FastAPI)\nCore API Endpoints\nGET / \u2013 Health check endpoint\nPOST /ask \u2013 GPT-4-powered agent Q&A endpoint (Relay Agent)\nPOST /control/queue\\_action \u2013 Allows the agent to propose and queue actions\nGET /status/summary \u2013 Provides system health/status insights\nPOST /docs/sync\\_google \u2013 Syncs Google Docs from COMMAND\\_CENTER folder and converts them to Markdown\nGET /docs/list \u2013 Lists all imported Markdown files\nGET /docs/view?path=... \u2013 Returns contents of a specific document\nGET /debug/env \u2013 Diagnostic endpoint to verify environment variable loading (like GOOGLE\\_CREDS\\_JSON)\nOAuth Flow\nGET /google/auth \u2013 Launches Google OAuth using credentials in GOOGLE\\_CREDS\\_JSON\nGET /google/callback \u2013 Finalizes OAuth and writes token.json to frontend/sync/token.json\nInfrastructure\nAuto-creates required folders (docs/imported, docs/generated)\nModular routing structure with ask, status, control, docs, oauth, debug\nCORS-enabled for frontend origins:\nhttps://relay.wildfireranch.us\nhttps://status.wildfireranch.us\nhttp://localhost:3000\n\u2705 Google Docs Sync\nEnvironment Variables\nGOOGLE\\_CREDS\\_JSON \u2013 base64-encoded client\\_secret.json\nGOOGLE\\_TOKEN\\_JSON \u2013 base64-encoded token.json after successful auth (optional, used for persistent access)\nSync Logic\nUses google-auth, googleapiclient, and markdownify\nPulls files from folder: COMMAND\\_CENTER in Google Drive\nConverts content to Markdown\nSaves as .md files in docs/imported\nToken-based auth is triggered automatically unless token.json is missing or invalid (then triggers browser flow)\n\u2705 Frontend (Next.js + React)\nDocs Viewer UI\nDisplays document list and contents\nTwo-panel layout: sidebar (doc list) and content viewer\nScrollable and responsive\nSync Button\n\ud83d\udd04 Sync Google Docs button in the UI\nTriggers POST to /docs/sync\\_google\nRefreshes doc list after completion\nHandles sync status and error feedback inline\n\ud83e\udde0 Intelligence\nGPT-backed agent available via /ask\nSupports knowledge base lookups across synced Markdown docs\nPreloaded with GOOGLE\\_CREDS\\_JSON and OPENAI\\_API\\_KEY\nSmart routing, debug logging, and error feedback\n\ud83e\uddea Developer Support\n.env-ready variable structure (with base64-encoded credentials)\n.env.local used for frontend local overrides (e.g. NEXT\\_PUBLIC\\_RELAY\\_KEY)\nSupports local testing and live Railway/Vercel deployment\n\ud83d\ude80 Deployment Targets\nBackend (FastAPI): Railway \u2013 https://relay.wildfireranch.us\nFrontend (Next.js): Vercel \u2013 https://status.wildfireranch.us\n\ud83c\udfc1 Version 1 Milestone Complete\nNext steps (future versions): frontend action queue, miner controls, agent decision visualizer, and token bootstrap tool.\nVersion: Relay Command Center V1\u000bDate: 2025-06-06\u000bLead: Bret Westwood\u000bBuilt with Echo \ud83d\udcac", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3194, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "af1348d7-dafe-4b9c-b1c3-741d82c9dc1a": {"__data__": {"id_": "af1348d7-dafe-4b9c-b1c3-741d82c9dc1a", "embedding": null, "metadata": {"file_path": "/app/docs/imported/repository_overview_250606.md", "file_name": "repository_overview_250606.md", "file_size": 7775, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "89382837-662b-4520-b66b-a2c9c78eccb5", "node_type": "4", "metadata": {"file_path": "/app/docs/imported/repository_overview_250606.md", "file_name": "repository_overview_250606.md", "file_size": 7775, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "91867e606be8078df6f972c7d7065c142342af85ee453221ab519546998e93b3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a45f5cca-c770-48de-944e-21946c4e54c6", "node_type": "1", "metadata": {}, "hash": "c512d0f3779c22b4ee2d8b96642942cead582c6265c707b036872dd5310dc031", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "to newcomer\nJun 6\nWildfireRanch/Relay\nArchive\nShare\nExplain the codebase to a newcomer. What is the general structure, what are the important things to know, and what are some pointers for things to learn next?\nCopy\nRepository Overview\nThis project hosts \u201cRelay,\u201d a small FastAPI backend with a Next.js/React frontend. The repository structure is straightforward:\n/main.py \u2013 FastAPI application entry\n/routes/ \u2013 REST endpoints\n/services/ \u2013 Core backend logic\n/frontend/ \u2013 Next.js frontend\n/docs/ \u2013 Generated/Imported docs\n/data/ & /logs/ \u2013 Action queue and logging files\n/tests/ \u2013 (mostly empty) test placeholders\nBackend\nmain.py initializes FastAPI, loads environment variables, configures CORS and mounts the route modules:\n9 from dotenv import load\\_dotenv\n10 load\\_dotenv()\n...\n35 app.add\\_middleware(\n...\n49 app.include\\_router(ask.router)\n50 app.include\\_router(status.router)\n51 app.include\\_router(control.router)\n52 app.include\\_router(docs.router)\n53 app.include\\_router(oauth.router)\nServices\nservices/agent.py\nImplements the OpenAI-powered assistant. It determines if code/doc context is needed, can auto-generate docs, and queues new files through /control/queue\\_action.\nKey logic includes the system prompt and context gathering helpers:\n15 SYSTEM\\_PROMPT = \"\"\"\nYou are Relay...\n...\n30 def needs\\_code\\_context(query: str) -> bool:\n...\n41 async def answer(user_id: str, query: str, context: Optional[str] = None, stream: bool = False):\n...\n85 async def generate\\_doc\\_for\\_path(rel\\_path: str) -> str:\n...\n136 def read\\_source\\_files(roots=[\"services\"], exts=[\".py\", \".tsx\", \".ts\"]):\n...\n166 def read\\_docs(root=\"docs\", exts=[\".md\", \".txt\"]):\nservices/google\\_docs\\_sync.py\nHandles Google OAuth, downloads docs from a specified Drive folder, converts them to Markdown, and saves them under docs/imported:\n1 # File: services/google\\_docs\\_sync.py\n...\n31 def get\\_google\\_service():\n...\n138 def sync\\_google\\_docs() -> list:\n...\n152 if enabled:\n153 sync\\_google\\_docs()\nservices/kb.py\nEmbeds markdown docs into a SQLite-based vector database using LangChain to enable semantic search:\n11 DOCS\\_DIR = ROOT / \"docs\"\n...\n35 def embed\\_docs():\n...\n53 def cosine\\_similarity(v1, v2):\n...\n58 def search(query, k=4):\nOther helpers include logging (services/logs.py) and environment validation (services/settings.py).\nRoutes\nFastAPI endpoints live in routes/. Examples:\nroutes/ask.py \u2013 exposes /ask for user questions and /test\\_openai for verifying OpenAI access.\nroutes/control.py \u2013 provides endpoints for writing files, queuing actions, approving queued actions, and retrieving logs:\n14 def auth(key: str = Header(..., alias=\"X-API-Key\")):\n...\n45 @router.post(\"/write\\_file\")\n...\n69 @router.post(\"/queue\\_action\")\n...\n94 @router.post(\"/approve\\_action\")\n...\n134 @router.get(\"/list\\_log\")\nroutes/docs.py \u2013 manages document syncing and knowledge-base refreshing:\n31 @router.post(\"/update\\_context\")\n...\n58 @router.post(\"/sync\\_google\")\n63 @router.post(\"/sync\")\n74 @router.post(\"/refresh\\_kb\")\n85 @router.post(\"/full\\_sync\")\n98 @router.get(\"/list\")\n109 @router.get(\"/view\")\nFrontend\nThe frontend/ folder contains a Next.js app. The home page (src/app/page.tsx) links to Docs, Control, and Status pages and embeds several React components:\n3 import AskAgent from \"@/components/AskAgent/AskAgent\"\n...\n10 \n...\n23 \n...\n29 \n33 \nKey components include:\nAskAgent \u2013 simple form that queries /ask.\nActionQueuePanel \u2013 lists and approves queued actions by hitting /control/\\* endpoints.\nDocsViewer \u2013 displays Markdown files and allows manual Google Docs sync.\nSearchPanel \u2013 calls the /kb/search API.\nThe frontend also has minimal API routes under src/app/api/ that forward requests to the backend, allowing the Next.js app to act as a thin UI over the FastAPI service.\nData and Logging\nQueued actions are stored in data/pending\\_actions.json, and executed actions are logged to logs/actions.log. Basic session logs are written via services/logs.py. The docs directory (docs/) contains imported or generated documentation used by the knowledge base.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4042, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a45f5cca-c770-48de-944e-21946c4e54c6": {"__data__": {"id_": "a45f5cca-c770-48de-944e-21946c4e54c6", "embedding": null, "metadata": {"file_path": "/app/docs/imported/repository_overview_250606.md", "file_name": "repository_overview_250606.md", "file_size": 7775, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "89382837-662b-4520-b66b-a2c9c78eccb5", "node_type": "4", "metadata": {"file_path": "/app/docs/imported/repository_overview_250606.md", "file_name": "repository_overview_250606.md", "file_size": 7775, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "91867e606be8078df6f972c7d7065c142342af85ee453221ab519546998e93b3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "af1348d7-dafe-4b9c-b1c3-741d82c9dc1a", "node_type": "1", "metadata": {"file_path": "/app/docs/imported/repository_overview_250606.md", "file_name": "repository_overview_250606.md", "file_size": 7775, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "e8a403eda54b47511aaca46e98bd432a645f3841a57a56bdc43ae4c0c53d5fed", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The home page (src/app/page.tsx) links to Docs, Control, and Status pages and embeds several React components:\n3 import AskAgent from \"@/components/AskAgent/AskAgent\"\n...\n10 \n...\n23 \n...\n29 \n33 \nKey components include:\nAskAgent \u2013 simple form that queries /ask.\nActionQueuePanel \u2013 lists and approves queued actions by hitting /control/\\* endpoints.\nDocsViewer \u2013 displays Markdown files and allows manual Google Docs sync.\nSearchPanel \u2013 calls the /kb/search API.\nThe frontend also has minimal API routes under src/app/api/ that forward requests to the backend, allowing the Next.js app to act as a thin UI over the FastAPI service.\nData and Logging\nQueued actions are stored in data/pending\\_actions.json, and executed actions are logged to logs/actions.log. Basic session logs are written via services/logs.py. The docs directory (docs/) contains imported or generated documentation used by the knowledge base.\nGetting Started / Next Steps\nEnvironment Setup \u2013 ensure .env contains OPENAI\\_API\\_KEY, GOOGLE\\_CREDS\\_JSON, optional GOOGLE\\_TOKEN\\_JSON, and API\\_KEY. main.py loads these via dotenv on startup.\nRunning Locally \u2013 start the backend (python main.py or uvicorn main:app) and the frontend (npm run dev within frontend/).\nDocs Sync and KB \u2013 explore services/google\\_docs\\_sync.py and the /docs routes to understand how Google Docs are pulled and embedded.\nAgent Logic \u2013 services/agent.py is central to how the assistant gathers context and answers questions; studying its helper functions is useful for extending functionality.\nTesting \u2013 the tests/ directory contains placeholders. Adding real tests (for routes, sync logic, etc.) would be a logical area for improvement.\nOverall, the project integrates OpenAI, Google Drive, and a simple knowledge base to provide a conversational assistant with access to synced documentation and the ability to queue file changes. The Next.js frontend offers a small dashboard for user interaction. Future work might include fleshing out tests, expanding route functionality, or enhancing the frontend.\ncan you put this in a pasteable document\nCopy\nBelow is a pasteable Markdown document summarizing the repository structure, components, and suggested next steps:\nRelay Repository Overview\nThis project contains a small FastAPI backend paired with a Next.js/React frontend. The layout is straightforward:\n/main.py \u2013 FastAPI application entry point\n/routes/ \u2013 REST API endpoints\n/services/ \u2013 Core backend logic\n/frontend/ \u2013 Next.js frontend\n/docs/ \u2013 Generated/imported documentation\n/data/ & /logs/ \u2013 Queued actions and logs\n/tests/ \u2013 Mostly empty placeholders\nBackend\nmain.py initializes FastAPI, loads environment variables, configures CORS, and registers route modules.\nKey Service Modules\nservices/agent.py \u2013 Implements the OpenAI\u2011powered assistant. Handles context gathering, question answering, and documentation generation.\nservices/google\\_docs\\_sync.py \u2013 Syncs documentation from a Google Drive folder and stores Markdown files under docs/imported.\nservices/kb.py \u2013 Embeds Markdown docs into a SQLite vector database for semantic search.\nOther helper modules manage logging and environment validation.\nRoutes\nroutes/ask.py \u2013 /ask endpoint and an OpenAI test route.\nroutes/control.py \u2013 Endpoints for writing files, queuing/approving actions, and retrieving logs.\nroutes/docs.py \u2013 Manages document syncing and knowledge-base refreshing.\nFrontend\nLocated in frontend/, the Next.js app serves a dashboard with components to interact with the backend:\nAskAgent \u2013 Form for querying /ask.\nActionQueuePanel \u2013 Approve queued actions via /control/\\*.\nDocsViewer \u2013 Display Markdown docs and sync with Google Docs.\nSearchPanel \u2013 Query the knowledge base.\nData and Logging\ndata/pending\\_actions.json \u2013 Stores queued actions.\nlogs/actions.log \u2013 Logs executed actions.\ndocs/ \u2013 Contains imported/generated docs used by the knowledge base.\nGetting Started\nEnvironment Variables \u2013 Ensure .env includes OPENAI\\_API\\_KEY, GOOGLE\\_CREDS\\_JSON, optional GOOGLE\\_TOKEN\\_JSON, and API\\_KEY.\nRun Locally \u2013 Start the backend (python main.py or uvicorn main:app) and the frontend (npm run dev inside frontend/).\nDocs & KB \u2013 Study services/google\\_docs\\_sync.py and the /docs routes to see how documentation is synced and indexed.\nAgent Logic \u2013 Review services/agent.py to understand how context is gathered and responses are generated.\nTesting \u2013 The tests/ directory is mostly empty. Adding real tests for routes and sync logic is a natural improvement.\nThis text can be copied directly into any document or note-taking tool.", "mimetype": "text/plain", "start_char_idx": 3133, "end_char_idx": 7681, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "735c5632-2eef-4267-9f01-d844c9b3b5b4": {"__data__": {"id_": "735c5632-2eef-4267-9f01-d844c9b3b5b4", "embedding": null, "metadata": {"file_path": "/app/docs/imported/test_placeholder.md", "file_name": "test_placeholder.md", "file_size": 0, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0c5bffea-629f-41a4-98aa-62251d0a9904", "node_type": "4", "metadata": {"file_path": "/app/docs/imported/test_placeholder.md", "file_name": "test_placeholder.md", "file_size": 0, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "d8609a3a028dfca5f55f87dd3cb5a5da11969987412b31373fd6c3a75851facd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 0, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "72c154dd-bd22-44d6-8548-502f450f53b2": {"__data__": {"id_": "72c154dd-bd22-44d6-8548-502f450f53b2", "embedding": null, "metadata": {"file_path": "/app/docs/imported/v1_documentation_250606.md", "file_name": "v1_documentation_250606.md", "file_size": 9879, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "61560e80-1b0c-48b7-837c-d00a6483902c", "node_type": "4", "metadata": {"file_path": "/app/docs/imported/v1_documentation_250606.md", "file_name": "v1_documentation_250606.md", "file_size": 9879, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "8c55914e86c248bde10038f9f3b52bf2ad46ea8e4deeee80c14c2b477237255c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3b22dafb-6cb3-414f-8e41-9b32debdb0b0", "node_type": "1", "metadata": {}, "hash": "b298ec73cfc8ec3f9d302c8f927345d8cd813f2c9719f85cab75cc872e0d97fc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "1. Functionality\nConversational AI Agent (/ask): Leverages GPT\u20114o to handle free\u2011form queries, cite sources, and suggest code patches based on context.\nSemantic Knowledge Base (/kb/search): Performs vector similarity searches over imported Markdown docs (Google\u2011synced or generated) using SQLite + LangChain embeddings.\nGoogle Docs Sync (/docs/sync): OAuth2\u2011powered flow that imports designated Drive documents into docs/imported, converting them to Markdown and refreshing the KB.\nDocumentation Browser (/docs/list, /docs/view): Lists available docs and serves their content for in\u2011app viewing.\nAction Queue & Patch Approval (/control/queue\\_action, /control/approve\\_action): Stages file writes or code modifications for developer review before applying changes.\nEnvironment Validator (/check/env\\_keys): Validates required environment variables at startup, preventing misconfigurations.\nDashboard UI: Next.js/React interface with panels:\nAskAgent \u2013 Chat interface for AI queries\nSearchPanel \u2013 KB lookup by keyword\nDocsViewer \u2013 Two\u2011pane Markdown viewer with sync trigger\nActionQueuePanel \u2013 Pending patches list and one\u2011click approval\n2. How to Use\nPrerequisites: Node.js, Python 3.12+, uvicorn, npm, and valid Google OAuth credentials.\nEnvironment Setup\u000bcp .env.example .env\n# Populate with:\n# OPENAI\\_API\\_KEY, API\\_KEY, GOOGLE\\_CREDS\\_JSON, (optional) GOOGLE\\_TOKEN\\_JSON\nInstall & Launch Services\u000b# Backend\npip install -r requirements.txt\nuvicorn main:app --reload --port 8080\n# Frontend\ncd frontend\nnpm install\nnpm run dev # runs on port 3000\nSync Documentation\nIn browser, go to http://localhost:8080/docs/sync\nAuthenticate via Google (first run)\nConfirm import: Markdown files appear under docs/imported.\nInteract\nAskAgent: Ask questions in Dashboard, view citations and suggestions.\nSearchPanel: Search KB for context or troubleshooting docs.\nDocsViewer: Navigate synced docs; click \u201cSync\u201d to refresh.\nActionQueuePanel: Review queued patches, click \u201cApprove\u201d to apply.\nDirect API Calls\u000bGET /ask?query=Your+question\nPOST /api/kb/search { query: string, k: number }\nPOST /control/queue\\_action { patch details }\nPOST /control/approve\\_action { action\\_id }\nPOST /docs/sync\nGET /docs/list\nGET /docs/view?path=imported/YourDoc.md\n3. Technical Details\nProject Structure\n/ # Root\n\u251c\u2500 main.py # FastAPI startup & route registration\n\u251c\u2500 routes/\n\u2502 \u251c\u2500 ask.py # /ask endpoint logic\n\u2502 \u251c\u2500 control.py # queue\\_action, approve\\_action\n\u2502 \u251c\u2500 docs.py # sync, list, view routes\n\u2502 \u2514\u2500 check.py # /check/env\\_keys\n\u251c\u2500 services/\n\u2502 \u251c\u2500 agent.py # GPT prompt composition & context loader\n\u2502 \u251c\u2500 kb.py # embedding & search utils\n\u2502 \u251c\u2500 google\\_docs\\_sync.py # OAuth flow & Drive MD conversion\n\u2502 \u2514\u2500 settings.py # Env var schema & loader\n\u251c\u2500 docs/\n\u2502 \u251c\u2500 imported/ # Google\u2011sync Markdown files\n\u2502 \u2514\u2500 generated/ # AI\u2011generated summaries\n\u251c\u2500 data/\n\u2502 \u2514\u2500 pending\\_actions.json # Queued patch state\n\u251c\u2500 logs/\n\u2502 \u2514\u2500 actions.log # Patch application history\n\u251c\u2500 frontend/\n\u2502 \u251c\u2500 src/app/page.tsx # Main Dashboard layout\n\u2502 \u251c\u2500 components/\n\u2502 \u2502 \u251c\u2500 AskAgent.tsx\n\u2502 \u2502 \u251c\u2500 SearchPanel.tsx\n\u2502 \u2502 \u251c\u2500 DocsViewer.tsx\n\u2502 \u2502 \u2514\u2500 ActionQueuePanel.tsx\n\u2502 \u2514\u2500 api/ # Next.js API proxy (optional)\n\u2514\u2500 tests/ # Unit/integration test stubs\nKey Code Highlights\nSYSTEM\\_PROMPT in services/agent.py: Central AI persona & context roles.\nContext Loaders: agent.read\\_source\\_files() reads code snippets; agent.read\\_docs() pulls Markdown docs.\nEmbeddings: kb.embed\\_doc() & kb.search() use OpenAI's embedding model, cache in SQLite DB.\nOAuth2 Flow: google\\_docs\\_sync.py uses InstalledAppFlow for local webserver auth, token persistence.\nPatch Workflow: data/pending\\_actions.json stores staged patch diffs; control.py applies approved diffs to disk.\n4.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3674, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3b22dafb-6cb3-414f-8e41-9b32debdb0b0": {"__data__": {"id_": "3b22dafb-6cb3-414f-8e41-9b32debdb0b0", "embedding": null, "metadata": {"file_path": "/app/docs/imported/v1_documentation_250606.md", "file_name": "v1_documentation_250606.md", "file_size": 9879, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "61560e80-1b0c-48b7-837c-d00a6483902c", "node_type": "4", "metadata": {"file_path": "/app/docs/imported/v1_documentation_250606.md", "file_name": "v1_documentation_250606.md", "file_size": 9879, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "8c55914e86c248bde10038f9f3b52bf2ad46ea8e4deeee80c14c2b477237255c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "72c154dd-bd22-44d6-8548-502f450f53b2", "node_type": "1", "metadata": {"file_path": "/app/docs/imported/v1_documentation_250606.md", "file_name": "v1_documentation_250606.md", "file_size": 9879, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "1a3cc7ac6a0c27fc32f821ba4a4dc76e7d208d14a5fc18aeecc54ffa05d53edb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c4f918e2-abb0-4d87-8024-3abdafb9d222", "node_type": "1", "metadata": {}, "hash": "3f7b84fec6e34c374f9d424c32c61d147f3c6859f20b5c02b79f482361e1f48c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Context Loaders: agent.read\\_source\\_files() reads code snippets; agent.read\\_docs() pulls Markdown docs.\nEmbeddings: kb.embed\\_doc() & kb.search() use OpenAI's embedding model, cache in SQLite DB.\nOAuth2 Flow: google\\_docs\\_sync.py uses InstalledAppFlow for local webserver auth, token persistence.\nPatch Workflow: data/pending\\_actions.json stores staged patch diffs; control.py applies approved diffs to disk.\n4. Actual Routes & Descriptions\nThese endpoints are loaded from current code:\nGET / \u2014 Sanity check (uptime, load balancer) (main.py)\nGET /ask \u2014 AI query interface (routes/ask.py)\nGET /check/env\\_keys \u2014 Env var validation (routes/check.py)\nPOST /docs/sync \u2014 Trigger Google Docs import (routes/docs.py)\nGET /docs/list \u2014 List available docs (routes/docs.py)\nGET /docs/view \u2014 Serve markdown content (routes/docs.py)\nPOST /control/queue\\_action \u2014 Stage file/patch write (routes/control.py)\nPOST /control/approve\\_action \u2014 Approve and apply staged action (routes/control.py)\nPOST /api/kb/search \u2014 Semantic search payload (routes/kb.py)\n5. Impact & Metrics (Placeholders)\nGoogle Docs Imported: \\_\\_ docs\nMarkdown Files: \\_\\_ files in docs/imported\nAPI Hits: /ask \\_\\_ calls, KB search \\_\\_ calls\nPatches Queued/Applied: \\_\\_ / \\_\\_\nAvg. Latency: /ask \\_\\_ ms, /api/kb/search \\_\\_ ms\nOnboarding Time: Setup from zero to running in \\_\\_ minutes\nFill in with real telemetry to quantify v1 success.\nEnd of Release Notes & Documentation for v1.\nV1 Relay Command Center \u2013 Release Notes & Documentation\n1. Functionality\nConversational AI Agent (/ask): Leverages GPT\u20114o to handle free\u2011form queries, cite sources, and suggest code patches based on context.\nSemantic Knowledge Base (/kb/search): Performs vector similarity searches over imported Markdown docs (Google\u2011synced or generated) using SQLite + LangChain embeddings.\nGoogle Docs Sync (/docs/sync): OAuth2\u2011powered flow that imports designated Drive documents into docs/imported, converting them to Markdown and refreshing the KB.\nDocumentation Browser (/docs/list, /docs/view): Lists available docs and serves their content for in\u2011app viewing.\nAction Queue & Patch Approval (/control/queue\\_action, /control/approve\\_action): Stages file writes or code modifications for developer review before applying changes.\nEnvironment Validator (/check/env\\_keys): Validates required environment variables at startup, preventing misconfigurations.\nDashboard UI: Next.js/React interface with panels:\nAskAgent \u2013 Chat interface for AI queries\nSearchPanel \u2013 KB lookup by keyword\nDocsViewer \u2013 Two\u2011pane Markdown viewer with sync trigger\nActionQueuePanel \u2013 Pending patches list and one\u2011click approval\n2. How to Use\nPrerequisites: Node.js, Python 3.12+, uvicorn, npm, and valid Google OAuth credentials.\nEnvironment Setup\ncp .env.example .env\n# Populate with:\n# OPENAI\\_API\\_KEY, API\\_KEY, GOOGLE\\_CREDS\\_JSON, (optional) GOOGLE\\_TOKEN\\_JSON\nInstall & Launch Services\n# Backend\npip install -r requirements.txt\nuvicorn main:app --reload --port 8080\n# Frontend\ncd frontend\nnpm install\nnpm run dev # runs on port 3000\nSync Documentation\nIn browser, go to http://localhost:8080/docs/sync\nAuthenticate via Google (first run)\nConfirm import: Markdown files appear under docs/imported.\nInteract\nAskAgent: Ask questions in Dashboard, view citations and suggestions.\nSearchPanel: Search KB for context or troubleshooting docs.\nDocsViewer: Navigate synced docs; click \u201cSync\u201d to refresh.\nActionQueuePanel: Review queued patches, click \u201cApprove\u201d to apply.\nDirect API Calls\nGET /ask?query=Your+question\nPOST /api/kb/search { query: string, k: number }\nPOST /control/queue\\_action { patch details }\nPOST /control/approve\\_action { action\\_id }\nPOST /docs/sync\nGET /docs/list\nGET /docs/view?path=imported/YourDoc.md\n3.", "mimetype": "text/plain", "start_char_idx": 3259, "end_char_idx": 6998, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c4f918e2-abb0-4d87-8024-3abdafb9d222": {"__data__": {"id_": "c4f918e2-abb0-4d87-8024-3abdafb9d222", "embedding": null, "metadata": {"file_path": "/app/docs/imported/v1_documentation_250606.md", "file_name": "v1_documentation_250606.md", "file_size": 9879, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "61560e80-1b0c-48b7-837c-d00a6483902c", "node_type": "4", "metadata": {"file_path": "/app/docs/imported/v1_documentation_250606.md", "file_name": "v1_documentation_250606.md", "file_size": 9879, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "8c55914e86c248bde10038f9f3b52bf2ad46ea8e4deeee80c14c2b477237255c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3b22dafb-6cb3-414f-8e41-9b32debdb0b0", "node_type": "1", "metadata": {"file_path": "/app/docs/imported/v1_documentation_250606.md", "file_name": "v1_documentation_250606.md", "file_size": 9879, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "82d88423fdaf45fd4d7a8745b9a03589a930aabc739d508234654af510550503", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Interact\nAskAgent: Ask questions in Dashboard, view citations and suggestions.\nSearchPanel: Search KB for context or troubleshooting docs.\nDocsViewer: Navigate synced docs; click \u201cSync\u201d to refresh.\nActionQueuePanel: Review queued patches, click \u201cApprove\u201d to apply.\nDirect API Calls\nGET /ask?query=Your+question\nPOST /api/kb/search { query: string, k: number }\nPOST /control/queue\\_action { patch details }\nPOST /control/approve\\_action { action\\_id }\nPOST /docs/sync\nGET /docs/list\nGET /docs/view?path=imported/YourDoc.md\n3. Technical Details\nProject Structure\n/ # Root\n\u251c\u2500 main.py # FastAPI startup & route registration\n\u251c\u2500 routes/\n\u2502 \u251c\u2500 ask.py # /ask endpoint logic\n\u2502 \u251c\u2500 control.py # queue\\_action, approve\\_action\n\u2502 \u251c\u2500 docs.py # sync, list, view routes\n\u2502 \u2514\u2500 check.py # /check/env\\_keys\n\u251c\u2500 services/\n\u2502 \u251c\u2500 agent.py # GPT prompt composition & context loader\n\u2502 \u251c\u2500 kb.py # embedding & search utils\n\u2502 \u251c\u2500 google\\_docs\\_sync.py # OAuth flow & Drive MD conversion\n\u2502 \u2514\u2500 settings.py # Env var schema & loader\n\u251c\u2500 docs/\n\u2502 \u251c\u2500 imported/ # Google\u2011sync Markdown files\n\u2502 \u2514\u2500 generated/ # AI\u2011generated summaries\n\u251c\u2500 data/\n\u2502 \u2514\u2500 pending\\_actions.json # Queued patch state\n\u251c\u2500 logs/\n\u2502 \u2514\u2500 actions.log # Patch application history\n\u251c\u2500 frontend/\n\u2502 \u251c\u2500 src/app/page.tsx # Main Dashboard layout\n\u2502 \u251c\u2500 components/\n\u2502 \u2502 \u251c\u2500 AskAgent.tsx\n\u2502 \u2502 \u251c\u2500 SearchPanel.tsx\n\u2502 \u2502 \u251c\u2500 DocsViewer.tsx\n\u2502 \u2502 \u2514\u2500 ActionQueuePanel.tsx\n\u2502 \u2514\u2500 api/ # Next.js API proxy (optional)\n\u2514\u2500 tests/ # Unit/integration test stubs\nKey Code Highlights\nSYSTEM\\_PROMPT in services/agent.py: Central AI persona & context roles.\nContext Loaders: agent.read\\_source\\_files() reads code snippets; agent.read\\_docs() pulls Markdown docs.\nEmbeddings: kb.embed\\_doc() & kb.search() use OpenAI's embedding model, cache in SQLite DB.\nOAuth2 Flow: google\\_docs\\_sync.py uses InstalledAppFlow for local webserver auth, token persistence.\nPatch Workflow: data/pending\\_actions.json stores staged patch diffs; control.py applies approved diffs to disk.\n4. Actual Routes & Descriptions\nThese endpoints are loaded from current code:\nGET / \u2014 Sanity check (uptime, load balancer) (main.py)\nGET /ask \u2014 AI query interface (routes/ask.py)\nGET /check/env\\_keys \u2014 Env var validation (routes/check.py)\nPOST /docs/sync \u2014 Trigger Google Docs import (routes/docs.py)\nGET /docs/list \u2014 List available docs (routes/docs.py)\nGET /docs/view \u2014 Serve markdown content (routes/docs.py)\nPOST /control/queue\\_action \u2014 Stage file/patch write (routes/control.py)\nPOST /control/approve\\_action \u2014 Approve and apply staged action (routes/control.py)\nPOST /api/kb/search \u2014 Semantic search payload (routes/kb.py)\n5. Impact & Metrics (Placeholders)\nGoogle Docs Imported: \\_\\_ docs\nMarkdown Files: \\_\\_ files in docs/imported\nAPI Hits: /ask \\_\\_ calls, KB search \\_\\_ calls\nPatches Queued/Applied: \\_\\_ / \\_\\_\nAvg. Latency: /ask \\_\\_ ms, /api/kb/search \\_\\_ ms\nOnboarding Time: Setup from zero to running in \\_\\_ minutes\nFill in with real telemetry to quantify v1 success.\nEnd of Release Notes & Documentation for v1.", "mimetype": "text/plain", "start_char_idx": 6474, "end_char_idx": 9465, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6a3302e9-260f-47df-b87f-7b7ba002a0b7": {"__data__": {"id_": "6a3302e9-260f-47df-b87f-7b7ba002a0b7", "embedding": null, "metadata": {"file_path": "/app/docs/imported/\ud83d\udd27_google_docs_sync_integration.md", "file_name": "\ud83d\udd27_google_docs_sync_integration.md", "file_size": 3065, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a4fae8b6-ccef-469c-b9fa-81a9ada5221c", "node_type": "4", "metadata": {"file_path": "/app/docs/imported/\ud83d\udd27_google_docs_sync_integration.md", "file_name": "\ud83d\udd27_google_docs_sync_integration.md", "file_size": 3065, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "project_docs", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "50f017801cdad07478f2bc4c0babb809818690d0dd6a8a16e5745a1f4db4a7d8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\ud83d\udd27 Google Docs Sync Integration\nPurpose: To synchronize Google Docs from a specific folder in Google Drive into your local application, converting them into Markdown files for further processing.\nKey Components:\nEnvironment Variables:\u000b\nGOOGLE\\_CREDS\\_JSON: Base64-encoded Google OAuth 2.0 credentials JSON.\u000b\nGOOGLE\\_TOKEN\\_JSON: Base64-encoded token JSON obtained after user authorization.\u000b\nFile Paths:\u000b\nCREDENTIALS\\_PATH: Path to store decoded credentials (/tmp/credentials.json).\u000b\nTOKEN\\_PATH: Path to store decoded token (frontend/sync/token.json).\u000b\nIMPORT\\_PATH: Directory to store imported Markdown files (docs/imported).\u000b\nFolder Configuration:\u000b\nCOMMAND\\_CENTER\\_FOLDER\\_NAME: Name of the folder in Google Drive to sync (COMMAND\\_CENTER).\u000b\nWorkflow:\nCredential Handling:\u000b\nCheck if CREDENTIALS\\_PATH exists. If not, decode GOOGLE\\_CREDS\\_JSON and write to this path.\u000b\nCheck if TOKEN\\_PATH exists. If not, decode GOOGLE\\_TOKEN\\_JSON (if available) and write to this path.\u000b\nAuthentication:\u000b\nIf TOKEN\\_PATH exists, load credentials from it.\u000b\nIf credentials are invalid or don't exist:\u000b\nInitiate OAuth flow using InstalledAppFlow.from\\_client\\_secrets\\_file.\u000b\nRun local server to obtain user authorization and generate new token.\u000b\nSave new token to TOKEN\\_PATH.\u000b\nGoogle Drive Interaction:\u000b\nBuild drive\\_service and docs\\_service using authenticated credentials.\u000b\nLocate the folder ID for COMMAND\\_CENTER\\_FOLDER\\_NAME.\u000b\nRetrieve all Google Docs within this folder.\u000b\nFor each document:\u000b\nFetch content using docs\\_service.\u000b\nConvert content to Markdown using markdownify.\u000b\nSave the Markdown file to IMPORT\\_PATH.\u000b\n\ud83d\udee0\ufe0f Error Handling and Debugging\nCommon Issues Encountered:\nMissing Environment Variables:\u000b\nError: \u274c Missing GOOGLE\\_CREDS\\_JSON in environment variables\u000b\nSolution: Ensure that GOOGLE\\_CREDS\\_JSON is correctly set in your environment.\u000b\nSyntax Errors:\u000b\nError: SyntaxError: 'return' outside function\u000b\nCause: Incorrect indentation or misplaced return statement.\u000b\nSolution: Ensure that all code blocks are properly indented and that return statements are within function scopes.\u000b\nAttribute Errors:\u000b\nError: AttributeError: 'InstalledAppFlow' object has no attribute 'run\\_console'\u000b\nCause: Incorrect method used for initiating OAuth flow.\u000b\nSolution: Use run\\_local\\_server(port=0) instead of run\\_console() for local development.\u000b\nOAuth Redirect URI Mismatch:\u000b\nError: Error 400: redirect\\_uri\\_mismatch\u000b\nCause: The redirect URI used in the application doesn't match any of the authorized redirect URIs in the Google Cloud Console.\u000b\nSolution:\u000b\nNavigate to Google Cloud Console Credentials page.\u000b\nSelect your OAuth 2.0 Client ID.\u000b\nIn the \"Authorized redirect URIs\" section, add the exact redirect URI used by your application (e.g., http://localhost:8080/).\u000b\nSave the changes.\u000b\n\ud83d\udd04 Full Sync Process\nEndpoint: POST /docs/full\\_sync\nFunctionality:\nInitiates the Google Docs synchronization process.\u000b\nEmbeds the synchronized Markdown documents into the knowledge base.\u000b\nLogs the synchronization activity for auditing and tracking purposes.serverfault.com", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3051, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0396bf68-47e3-4645-b9ad-86d41ed947ee": {"__data__": {"id_": "0396bf68-47e3-4645-b9ad-86d41ed947ee", "embedding": null, "metadata": {"tier": "project_docs", "file_path": "/app/docs/readme.md", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ce8dd2aa-4aca-4a2d-bfd4-ecd95dd6534b", "node_type": "4", "metadata": {"tier": "project_docs", "file_path": "/app/docs/readme.md", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "098d8e56067c11396ef25b59bac37f1fd18316d74480d4440db7da0575a69d3b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 0, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d7aee2c7-6a7a-49b1-8bad-90a31384ed21": {"__data__": {"id_": "d7aee2c7-6a7a-49b1-8bad-90a31384ed21", "embedding": null, "metadata": {"file_path": "/app/frontend/components.json", "file_name": "components.json", "file_type": "application/json", "file_size": 428, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1afc5ca0-4c7b-480a-9dd2-51727be5e050", "node_type": "4", "metadata": {"file_path": "/app/frontend/components.json", "file_name": "components.json", "file_type": "application/json", "file_size": 428, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "3f13de6ab7e54b73962eb263938d020508bcfc9960ed04072a8415c1d098ec58", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "{\n  \"$schema\": \"https://ui.shadcn.com/schema.json\",\n  \"style\": \"new-york\",\n  \"rsc\": true,\n  \"tsx\": true,\n  \"tailwind\": {\n    \"config\": \"\",\n    \"css\": \"src/app/globals.css\",\n    \"baseColor\": \"slate\",\n    \"cssVariables\": true,\n    \"prefix\": \"\"\n  },\n  \"aliases\": {\n    \"components\": \"@/components\",\n    \"utils\": \"@/lib/utils\",\n    \"ui\": \"@/components/ui\",\n    \"lib\": \"@/lib\",\n    \"hooks\": \"@/hooks\"\n  },\n  \"iconLibrary\": \"lucide\"\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 428, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0214fbe3-c1ac-4690-a528-7a5d9e10594f": {"__data__": {"id_": "0214fbe3-c1ac-4690-a528-7a5d9e10594f", "embedding": null, "metadata": {"file_path": "/app/frontend/next-env.d.ts", "file_name": "next-env.d.ts", "file_size": 211, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7abf54dc-8e4b-4450-a843-80baa48ff48d", "node_type": "4", "metadata": {"file_path": "/app/frontend/next-env.d.ts", "file_name": "next-env.d.ts", "file_size": 211, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "aa71108cf2c705c8ad102b227d8eaf2b81e65795ba5a6ded426e2e6cbaf35a62", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "/// <reference types=\"next\" />\n/// <reference types=\"next/image-types/global\" />\n\n// NOTE: This file should not be edited\n// see https://nextjs.org/docs/app/api-reference/config/typescript for more information.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 210, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "266592df-d32c-4574-b809-453b78331782": {"__data__": {"id_": "266592df-d32c-4574-b809-453b78331782", "embedding": null, "metadata": {"file_path": "/app/frontend/next.config.ts", "file_name": "next.config.ts", "file_size": 133, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "538826c7-a4f6-4df5-ae99-73f5e50bb87c", "node_type": "4", "metadata": {"file_path": "/app/frontend/next.config.ts", "file_name": "next.config.ts", "file_size": 133, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "392dfdd5ed0ff6c5540705a052645b22fc69b62568ae188b7ac1254d6db1efe2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import type { NextConfig } from \"next\";\n\nconst nextConfig: NextConfig = {\n  /* config options here */\n};\n\nexport default nextConfig;", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 132, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2c111119-5b15-478d-98d1-90b94cb8b263": {"__data__": {"id_": "2c111119-5b15-478d-98d1-90b94cb8b263", "embedding": null, "metadata": {"file_path": "/app/frontend/package.json", "file_name": "package.json", "file_type": "application/json", "file_size": 1627, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3818a848-5c42-489d-a6d2-1d25329bbf48", "node_type": "4", "metadata": {"file_path": "/app/frontend/package.json", "file_name": "package.json", "file_type": "application/json", "file_size": 1627, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "166d26864f3af3a75d4e652270800b0c75c28cd06ecdc68c51c4fbadc524aaed", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "{\n  \"name\": \"frontend\",\n  \"version\": \"0.1.0\",\n  \"private\": true,\n\n  \"scripts\": {\n    \"dev\": \"next dev --turbopack\",\n    \"build\": \"next build\",\n    \"start\": \"next start\",\n    \"lint\": \"next lint\",\n    \"storybook\": \"storybook dev -p 6006\",\n    \"build-storybook\": \"storybook build\"\n  },\n\n  \"dependencies\": {\n    \"@radix-ui/react-label\": \"^2.1.7\",\n    \"@radix-ui/react-slot\": \"^1.2.3\",\n\n    \"class-variance-authority\": \"^0.7.1\",\n    \"clsx\": \"^2.1.1\",\n    \"tailwind-merge\": \"^3.3.0\",\n\n    \"framer-motion\": \"^12.16.0\",\n    \"lucide-react\": \"^0.511.0\",\n\n    \"next\": \"15.3.3\",\n    \"next-auth\": \"^4.24.11\",\n    \"next-themes\": \"^0.4.6\",\n\n    \"react\": \"^19.0.0\",\n    \"react-dom\": \"^19.0.0\",\n\n    \"react-markdown\": \"^10.1.0\",\n    \"react-syntax-highlighter\": \"^15.6.1\",\n\n    \"recharts\": \"^2.15.3\"\n  },\n\n  \"devDependencies\": {\n    \"@chromatic-com/storybook\": \"^4.0.0\",\n    \"@eslint/eslintrc\": \"^3\",\n\n    \"@storybook/addon-a11y\": \"^9.0.6\",\n    \"@storybook/addon-docs\": \"^9.0.6\",\n    \"@storybook/addon-onboarding\": \"^9.0.6\",\n    \"@storybook/addon-vitest\": \"^9.0.6\",\n    \"@storybook/nextjs-vite\": \"^9.0.6\",\n    \"storybook\": \"^9.0.6\",\n    \"eslint-plugin-storybook\": \"^9.0.6\",\n\n    \"eslint\": \"^9\",\n    \"eslint-config-next\": \"15.3.3\",\n\n    \"tailwindcss\": \"^4.1.8\",\n    \"@tailwindcss/postcss\": \"^4.1.8\",\n    \"@tailwindcss/typography\": \"^0.5.11\",\n    \"autoprefixer\": \"^10.4.21\",\n\n    \"@types/node\": \"^20\",\n    \"@types/react\": \"^19\",\n    \"@types/react-dom\": \"^19\",\n\n    \"playwright\": \"^1.52.0\",\n    \"vitest\": \"^3.2.3\",\n    \"@vitest/browser\": \"^3.2.3\",\n    \"@vitest/coverage-v8\": \"^3.2.3\",\n\n    \"tw-animate-css\": \"^1.3.3\",\n\n    \"typescript\": \"^5\"\n  }\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1626, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "55f227b3-cf30-4a32-9876-61f7aad6c659": {"__data__": {"id_": "55f227b3-cf30-4a32-9876-61f7aad6c659", "embedding": null, "metadata": {"file_path": "/app/frontend/postcss.config.js", "file_name": "postcss.config.js", "file_type": "application/javascript", "file_size": 110, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "30ea6c55-ffa0-44b0-a5e3-618525cc661f", "node_type": "4", "metadata": {"file_path": "/app/frontend/postcss.config.js", "file_name": "postcss.config.js", "file_type": "application/javascript", "file_size": 110, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "83938e06c3f1bbd3e52af7f24a063cbe55ed7e97ce0715540da614800611e07f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// frontend/postcss.config.js\nmodule.exports = {\n  plugins: {\n    tailwindcss: {},\n    autoprefixer: {}\n  }\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 109, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9f8cef8f-3aa5-4a12-b248-851f2ba670a1": {"__data__": {"id_": "9f8cef8f-3aa5-4a12-b248-851f2ba670a1", "embedding": null, "metadata": {"file_path": "/app/frontend/src/app/action-queue/page.tsx", "file_name": "page.tsx", "file_size": 286, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0d494dc8-7d07-4c44-801e-d86762f915a2", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/app/action-queue/page.tsx", "file_name": "page.tsx", "file_size": 286, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "5116f6382020572150cd2248dd7e02c335334df4af2777977e0171be6e7a0766", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"use client\";\nimport ActionQueuePanel from \"@/components/ActionQueue/ActionQueuePanel\";\n\nexport default function ActionQueuePage() {\n  return (\n    <main className=\"p-6\">\n      <h1 className=\"text-2xl font-bold mb-4\">\ud83d\udccb Action Queue</h1>\n      <ActionQueuePanel />\n    </main>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 282, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a21b51f9-d1f2-43f1-8b24-28ecedf723fc": {"__data__": {"id_": "a21b51f9-d1f2-43f1-8b24-28ecedf723fc", "embedding": null, "metadata": {"file_path": "/app/frontend/src/app/api/docs/list/route.ts", "file_name": "route.ts", "file_size": 215, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "56d5a150-2b90-4300-b501-9725759db856", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/app/api/docs/list/route.ts", "file_name": "route.ts", "file_size": 215, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "04df1b765fd2ecfedd1cd14fb702698eebc54d36a8a9ffda7d292b18f9190cd2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { NextResponse } from \"next/server\"\n\nexport async function GET() {\n  const res = await fetch(`${process.env.NEXT_PUBLIC_API_URL}/docs/list`)\n  const data = await res.json()\n  return NextResponse.json(data)\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 214, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c19dadd7-258c-4d87-b394-681a39aebac2": {"__data__": {"id_": "c19dadd7-258c-4d87-b394-681a39aebac2", "embedding": null, "metadata": {"file_path": "/app/frontend/src/app/api/docs/view/route.ts", "file_name": "route.ts", "file_size": 358, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0307c0df-1e29-4696-8d03-e196b7e67638", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/app/api/docs/view/route.ts", "file_name": "route.ts", "file_size": 358, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "1d168124ebd435882c2dec029dff1cd38a302c49aa0f74f5303b3a533fde14e7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { NextRequest, NextResponse } from \"next/server\"\n\nexport async function GET(req: NextRequest) {\n  const url = new URL(req.url)\n  const path = url.searchParams.get(\"path\")\n  const res = await fetch(`${process.env.NEXT_PUBLIC_API_URL}/docs/view?path=${encodeURIComponent(path || \"\")}`)\n  const data = await res.json()\n  return NextResponse.json(data)\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 357, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "86275b3f-d56e-4714-9817-48fcde921c58": {"__data__": {"id_": "86275b3f-d56e-4714-9817-48fcde921c58", "embedding": null, "metadata": {"file_path": "/app/frontend/src/app/api/kb/search/route.ts", "file_name": "route.ts", "file_size": 389, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "43a338b7-920a-4c9a-a700-092e1dfdd77f", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/app/api/kb/search/route.ts", "file_name": "route.ts", "file_size": 389, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "6ae0a1fbaa695ba02d83608f95f1f54fe3cf6bbe48690c19e06ea9c73d95d82e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { NextRequest, NextResponse } from \"next/server\"\n\nexport async function POST(req: NextRequest) {\n  const body = await req.json()\n  const res = await fetch(`${process.env.NEXT_PUBLIC_API_URL}/kb/search`, {\n    method: \"POST\",\n    headers: { \"Content-Type\": \"application/json\" },\n    body: JSON.stringify(body),\n  })\n  const data = await res.json()\n  return NextResponse.json(data)\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 388, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "21026d6e-054f-4bd7-8039-f58dd0ecc07d": {"__data__": {"id_": "21026d6e-054f-4bd7-8039-f58dd0ecc07d", "embedding": null, "metadata": {"file_path": "/app/frontend/src/app/api/status/summary/route.ts", "file_name": "route.ts", "file_size": 220, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cf0a1220-6211-45fa-924e-e5ad10012b0a", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/app/api/status/summary/route.ts", "file_name": "route.ts", "file_size": 220, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "bf69ef56c12f482189fef103cc87c217672cac347ce2cda06ffdff4a5d65ffe5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import { NextResponse } from \"next/server\"\n\nexport async function GET() {\n  const res = await fetch(`${process.env.NEXT_PUBLIC_API_URL}/status/summary`)\n  const data = await res.json()\n  return NextResponse.json(data)\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 219, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "50a43997-5821-404a-8fb7-1f5d9754d2b9": {"__data__": {"id_": "50a43997-5821-404a-8fb7-1f5d9754d2b9", "embedding": null, "metadata": {"file_path": "/app/frontend/src/app/ask/page.tsx", "file_name": "page.tsx", "file_size": 5898, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9c13ef1d-7370-4e01-9b40-f1c9ae69a010", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/app/ask/page.tsx", "file_name": "page.tsx", "file_size": 5898, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "f414f2555847b5cbe240d18d03fccc6d425931e88a7be4c4e3ba7e7c5724e955", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1ee72952-cc6b-4f42-935d-1c818f435999", "node_type": "1", "metadata": {}, "hash": "e2f97991b7cb06ad5baae8a871329c590df3e965f71cc63853a50021a7a76e4a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: src/app/ask/page.tsx\n// Purpose: Ask Echo \u2014 bulletproof LLM chat interface with markdown rendering, local history, and safe input handling\n\n\"use client\";\n\nimport React, { useState, useRef, useEffect, useCallback } from \"react\";\nimport SafeMarkdown from \"@/components/SafeMarkdown\";\nimport { API_ROOT } from \"@/lib/api\";\n\n// Message type\ntype Message = {\n  role: \"user\" | \"assistant\";\n  content: string;\n  context?: string;\n};\n\nconst USER_ID = \"bret-demo\";\nconst STORAGE_KEY = `echo-chat-history-${USER_ID}`;\nconst INPUT_KEY = `echo-chat-input-${USER_ID}`;\n\n// Type guard for stored messages\nfunction isMessage(val: unknown): val is Message {\n  return (\n    typeof val === \"object\" &&\n    val !== null &&\n    (val as Message).role &&\n    typeof (val as Message).content === \"string\" &&\n    ((val as Message).role === \"user\" || (val as Message).role === \"assistant\")\n  );\n}\n\n// Normalize unknown array into safe Message[]\nfunction normalizeMessages(arr: unknown[]): Message[] {\n  return Array.isArray(arr)\n    ? arr\n        .filter(isMessage)\n        .map((msg) => ({\n          role: msg.role,\n          content: String(msg.content),\n          ...(typeof msg.context === \"string\" && { context: msg.context }),\n        }))\n    : [];\n}\n\n// Markdown stringifier (bulletproof)\nfunction toMDString(val: unknown): string {\n  if (val == null) return \"_(no content)_\";\n  if (typeof val === \"string\") return val;\n  if (Array.isArray(val)) return val.map(toMDString).join(\"\\n\\n\");\n  try {\n    return \"```json\\n\" + JSON.stringify(val, null, 2) + \"\\n```\";\n  } catch {\n    return String(val);\n  }\n}\n\nexport default function AskPage() {\n  const [messages, setMessages] = useState<Message[]>(() => {\n    if (typeof window !== \"undefined\") {\n      const raw = localStorage.getItem(STORAGE_KEY);\n      if (raw) {\n        try {\n          return normalizeMessages(JSON.parse(raw));\n        } catch {\n          return [];\n        }\n      }\n    }\n    return [];\n  });\n\n  const [input, setInput] = useState<string>(\"\");\n  const [loading, setLoading] = useState(false);\n  const bottomRef = useRef<HTMLDivElement>(null);\n\n  // Load cached input on mount\n  useEffect(() => {\n    const cached = localStorage.getItem(INPUT_KEY);\n    if (cached) setInput(cached);\n  }, []);\n\n  // Persist messages + scroll to bottom\n  useEffect(() => {\n    localStorage.setItem(STORAGE_KEY, JSON.stringify(messages));\n    bottomRef.current?.scrollIntoView({ behavior: \"smooth\" });\n  }, [messages]);\n\n  // Persist input while typing\n  useEffect(() => {\n    localStorage.setItem(INPUT_KEY, input);\n  }, [input]);\n\n  const sendMessage = useCallback(async (e?: React.FormEvent): Promise<void> => {\n    if (e) e.preventDefault();\n    if (!input.trim() || loading) return;\n\n    const userMessage = input;\n    setMessages((msgs) => [\n      ...msgs,\n      { role: \"user\", content: toMDString(userMessage) },\n    ]);\n    setLoading(true);\n    setInput(\"\");\n\n    try {\n      const res = await fetch(`${API_ROOT}/mcp/run`, {\n        method: \"POST\",\n        headers: {\n          \"Content-Type\": \"application/json\",\n          \"X-User-Id\": USER_ID,\n        },\n        body: JSON.stringify({\n          query: userMessage,\n          role: \"planner\",\n          debug: true,\n        }),\n      });\n\n      const data = await res.json();\n      const result = data?.result || data;\n\n      const content =\n        result?.plan?.objective ||\n        result?.plan?.recommendation ||\n        result?.recommendation ||\n        result?.response ||\n        data?.response ||\n        \"[no answer]\";\n\n      setMessages((msgs) => [\n        ...msgs,\n        { role: \"assistant\", content: toMDString(content) },\n      ]);\n    } catch (err) {\n      console.error(\"\u26a0\ufe0f Fetch error:\", err);\n      setMessages((msgs) => [\n        ...msgs,\n        {\n          role: \"assistant\",\n          content: toMDString(\"[error] Unable to get response.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3863, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1ee72952-cc6b-4f42-935d-1c818f435999": {"__data__": {"id_": "1ee72952-cc6b-4f42-935d-1c818f435999", "embedding": null, "metadata": {"file_path": "/app/frontend/src/app/ask/page.tsx", "file_name": "page.tsx", "file_size": 5898, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9c13ef1d-7370-4e01-9b40-f1c9ae69a010", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/app/ask/page.tsx", "file_name": "page.tsx", "file_size": 5898, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "f414f2555847b5cbe240d18d03fccc6d425931e88a7be4c4e3ba7e7c5724e955", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "50a43997-5821-404a-8fb7-1f5d9754d2b9", "node_type": "1", "metadata": {"file_path": "/app/frontend/src/app/ask/page.tsx", "file_name": "page.tsx", "file_size": 5898, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "4726cb6a70c71484036c2f2165283b7fd2eb3c4278dab0f0ab8bb80281b18776", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"),\n        },\n      ]);\n    }\n\n    setLoading(false);\n  }, [input, loading]);\n\n  const renderedMessages = messages.map((msg, i) => {\n    if (typeof msg.content !== \"string\") {\n      console.log(\"DEBUG 418:\", typeof msg.content, msg.content);\n    }\n    return (\n      <div\n        key={i}\n        className={\n          msg.role === \"user\"\n            ? \"text-right text-blue-700\"\n            : \"text-left text-green-700\"\n        }\n      >\n        <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n          <SafeMarkdown>{msg.content}</SafeMarkdown>\n        </div>\n      </div>\n    );\n  });\n\n  return (\n    <div className=\"w-full max-w-2xl mx-auto min-h-screen flex flex-col\">\n      <h1 className=\"text-3xl font-bold my-4\">Ask Echo</h1>\n      <div className=\"flex-1 space-y-2 overflow-y-auto border rounded-xl p-4 bg-muted\">\n        {renderedMessages}\n\n        {loading && (\n          <div className=\"text-left text-green-600 italic\">Thinking\u2026</div>\n        )}\n        <div ref={bottomRef} />\n      </div>\n      <form\n        onSubmit={sendMessage}\n        className=\"flex items-center gap-2 mt-4\"\n        autoComplete=\"off\"\n      >\n        <input\n          type=\"text\"\n          className=\"flex-1 rounded border px-3 py-2\"\n          placeholder=\"Type your question\u2026\"\n          value={input}\n          onChange={(e) => setInput(e.target.value)}\n          disabled={loading}\n          name=\"echo-message\"\n          id=\"echo-message\"\n          onKeyDown={(e) => {\n            if (e.key === \"Enter\" && !e.shiftKey) {\n              e.preventDefault();\n              sendMessage();\n            }\n          }}\n        />\n        <button\n          type=\"submit\"\n          className=\"bg-blue-600 text-white rounded px-4 py-2\"\n          disabled={loading || !input.trim()}\n        >\n          {loading ? \"Sending\u2026\" : \"Send\"}\n        </button>\n      </form>\n      <div className=\"text-xs text-gray-400 text-center mt-2\">\n        API root: <span className=\"font-mono\">{API_ROOT}</span>\n      </div>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 3863, "end_char_idx": 5885, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b6f8c778-ce5f-4381-875b-56fd57d7d3c6": {"__data__": {"id_": "b6f8c778-ce5f-4381-875b-56fd57d7d3c6", "embedding": null, "metadata": {"file_path": "/app/frontend/src/app/audit/page.tsx", "file_name": "page.tsx", "file_size": 261, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b7b0b669-7e2e-4c36-bb02-b63d4ab74bc1", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/app/audit/page.tsx", "file_name": "page.tsx", "file_size": 261, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "cad279930874b218c98c74cd1e40fd0adb8feccefc263e6e5987cbedbe6d6089", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"use client\";\nimport AuditPanel from \"@/components/AuditPanel/AuditPanel\";\n\nexport default function AuditPage() {\n  return (\n    <main className=\"p-6\">\n      <h1 className=\"text-2xl font-bold mb-4\">\ud83d\udee1\ufe0f Audit Log</h1>\n      <AuditPanel />\n    </main>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 255, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "169d6cd7-1764-4a73-8087-a2489c879090": {"__data__": {"id_": "169d6cd7-1764-4a73-8087-a2489c879090", "embedding": null, "metadata": {"file_path": "/app/frontend/src/app/codex/page.tsx", "file_name": "page.tsx", "file_size": 3861, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0f0c8f2d-d9a2-4d17-971f-10b704acebfa", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/app/codex/page.tsx", "file_name": "page.tsx", "file_size": 3861, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "7811f3b0cd3406efd5f4515bd471d837fc2bf56c3c185b378de3dda98d2eff2c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: src/app/codex/page.tsx\n// Purpose: Codex agent page with robust markdown/code output; status and patch display is bulletproofed.\n\n\"use client\";\n\nimport React, { useState } from \"react\";\nimport { CodexEditor, CodexPromptBar, CodexPatchView } from \"@/components/Codex\";\nimport { Button } from \"@/components/ui/button\";\nimport { API_ROOT } from \"@/lib/api\";\nimport SafeMarkdown from \"@/components/SafeMarkdown\";\nimport { toMDString } from \"@/lib/toMDString\";\n\n// Helper replaced by shared utility\n\nconst CodexPage: React.FC = () => {\n  const [code, setCode] = useState<string>(\"\");\n  const [prompt, setPrompt] = useState<string>(\"\");\n  const [streamingPatch, setStreamingPatch] = useState<string>(\"\");\n  const [parsedPatch, setParsedPatch] = useState<{\n    file: string;\n    patch: string;\n    reason: string;\n  } | null>(null);\n  const [status, setStatus] = useState<string>(\"\");\n\n  const handleSubmit = async (): Promise<void> => {\n    setStreamingPatch(\"\u23f3 Working...\");\n    setParsedPatch(null);\n\n    try {\n      const res = await fetch(`${API_ROOT}/ask/codex_stream`, {\n        method: \"POST\",\n        headers: { \"Content-Type\": \"application/json\" },\n        body: JSON.stringify({ question: prompt, context: code }),\n      });\n\n      const reader = res.body?.getReader();\n      const decoder = new TextDecoder();\n      let patch = \"\";\n\n      while (true) {\n        const { value, done } = await reader!.read();\n        if (done) break;\n        patch += decoder.decode(value, { stream: true });\n        setStreamingPatch(patch);\n      }\n\n      const fileMatch = patch.match(/File:\\s*(.*)/);\n      const reasonMatch = patch.match(/Reason:\\s*([\\s\\S]*)/);\n      const patchStart = patch.indexOf(\"Patch:\");\n      const reasonStart = patch.indexOf(\"Reason:\");\n\n      const extracted = {\n        file: fileMatch?.[1]?.trim() || \"\",\n        patch: patchStart !== -1 && reasonStart !== -1 ? patch.slice(patchStart + 6, reasonStart).trim() : \"\",\n        reason: reasonMatch?.[1]?.trim() || \"\"\n      };\n\n      if (extracted.file && extracted.patch) setParsedPatch(extracted);\n    } catch (err) {\n      setStreamingPatch(\"\u274c Error while generating patch: \" + String(err));\n    }\n  };\n\n  const applyPatch = async (): Promise<void> => {\n    if (!parsedPatch) return;\n    setStatus(toMDString(\"\u23f3 Applying patch...\"));\n\n    try {\n      const res = await fetch(`${API_ROOT}/codex/apply_patch`, {\n        method: \"POST\",\n        headers: { \"Content-Type\": \"application/json\" },\n        body: JSON.stringify({\n          target_file: parsedPatch.file,\n          patch: parsedPatch.patch,\n          reason: parsedPatch.reason\n        })\n      });\n\n      if (res.ok) {\n        setStatus(toMDString(\"\u2705 Patch applied successfully.\"));\n      } else {\n        const err = await res.text();\n        setStatus(toMDString(\"\u274c Failed to apply patch: \" + err));\n      }\n    } catch (err) {\n      setStatus(toMDString(\"\u274c Patch request failed: \" + String(err)));\n    }\n  };\n\n  if (typeof status !== \"string\") {\n    console.log(\"DEBUG 418:\", typeof status, status);\n  }\n\n  return (\n    <div className=\"p-6 space-y-4\">\n      <h1 className=\"text-2xl font-bold\">\ud83e\udde0 Codex \u2014 Code Editing Agent</h1>\n\n      <CodexEditor code={code} setCode={setCode} />\n      <CodexPromptBar prompt={prompt} setPrompt={setPrompt} onSubmit={handleSubmit} />\n      <CodexPatchView patch={streamingPatch} />\n\n      {parsedPatch && (\n        <div className=\"space-y-2\">\n          <Button onClick={applyPatch}>\u2705 Approve & Apply Patch</Button>\n          {status && (\n            <div className=\"text-sm text-muted-foreground\">\n              <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n                <SafeMarkdown>{toMDString(status)}</SafeMarkdown>\n              </div>\n            </div>\n          )}\n        </div>\n      )}\n    </div>\n  );\n};\n\nexport default CodexPage;", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3841, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9ff60f9e-9fb9-4443-96b9-ad4d016a0c75": {"__data__": {"id_": "9ff60f9e-9fb9-4443-96b9-ad4d016a0c75", "embedding": null, "metadata": {"file_path": "/app/frontend/src/app/control/page.tsx", "file_name": "page.tsx", "file_size": 893, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "084fd30d-cb52-42a1-96a1-8dfbdf044117", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/app/control/page.tsx", "file_name": "page.tsx", "file_size": 893, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "eaef09f432e3d59b93ebe1628fa3fa40e03c0fe1e883d3e00bc708735ec3b5c0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: frontend/src/app/control/page.tsx\n// Purpose: Admin control dashboard with patch queue, logs, and memory panels\n\nimport ActionQueuePanel from \"@/components/ActionQueue/ActionQueuePanel\";\nimport LogsPanel from \"@/components/LogsPanel/LogsPanel\";\nimport MemoryPanel from \"@/components/MemoryPanel\";\n\nexport default function ControlPage() {\n  return (\n    <main className=\"p-6 space-y-6\">\n      <h1 className=\"text-2xl font-bold mb-4\">\ud83e\udde0 Relay Control Center</h1>\n\n      <section>\n        <h2 className=\"text-xl font-semibold mb-2\">\ud83d\udcdd Pending Actions</h2>\n        <ActionQueuePanel />\n      </section>\n\n      <section>\n        <h2 className=\"text-xl font-semibold mb-2\">\ud83d\udcc4 Execution Logs</h2>\n        <LogsPanel />\n      </section>\n\n      <section>\n        <h2 className=\"text-xl font-semibold mb-2\">\ud83e\uddec Memory Log</h2>\n        <MemoryPanel />\n      </section>\n    </main>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 880, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a02055be-f10d-4d4a-ba5f-aaba1cdb9a4d": {"__data__": {"id_": "a02055be-f10d-4d4a-ba5f-aaba1cdb9a4d", "embedding": null, "metadata": {"file_path": "/app/frontend/src/app/dashboard/page.tsx", "file_name": "page.tsx", "file_size": 173, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "79388ba0-f2e0-4d4d-9d06-c0fcfcc9693c", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/app/dashboard/page.tsx", "file_name": "page.tsx", "file_size": 173, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "7bdddbe36c7e98ad5e9d3db8114786221ba13e3fa15935045bdf5458bce83c53", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: frontend/src/app/dashboard/page.tsx\n\nimport Dashboard from \"@/components/dashboard/Dashboard\";\n\nexport default function DashboardPage() {\n  return <Dashboard />;\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 172, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "80f9cb49-d9a3-47c4-8bc6-23531d4561de": {"__data__": {"id_": "80f9cb49-d9a3-47c4-8bc6-23531d4561de", "embedding": null, "metadata": {"file_path": "/app/frontend/src/app/docs/page.tsx", "file_name": "page.tsx", "file_size": 231, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "72a7d590-6854-46a3-81dd-1fe3c2a66dd2", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/app/docs/page.tsx", "file_name": "page.tsx", "file_size": 231, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "079e64bd1f2d1e7146b25311c4786fbf05a5763009e2439e2f834e1eea6ca4cf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: src/app/docs/page.tsx\n// Purpose: Route-level page that renders the full DocsViewer\n\n'use client'\n\nimport DocsViewer from '@/components/DocsViewer/DocsViewer'\n\nexport default function DocsPage() {\n  return <DocsViewer />\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 231, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "168ba6fe-c97e-4277-b311-ef14f3708261": {"__data__": {"id_": "168ba6fe-c97e-4277-b311-ef14f3708261", "embedding": null, "metadata": {"file_path": "/app/frontend/src/app/layout.tsx", "file_name": "layout.tsx", "file_size": 514, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "bd8404cc-a24b-4070-bfba-aaf44f3b1c25", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/app/layout.tsx", "file_name": "layout.tsx", "file_size": 514, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "fe780f1687163cc3a581ee50720fc550e3518daba0cfe20b71dfc690e00d7fa6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import './globals.css';\nimport { ReactNode } from 'react';\nimport Sidebar from '@/components/Sidebar/Sidebar';\n\nexport default function RootLayout({ children }: { children: ReactNode }) {\n  return (\n    <html lang=\"en\">\n      <body className=\"min-h-screen font-sans bg-background text-foreground\">\n        <div className=\"flex h-screen\">\n          <Sidebar />\n          <main className=\"flex-1 overflow-auto p-6 bg-gray-50\">\n            {children}\n          </main>\n        </div>\n      </body>\n    </html>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 513, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2b52d66a-71c7-4892-b9c1-e5d6c53acff9": {"__data__": {"id_": "2b52d66a-71c7-4892-b9c1-e5d6c53acff9", "embedding": null, "metadata": {"file_path": "/app/frontend/src/app/logs/page.tsx", "file_name": "page.tsx", "file_size": 482, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b3b15f81-73e1-4060-89ce-b7889cdc75b8", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/app/logs/page.tsx", "file_name": "page.tsx", "file_size": 482, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "02fb805d3d98149d4c1ce77e4824aaed74a34e37929262ea9dba49aa7ac61450", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: src/app/logs/page.tsx\n\nimport LogsPanel from \"@/components/LogsPanel/LogsPanel\";\n\nexport default function LogsPage() {\n  return (\n    <main className=\"max-w-3xl mx-auto py-8 px-2\">\n      <h1 className=\"text-2xl font-bold mb-6\">\ud83d\udcdc System Logs</h1>\n      <p className=\"mb-4 text-muted-foreground\">\n        View all system logs, errors, and events. Use filters, search, and export features for auditing and troubleshooting.\n      </p>\n      <LogsPanel />\n    </main>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 478, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "25d92bbf-5613-483c-ba02-fc330476fbad": {"__data__": {"id_": "25d92bbf-5613-483c-ba02-fc330476fbad", "embedding": null, "metadata": {"file_path": "/app/frontend/src/app/metricschart/page.tsx", "file_name": "page.tsx", "file_size": 271, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f8b3b48d-520d-4795-87a7-ad007a31be3d", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/app/metricschart/page.tsx", "file_name": "page.tsx", "file_size": 271, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "a70853a76912ecd065718226adde386c2832254fd6f706ff147062e04befa9aa", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'use client'\n\nimport MetricsChart from '@/components/MetricsCharts/MetricsCharts'\n\nexport default function MetricsChartPage() {\n  return (\n    <main className=\"p-6 space-y-6\">\n      <h1 className=\"text-2xl font-bold\">Metrics</h1>\n      <MetricsChart />\n    </main>\n  )\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 270, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ffd9b4bc-b29e-4ac7-a5c2-4accf1a8a6d0": {"__data__": {"id_": "ffd9b4bc-b29e-4ac7-a5c2-4accf1a8a6d0", "embedding": null, "metadata": {"file_path": "/app/frontend/src/app/page.tsx", "file_name": "page.tsx", "file_size": 1969, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "799e5c43-9902-4e43-be76-114a338d915a", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/app/page.tsx", "file_name": "page.tsx", "file_size": 1969, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "52326aef3dc9e4e19ec82148f051fe9a8505c568e101c379b15af4c47e90a2d9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: src/app/page.tsx\n// Purpose: Wildfire Ranch Command Center UI (Puck-free)\n\n'use client'\n\nimport Image from 'next/image'\n\nexport default function HomePage() {\n  const statusColors = ['red', 'green', 'orange', 'green']\n\n  return (\n    <main className=\"flex-1 grid grid-cols-4 grid-rows-2 gap-4 p-4 bg-gray-50\">\n      {/* Top Left Panel */}\n      <div className=\"col-span-3 row-span-1 bg-white rounded-xl shadow p-4\">\n        <h3 className=\"font-semibold mb-2\">Top Left Panel</h3>\n        <p>Content goes here\u2026</p>\n      </div>\n\n      {/* Agent Status */}\n      <div className=\"col-span-1 row-span-1 bg-white rounded-xl shadow p-4\">\n        <h4 className=\"font-bold flex items-center gap-2 mb-2\">\n          <Image src=\"/PlannerCop.png\" alt=\"agent\" width={20} height={20} />\n          Agent Status\n        </h4>\n        <ul className=\"text-sm space-y-1\">\n          {statusColors.map((color, i) => (\n            <li key={i} className=\"flex items-center gap-2\">\n              <span className={`w-3 h-3 rounded-full bg-${color}-500`} />\n              Service {i + 1}\n            </li>\n          ))}\n        </ul>\n      </div>\n\n      {/* Bottom Left Panel */}\n      <div className=\"col-span-3 row-span-1 bg-white rounded-xl shadow p-4\">\n        <h3 className=\"font-semibold mb-2\">Bottom Left Panel</h3>\n        <p>More content here\u2026</p>\n      </div>\n\n      {/* Shack Status */}\n      <div className=\"col-span-1 row-span-1 bg-white rounded-xl shadow p-4\">\n        <h4 className=\"font-bold flex items-center gap-2 mb-2\">\n          <Image src=\"/WildfireMang.png\" alt=\"shack\" width={20} height={20} />\n          Shack Status\n        </h4>\n        <ul className=\"text-sm space-y-1\">\n          {statusColors.map((color, i) => (\n            <li key={i} className=\"flex items-center gap-2\">\n              <span className={`w-3 h-3 rounded-full bg-${color}-500`} />\n              Service {i + 1}\n            </li>\n          ))}\n        </ul>\n      </div>\n    </main>\n  )\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1964, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1a01ca20-d51c-4323-8003-178197279757": {"__data__": {"id_": "1a01ca20-d51c-4323-8003-178197279757", "embedding": null, "metadata": {"file_path": "/app/frontend/src/app/settings/page.tsx", "file_name": "page.tsx", "file_size": 353, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0d9492d0-368b-4d83-841d-9dbf1f0ec05a", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/app/settings/page.tsx", "file_name": "page.tsx", "file_size": 353, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "fe9cf35963bf4592ce87180a022eacdf14a201cc9982cb18918f1a1002fef588", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: frontend/src/app/settings/page.tsx\n\nexport default function SettingsPage() {\n  return (\n    <main className=\"p-6\">\n      <h1 className=\"text-2xl font-bold mb-4\">\u2699\ufe0f Settings</h1>\n      <p className=\"text-muted-foreground\">Configure your Relay experience here.</p>\n      {/* Add settings forms, toggles, API keys, etc. */}\n    </main>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 348, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "97b597d8-b8c7-4da6-9750-3aae1f481788": {"__data__": {"id_": "97b597d8-b8c7-4da6-9750-3aae1f481788", "embedding": null, "metadata": {"file_path": "/app/frontend/src/app/status/page.tsx", "file_name": "page.tsx", "file_size": 284, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "db5ec47e-45bc-4a07-aed9-aa600aa420e0", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/app/status/page.tsx", "file_name": "page.tsx", "file_size": 284, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "7c519adb900ba45466c4d20ee20a32a27de073c1e9d20b25db4b77ccfde785de", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: frontend/src/app/status/page.tsx\n\nimport StatusPanel from \"@/components/StatusPanel\";\n\nexport default function StatusPage() {\n  return (\n    <main className=\"p-6\">\n      <h1 className=\"text-2xl font-bold mb-4\">\ud83d\udcca System Status</h1>\n      <StatusPanel />\n    </main>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 280, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "83b68592-9154-4fa9-8b24-ddf74037695b": {"__data__": {"id_": "83b68592-9154-4fa9-8b24-ddf74037695b", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/ActionQueue/ActionQueuePanel.tsx", "file_name": "ActionQueuePanel.tsx", "file_size": 12602, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ff46f666-a791-4054-b5a3-427bcc10fad8", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/ActionQueue/ActionQueuePanel.tsx", "file_name": "ActionQueuePanel.tsx", "file_size": 12602, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "68cc58f4894b35af1a440d98270c7749d9a4b428bb5ca4b47ffae6b2055f7c5f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "dfe8c128-0999-4355-9c64-c06cf45cb4b6", "node_type": "1", "metadata": {}, "hash": "fa741834527ccf3b6307651c6d4d239e15838bfa37341b0b529b3c9d29cd44c6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: frontend/src/components/ActionQueuePanel.tsx\n// Purpose: Superpanel for agent patch/action queue with approve/deny, context diff, and deep audit.\n//          All rationale, diff, content, and context fields are rendered with SafeMarkdown for bulletproof safety.\n\n\"use client\";\n\nimport { useEffect, useState, useCallback } from \"react\";\nimport { Button } from \"@/components/ui/button\";\nimport { Card, CardContent } from \"@/components/ui/card\";\nimport { Badge } from \"@/components/ui/badge\";\nimport { Textarea } from \"@/components/ui/textarea\";\nimport { API_ROOT } from \"@/lib/api\";\nimport SafeMarkdown from \"@/components/SafeMarkdown\";\nimport { toMDString } from \"@/lib/toMDString\";\n\ntype ActionStatus = \"pending\" | \"approved\" | \"denied\";\n\ntype HistoryEntry = {\n  timestamp: string;\n  status: ActionStatus;\n  user?: string;\n  comment?: string;\n};\n\ntype Action = {\n  id: string;\n  timestamp: string;\n  status: ActionStatus;\n  action: {\n    type: string;\n    path?: string;\n    content?: string;\n    diff?: string;\n    context?: string;\n    rationale?: string;\n  };\n  history?: HistoryEntry[];\n};\n\n\nexport default function ActionQueuePanel() {\n  const [actions, setActions] = useState<Action[]>([]);\n  const [processing, setProcessing] = useState<string | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [loading, setLoading] = useState<boolean>(true);\n  const [showContext, setShowContext] = useState<{ [id: string]: boolean }>({});\n  const [showHistory, setShowHistory] = useState<{ [id: string]: boolean }>({});\n  const [comment, setComment] = useState<{ [id: string]: string }>({});\n  const [compareContextId, setCompareContextId] = useState<string | null>(null);\n  const [autoRefresh, setAutoRefresh] = useState(true);\n\n  const API_KEY = process.env.NEXT_PUBLIC_API_KEY || \"\";\n  const USER_ID = \"bret\";\n\n  const fetchQueue = useCallback(async () => {\n    setLoading(true);\n    setError(null);\n    try {\n      const res = await fetch(`${API_ROOT}/control/list_queue`, {\n        headers: {\n          \"X-API-Key\": API_KEY,\n          \"X-User-Id\": USER_ID\n        }\n      });\n      if (!res.ok) throw new Error(\"Bad response\");\n      const data = await res.json();\n      const mapped = (data.actions || []).map((a: Action) => ({\n        ...a,\n        action: {\n          ...a.action,\n          rationale: toMDString(a.action?.rationale),\n          diff: toMDString(a.action?.diff),\n          context: toMDString(a.action?.context),\n          content: toMDString(a.action?.content)\n        },\n        history: Array.isArray(a.history)\n          ? a.history.map(h => ({\n              ...h,\n              comment: toMDString(h.comment)\n            }))\n          : a.history\n      }));\n      setActions(mapped);\n    } catch (err) {\n      console.error(\"Queue fetch failed\", err);\n      setError(\"Failed to fetch action queue.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2859, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "dfe8c128-0999-4355-9c64-c06cf45cb4b6": {"__data__": {"id_": "dfe8c128-0999-4355-9c64-c06cf45cb4b6", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/ActionQueue/ActionQueuePanel.tsx", "file_name": "ActionQueuePanel.tsx", "file_size": 12602, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ff46f666-a791-4054-b5a3-427bcc10fad8", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/ActionQueue/ActionQueuePanel.tsx", "file_name": "ActionQueuePanel.tsx", "file_size": 12602, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "68cc58f4894b35af1a440d98270c7749d9a4b428bb5ca4b47ffae6b2055f7c5f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "83b68592-9154-4fa9-8b24-ddf74037695b", "node_type": "1", "metadata": {"file_path": "/app/frontend/src/components/ActionQueue/ActionQueuePanel.tsx", "file_name": "ActionQueuePanel.tsx", "file_size": 12602, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "d9ba62b5c10d0d91b338162ffddded8f2787162539afc2b7e4fd6b74ce596183", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "81b6ddca-d136-40de-8fac-3957ac39b391", "node_type": "1", "metadata": {}, "hash": "51cdb2a56bdfa9b0fbe3ae28ce2ed81e46d64ce3a6b266bd42872bd9d631d0e3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "a.history.map(h => ({\n              ...h,\n              comment: toMDString(h.comment)\n            }))\n          : a.history\n      }));\n      setActions(mapped);\n    } catch (err) {\n      console.error(\"Queue fetch failed\", err);\n      setError(\"Failed to fetch action queue.\");\n    }\n    setLoading(false);\n  }, [API_KEY, USER_ID]);\n\n  const updateStatus = async (id: string, action: \"approve\" | \"deny\") => {\n    setProcessing(id + action);\n    try {\n      const res = await fetch(`${API_ROOT}/control/${action}_action`, {\n        method: \"POST\",\n        headers: {\n          \"Content-Type\": \"application/json\",\n          \"X-API-Key\": API_KEY,\n          \"X-User-Id\": USER_ID\n        },\n        body: JSON.stringify({ id, comment: comment[id] || \"\" })\n      });\n      if (!res.ok) throw new Error(`${action} failed`);\n      await fetchQueue();\n      setComment((prev) => ({ ...prev, [id]: \"\" }));\n    } catch (err) {\n      console.error(`Action ${action} failed`, err);\n      setError(`Failed to ${action} action.`);\n    }\n    setProcessing(null);\n  };\n\n  useEffect(() => {\n    fetchQueue();\n    if (!autoRefresh) return;\n    const interval = setInterval(fetchQueue, 15000);\n    return () => clearInterval(interval);\n  }, [fetchQueue, autoRefresh]);\n\n  const getActionById = (id: string) => actions.find(a => a.id === id);\n\n  for (const a of actions) {\n    if (a.action.rationale && typeof a.action.rationale !== \"string\") {\n      console.log(\"DEBUG 418:\", typeof a.action.rationale, a.action.rationale);\n    }\n    if (a.action.diff && typeof a.action.diff !== \"string\") {\n      console.log(\"DEBUG 418:\", typeof a.action.diff, a.action.diff);\n    }\n    if (typeof a.action.content !== \"string\") {\n      console.log(\"DEBUG 418:\", typeof a.action.content, a.action.content);\n    }\n    if (a.action.context && typeof a.action.context !== \"string\") {\n      console.log(\"DEBUG 418:\", typeof a.action.context, a.action.context);\n    }\n    if (Array.isArray(a.history)) {\n      for (const h of a.history) {\n        if (h.comment && typeof h.comment !== \"string\") {\n          console.log(\"DEBUG 418:\", typeof h.comment, h.comment);\n        }\n      }\n    }\n  }\n\n  if (error) return <p className=\"text-red-500\">{error}</p>;\n  if (loading) return <p className=\"text-muted-foreground\">Loading queue...</p>;\n  if (!actions.length) return <p className=\"text-muted-foreground\">No actions in queue.</p>;\n\n  return (\n    <div className=\"space-y-4\">\n      <div className=\"flex gap-2 mb-4 items-center\">\n        <Button variant={autoRefresh ? \"default\" : \"outline\"} onClick={() => setAutoRefresh(!autoRefresh)}>\n          {autoRefresh ? \"Auto-Refresh ON\" : \"Auto-Refresh OFF\"}\n        </Button>\n        <span className=\"text-xs text-gray-400\">Queue updates every 15s</span>\n      </div>\n      {actions.map((a) => (\n        <Card key={a.id}>\n          <CardContent className=\"p-4 space-y-2\">\n            <div className=\"flex items-center gap-2 text-sm font-mono text-muted-foreground\">\n              #{a.id.slice(0, 8)} \u2022 {a.timestamp}\n              <Badge variant={\n                a.status === \"approved\" ? \"success\" :\n                a.status === \"denied\" ? \"destructive\" : \"secondary\"\n              }>\n                {a.status}\n              </Badge>\n            </div>\n\n            <div className=\"text-sm\">\n              <strong>Type:</strong> {a.action.type}\n              {a.action.path && <span className=\"ml-2\"><strong>Path:</strong> {a.action.path}</span>}\n            </div>\n\n            {a.action.rationale && (\n              <div className=\"text-xs text-blue-800 mt-1 italic\">\n                <strong>Why?</strong>{\" \"}\n                <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n                  <SafeMarkdown>{toMDString(a.action.rationale)}</SafeMarkdown>\n                </div>\n              </div>\n            )}\n\n            {a.action.diff ?", "mimetype": "text/plain", "start_char_idx": 2584, "end_char_idx": 6450, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "81b6ddca-d136-40de-8fac-3957ac39b391": {"__data__": {"id_": "81b6ddca-d136-40de-8fac-3957ac39b391", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/ActionQueue/ActionQueuePanel.tsx", "file_name": "ActionQueuePanel.tsx", "file_size": 12602, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ff46f666-a791-4054-b5a3-427bcc10fad8", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/ActionQueue/ActionQueuePanel.tsx", "file_name": "ActionQueuePanel.tsx", "file_size": 12602, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "68cc58f4894b35af1a440d98270c7749d9a4b428bb5ca4b47ffae6b2055f7c5f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "dfe8c128-0999-4355-9c64-c06cf45cb4b6", "node_type": "1", "metadata": {"file_path": "/app/frontend/src/components/ActionQueue/ActionQueuePanel.tsx", "file_name": "ActionQueuePanel.tsx", "file_size": 12602, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "d394638e4301c094dae1fff3f859810e2309a396c83ff56bb4bd47e1e56474a2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3218b662-4297-472b-820a-57e402a0495b", "node_type": "1", "metadata": {}, "hash": "bf12b638bb8fdc9f1c48e18bfaf33884ce294fc999841b19a8c22fb56cd9a77c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"success\" :\n                a.status === \"denied\" ? \"destructive\" : \"secondary\"\n              }>\n                {a.status}\n              </Badge>\n            </div>\n\n            <div className=\"text-sm\">\n              <strong>Type:</strong> {a.action.type}\n              {a.action.path && <span className=\"ml-2\"><strong>Path:</strong> {a.action.path}</span>}\n            </div>\n\n            {a.action.rationale && (\n              <div className=\"text-xs text-blue-800 mt-1 italic\">\n                <strong>Why?</strong>{\" \"}\n                <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n                  <SafeMarkdown>{toMDString(a.action.rationale)}</SafeMarkdown>\n                </div>\n              </div>\n            )}\n\n            {a.action.diff ? (\n              <details>\n                <summary className=\"cursor-pointer text-xs text-blue-700\">View Diff</summary>\n                <div className=\"bg-muted p-2 rounded text-xs overflow-auto whitespace-pre-wrap\">\n                  <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n                    <SafeMarkdown>{toMDString(a.action.diff)}</SafeMarkdown>\n                  </div>\n                </div>\n              </details>\n            ) : (\n              <div className=\"bg-muted p-2 rounded text-sm overflow-auto whitespace-pre-wrap\">\n                <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n                  <SafeMarkdown>{toMDString(a.action.content?.slice(0, 500) || \"No content\")}</SafeMarkdown>\n                </div>\n              </div>\n            )}\n\n            {a.action.context && (\n              <Button\n                size=\"sm\"\n                variant=\"outline\"\n                className=\"my-2\"\n                onClick={() => setShowContext(prev => ({ ...prev, [a.id]: !prev[a.id] }))}\n              >\n                {showContext[a.id] ? \"Hide Agent Context\" : \"Show Agent Context\"}\n              </Button>\n            )}\n\n            {showContext[a.id] && a.action.context && (\n              <div className=\"bg-gray-100 p-2 rounded text-xs max-h-32 overflow-auto mt-2\">\n                <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n                  <SafeMarkdown>{toMDString(a.action.context)}</SafeMarkdown>\n                </div>\n              </div>\n            )}\n\n            {/* Context diff compare */}\n            <div className=\"mt-2\">\n              <label className=\"text-xs mr-2\">Compare context to:</label>\n              <select\n                className=\"border rounded px-1 py-0.5 text-xs\"\n                value={compareContextId === a.id ? \"\" : compareContextId || \"\"}\n                onChange={e => setCompareContextId(e.target.value || null)}\n              >\n                <option value=\"\">Select previous action\u2026</option>\n                {actions.filter(other => other.id !== a.id && other.action.context).map(other => (\n                  <option key={other.id} value={other.id}>\n                    #{other.id.slice(0, 8)} {other.action.type}\n                  </option>\n                ))}\n              </select>\n              {compareContextId && getActionById(compareContextId) && a.action.context && (\n                <details>\n                  <summary className=\"cursor-pointer text-xs text-blue-700 mt-1\">Show Context Diff</summary>\n                  <div className=\"bg-yellow-100 p-2 rounded text-xs overflow-auto whitespace-pre-wrap\">\n                    <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n                      <SafeMarkdown>\n                        {toMDString(\n                          diffContext(a.action.context, getActionById(compareContextId)?.action.context || \"\")\n                        )}\n                      </SafeMarkdown>\n                    </div>\n                  </div>\n                </details>\n              )}\n            </div>\n\n            <Button\n              size=\"sm\"\n              variant=\"ghost\"\n              className=\"my-2\"\n              onClick={() => setShowHistory(prev => ({ ...prev, [a.id]: !prev[a.id] }))}\n            >\n              {showHistory[a.id] ?", "mimetype": "text/plain", "start_char_idx": 5673, "end_char_idx": 9809, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3218b662-4297-472b-820a-57e402a0495b": {"__data__": {"id_": "3218b662-4297-472b-820a-57e402a0495b", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/ActionQueue/ActionQueuePanel.tsx", "file_name": "ActionQueuePanel.tsx", "file_size": 12602, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ff46f666-a791-4054-b5a3-427bcc10fad8", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/ActionQueue/ActionQueuePanel.tsx", "file_name": "ActionQueuePanel.tsx", "file_size": 12602, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "68cc58f4894b35af1a440d98270c7749d9a4b428bb5ca4b47ffae6b2055f7c5f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "81b6ddca-d136-40de-8fac-3957ac39b391", "node_type": "1", "metadata": {"file_path": "/app/frontend/src/components/ActionQueue/ActionQueuePanel.tsx", "file_name": "ActionQueuePanel.tsx", "file_size": 12602, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "b58c447deecc2a6cb1beb13d20b451919f14356fb992f2aa61e576be1db039a4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"Hide History\" : \"Show History\"}\n            </Button>\n\n            {showHistory[a.id] && Array.isArray(a.history) && (\n              <ul className=\"bg-gray-50 p-2 rounded text-xs mt-1 max-h-32 overflow-auto border\">\n                {a.history.map((h, i) => (\n                  <li key={i}>\n                    <span className=\"font-mono\">{h.timestamp}</span> \u2022 <Badge>{h.status}</Badge>\n                    {h.user && <span className=\"ml-2 text-blue-700\">{h.user}</span>}\n                    {h.comment && (\n                      <span className=\"ml-2 italic\">\n                        <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n                          <SafeMarkdown>{toMDString(h.comment)}</SafeMarkdown>\n                        </div>\n                      </span>\n                    )}\n                  </li>\n                ))}\n              </ul>\n            )}\n\n            {a.status === \"pending\" && (\n              <form className=\"flex flex-col gap-2 mt-2\" onSubmit={e => e.preventDefault()}>\n                <Textarea\n                  id={`comment-${a.id}`}\n                  name={`comment-${a.id}`}\n                  placeholder=\"Optional comment (why approve/deny?)\"\n                  value={comment[a.id] || \"\"}\n                  onChange={e =>\n                    setComment(prev => ({ ...prev, [a.id]: e.target.value }))\n                  }\n                  className=\"text-xs\"\n                  rows={2}\n                />\n                <div className=\"flex gap-2\">\n                  <Button\n                    variant=\"default\"\n                    onClick={() => updateStatus(a.id, \"approve\")}\n                    disabled={processing === a.id + \"approve\"}\n                    type=\"button\"\n                  >\n                    {processing === a.id + \"approve\" ? \"Approving...\" : \"Approve\"}\n                  </Button>\n                  <Button\n                    variant=\"destructive\"\n                    onClick={() => updateStatus(a.id, \"deny\")}\n                    disabled={processing === a.id + \"deny\"}\n                    type=\"button\"\n                  >\n                    {processing === a.id + \"deny\" ? \"Denying...\" : \"Deny\"}\n                  </Button>\n                </div>\n              </form>\n            )}\n          </CardContent>\n        </Card>\n      ))}\n    </div>\n  );\n\n  // Simple line diff for context comparison\n  function diffContext(ctx1: string, ctx2: string): string {\n    const lines1 = new Set((ctx1 || \"\").split(\"\\n\"));\n    const lines2 = new Set((ctx2 || \"\").split(\"\\n\"));\n    let out = \"\";\n    for (const l of lines1) {\n      if (!lines2.has(l)) out += `+ ${l}\\n`;\n    }\n    for (const l of lines2) {\n      if (!lines1.has(l)) out += `- ${l}\\n`;\n    }\n    return out || \"No differences.\";\n  }\n}", "mimetype": "text/plain", "start_char_idx": 9810, "end_char_idx": 12595, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5a0289f4-6019-4bf7-8327-9bb50aebfd55": {"__data__": {"id_": "5a0289f4-6019-4bf7-8327-9bb50aebfd55", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/AskAgent/ChatMessage.tsx", "file_name": "ChatMessage.tsx", "file_size": 894, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9d161425-b64a-45c6-a03e-fc42d622814e", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/AskAgent/ChatMessage.tsx", "file_name": "ChatMessage.tsx", "file_size": 894, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "3c5f9136da0e21dc802e102860ed4d1a3de362b30b721c028f0f75e106408d15", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: components/AskAgent/ChatMessage.tsx\n// Purpose: Renders a single chat message, always string-coercing content for SafeMarkdown.\n\nimport React from \"react\";\nimport SafeMarkdown from \"@/components/SafeMarkdown\"; // Use the shared safe renderer\nimport { toMDString } from \"@/lib/toMDString\";\n\ntype Props = {\n  role: \"user\" | \"assistant\";\n  content: unknown; // Accept anything, always coerce to string for safety\n};\n\n\nexport default function ChatMessage({ role, content }: Props) {\n  const alignClass =\n    role === \"user\" ? \"text-right text-blue-700\" : \"text-left text-green-700\";\n\n  if (typeof content !== \"string\") {\n    console.log(\"DEBUG 418:\", typeof content, content);\n  }\n\n  return (\n    <div className={alignClass}>\n      <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n        <SafeMarkdown>{toMDString(content)}</SafeMarkdown>\n      </div>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 893, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "df5f57c9-ffa8-4ecc-a2af-ccad2855d00c": {"__data__": {"id_": "df5f57c9-ffa8-4ecc-a2af-ccad2855d00c", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/AskAgent/ChatWindow.tsx", "file_name": "ChatWindow.tsx", "file_size": 1683, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3eafdc2e-75e9-49c8-8bc3-d517186c369b", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/AskAgent/ChatWindow.tsx", "file_name": "ChatWindow.tsx", "file_size": 1683, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "afc965a8d1985d51d97478128c6a48eb40e6e19283b1084d8f96247a2d811537", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: components/AskEcho/ChatWindow.tsx\n// Purpose: Chat window for Ask Echo UI using /mcp/run pipeline\n// Updated: 2025-07-01\n\n\"use client\";\n\nimport ChatMessage from \"./ChatMessage\";\nimport InputBar from \"./InputBar\";\nimport { useAskEcho } from \"./useAskEcho\";\nimport { toMDString } from \"@/lib/toMDString\";\n\nexport default function ChatWindow() {\n  // Unified chat state and actions from the custom hook\n  const {\n    input,\n    setInput,\n    messages,\n    sendMessage,\n    loading,\n    bottomRef,\n  } = useAskEcho();\n\n  const renderedMessages = messages.map((msg, i) => {\n    if (typeof msg.content !== \"string\") {\n      console.log(\"DEBUG 418:\", typeof msg.content, msg.content);\n    }\n    return (\n      <>\n        <ChatMessage key={i} role={msg.role} content={toMDString(msg.content)} />\n      </>\n    );\n  });\n\n  return (\n    <div className=\"w-full max-w-2xl mx-auto min-h-screen flex flex-col\">\n      {/* Header */}\n      <h1 className=\"text-3xl font-bold my-4\">Ask Echo</h1>\n\n      {/* Message List */}\n      <div className=\"flex-1 space-y-2 overflow-y-auto border rounded-xl p-4 bg-muted\">\n        {renderedMessages}\n        {loading && (\n          <div className=\"text-left text-green-700 animate-pulse\">\n            Echo is thinking\u2026\n          </div>\n        )}\n        <div ref={bottomRef} />\n      </div>\n\n      {/* Input Bar */}\n      <InputBar\n        value={input}\n        onChange={setInput}\n        onSend={sendMessage}\n        loading={loading}\n      />\n\n      {/* Keyboard shortcut hint */}\n      <div className=\"text-xs text-gray-400 text-center mt-2\">\n        Tip: Press <code>Enter</code> to send. Shift+Enter for newline.\n      </div>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1680, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "675fef89-ecfe-45c4-98e7-fcf80449f3be": {"__data__": {"id_": "675fef89-ecfe-45c4-98e7-fcf80449f3be", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/AskAgent/InputBar.tsx", "file_name": "InputBar.tsx", "file_size": 1460, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d8e830eb-78b8-46ce-b5c5-fdad03186e2a", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/AskAgent/InputBar.tsx", "file_name": "InputBar.tsx", "file_size": 1460, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "9a517bbe2f1f95b4d774fbcedee2db6b5ead4bb53c3dbd058b0ef7e7e9073f75", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: components/AskAgent/InputBar.tsx\n// Purpose: Text input + send button for AskAgent chat UI\n// Updated: 2025-06-30\n\nimport React from \"react\";\n\ntype Props = {\n  value: string;                 // Input value (controlled)\n  onChange: (val: string) => void; // Handle text changes\n  onSend: () => void;              // Called to send message\n  loading: boolean;                // Loading state (disables input/button)\n};\n\nconst InputBar: React.FC<Props> = ({ value, onChange, onSend, loading }) => {\n  return (\n    <form\n      className=\"flex items-center gap-2 mt-4\"\n      autoComplete=\"off\"\n      onSubmit={(e) => {\n        e.preventDefault();\n        if (!loading && value.trim()) onSend();\n      }}\n    >\n      <input\n        type=\"text\"\n        className=\"flex-1 rounded border px-3 py-2\"\n        placeholder=\"Type your question\u2026\"\n        value={value}\n        onChange={(e) => onChange(e.target.value)}\n        disabled={loading}\n        name=\"echo-message\"\n        id=\"echo-message\"\n        onKeyDown={(e) => {\n          if (e.key === \"Enter\" && !e.shiftKey && value.trim() && !loading) {\n            e.preventDefault();\n            onSend();\n          }\n        }}\n        autoFocus\n      />\n      <button\n        type=\"submit\"\n        className=\"bg-blue-600 text-white rounded px-4 py-2\"\n        disabled={loading || !value.trim()}\n      >\n        {loading ? \"Sending\u2026\" : \"Send\"}\n      </button>\n    </form>\n  );\n};\n\nexport default InputBar;", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1455, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1a54d072-d80b-4e68-a9f2-0fd5a17c2185": {"__data__": {"id_": "1a54d072-d80b-4e68-a9f2-0fd5a17c2185", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/AskAgent/hooks.ts", "file_name": "hooks.ts", "file_size": 3620, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "21bb60dc-2ddc-433f-909a-df6d6cd7fe8b", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/AskAgent/hooks.ts", "file_name": "hooks.ts", "file_size": 3620, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "6e6eda4a3d3b829dd49a5b057d584ca6c47a270080e1ca9322196263cdfc3959", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: frontend/src/components/AskAgent/hooks.ts\n// Purpose: Reusable React hook for AskAgent chat\u2014now wired to /mcp/run for agent/critic orchestration\n//          Ensures ALL message fields for markdown rendering are always strings (prevents React #418).\n// Updated: 2025-07-01\n\nimport { useState } from \"react\";\nimport { API_ROOT } from \"@/lib/api\";\nimport { toMDString } from \"@/lib/toMDString\";\n\n// Message interface for chat history\nexport interface Message {\n  user: string;   // User's input\n  agent: string;  // Agent's reply (ALWAYS stringified)\n  context?: string; // (ALWAYS stringified if present)\n  action?: { type: string; payload: unknown };\n  id?: string;\n  status?: \"pending\" | \"approved\" | \"denied\";\n}\n\n\n// Main hook for agent chat\nexport function useAskAgent(userId: string) {\n  const [messages, setMessages] = useState<Message[]>([]);\n  const [loading, setLoading] = useState(false);\n\n  // Send user query to backend, add both user and agent messages\n  const sendQuery = async (\n    query: string,\n    files: string[] = [],\n    topics: string[] = [],\n    role: string = \"planner\", // Optionally allow agent selection\n    debug: boolean = true,\n    scrollToBottom?: () => void\n  ) => {\n    if (!query.trim()) return;\n\n    // Add user message\n    setMessages((prev) => [...prev, { user: toMDString(query), agent: \"\" }]);\n    setLoading(true);\n\n    try {\n      // Build payload for unified MCP endpoint\n      const payload = {\n        query,\n        files,\n        topics,\n        role,\n        debug,\n      };\n\n      const res = await fetch(`${API_ROOT}/mcp/run`, {\n        method: \"POST\",\n        headers: {\n          \"Content-Type\": \"application/json\",\n          \"X-User-Id\": userId,\n        },\n        body: JSON.stringify(payload),\n      });\n\n      const data = await res.json();\n      const result = data?.result || data;\n\n      // Coerce all markdown-displayed fields to strings for safety\n      setMessages((prev) => [\n        ...prev.slice(0, -1),\n        {\n          user: query,\n          agent: toMDString(\n            result?.plan?.objective ||\n            result?.plan?.recommendation ||\n            result?.recommendation ||\n            result?.response ||\n            data?.response ||\n            \"[no answer]\"\n          ),\n          context: toMDString(result?.context || data?.context),\n          action: result?.action,\n          id: result?.id,\n          status: result?.id ? \"pending\" : undefined,\n        },\n      ]);\n\n      scrollToBottom?.();\n    } catch {\n      setMessages((prev) => [\n        ...prev.slice(0, -1),\n        { user: toMDString(query), agent: toMDString(\"Error contacting Relay.\") },\n      ]);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  // Approve/deny an agent-generated action, update status in message array\n  const updateActionStatus = async (\n    id: string,\n    action: \"approve\" | \"deny\",\n    idx: number\n  ) => {\n    try {\n      await fetch(`${API_ROOT}/control/${action}_action`, {\n        method: \"POST\",\n        headers: {\n          \"Content-Type\": \"application/json\",\n          \"X-User-Id\": userId,\n        },\n        body: JSON.stringify({ id, comment: \"inline approval\" }),\n      });\n\n      setMessages((prev) => {\n        const updated = [...prev];\n        if (updated[idx]) {\n          updated[idx] = {\n            ...updated[idx],\n            status: action === \"approve\" ? \"approved\" : \"denied\",\n          };\n        }\n        return updated;\n      });\n    } catch {\n      alert(\"Error approving/denying action.\");\n    }\n  };\n\n  return {\n    messages,\n    setMessages,\n    sendQuery,\n    updateActionStatus,\n    loading,\n  };\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3617, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d833d335-b802-46b7-9b92-565823cf6e3a": {"__data__": {"id_": "d833d335-b802-46b7-9b92-565823cf6e3a", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/AskAgent/useAskEcho.ts", "file_name": "useAskEcho.ts", "file_size": 5907, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b96e5856-0579-45a4-bb2d-fe1a6415db66", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/AskAgent/useAskEcho.ts", "file_name": "useAskEcho.ts", "file_size": 5907, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "6e5a5092263f22255cb6520e00a19acda0ec61edd6105e87ad64d5b817fda25d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7151be5b-5504-45ba-8071-ed4658f816f4", "node_type": "1", "metadata": {}, "hash": "24e30d32b3369372e48cc5155bf8f95557849ba98d3107d4737b4eba50c9c925", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: components/AskAgent/useAskEcho.ts\n// Purpose: Custom React hook for agent chat, POSTing to /mcp/run for full agent/critic orchestration\n// Updated: 2025-06-30\n\nimport { useState, useRef, useEffect, useCallback } from \"react\";\nimport { API_ROOT } from \"@/lib/api\";\nimport { toMDString } from \"@/lib/toMDString\";\n\n// Message type for chat history\nexport type Message = {\n  role: \"user\" | \"assistant\";\n  content: string;\n  context?: string;\n  action?: { type: string; payload: unknown };\n  id?: string;\n  status?: \"pending\" | \"approved\" | \"denied\";\n};\n\n// Set a test user ID; in production, wire this to user/session context\nconst USER_ID = \"bret-demo\";\nconst STORAGE_KEY = `echo-chat-history-${USER_ID}`;\n\nexport function useAskEcho() {\n  // Chat state and UI controls\n  const [messages, setMessages] = useState<Message[]>([]);\n  const [input, setInput] = useState(\"\");\n  const [loading, setLoading] = useState(false);\n  const [files, setFiles] = useState(\"\");      // Comma-separated string in UI\n  const [topics, setTopics] = useState(\"\");    // Comma-separated string in UI\n  const [role, setRole] = useState(\"planner\"); // Agent role, can be \"planner\", \"codex\", etc.\n  const [showContext, setShowContext] = useState<Record<number, boolean>>({});\n  const bottomRef = useRef<HTMLDivElement>(null);\n\n  // Load chat history from localStorage on mount\n  useEffect(() => {\n    if (typeof window !== \"undefined\") {\n      const raw = localStorage.getItem(STORAGE_KEY);\n      if (raw) {\n        try {\n          const parsed = JSON.parse(raw);\n          if (Array.isArray(parsed)) {\n            setMessages(\n             parsed\n  .filter(\n    (m: unknown): m is { role?: unknown; content?: unknown; context?: unknown } =>\n      typeof m === \"object\" &&\n      m !== null &&\n      \"content\" in m\n  )\n  .map((m) => ({\n    role:\n      m.role === \"user\" || m.role === \"assistant\"\n        ? m.role\n        : \"assistant\", // Fallback if missing\n    content: toMDString(m.content),\n    ...(typeof m.context === \"string\" && { context: toMDString(m.context) }),\n  }))\n\n            );\n          }\n        } catch {\n          setMessages([]);\n        }\n      }\n    }\n  }, []);\n\n  // Save chat history and scroll to bottom on message update\n  useEffect(() => {\n    if (typeof window !== \"undefined\") {\n      localStorage.setItem(STORAGE_KEY, JSON.stringify(messages));\n    }\n    bottomRef.current?.scrollIntoView({ behavior: \"smooth\" });\n  }, [messages]);\n\n  // Toggle expanded context view for a message\n  const toggleContext = useCallback((index: number) => {\n    setShowContext((prev) => ({ ...prev, [index]: !prev[index] }));\n  }, []);\n\n  // Approve or deny an agent-suggested action (e.g., code patch)\n  const updateActionStatus = useCallback(\n    async (id: string, action: \"approve\" | \"deny\", idx: number) => {\n      try {\n        await fetch(`${API_ROOT}/control/${action}_action`, {\n          method: \"POST\",\n          headers: {\n            \"Content-Type\": \"application/json\",\n            \"X-User-Id\": USER_ID,\n          },\n          body: JSON.stringify({ id, comment: \"inline approval\" }),\n        });\n\n        setMessages((prev) => {\n          const updated = [...prev];\n          if (updated[idx]) {\n            updated[idx] = {\n              ...updated[idx],\n              status: action === \"approve\" ? \"approved\" : \"denied\",\n            };\n          }\n          return updated;\n        });\n      } catch {\n        alert(\"Error approving/denying action.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3457, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7151be5b-5504-45ba-8071-ed4658f816f4": {"__data__": {"id_": "7151be5b-5504-45ba-8071-ed4658f816f4", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/AskAgent/useAskEcho.ts", "file_name": "useAskEcho.ts", "file_size": 5907, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b96e5856-0579-45a4-bb2d-fe1a6415db66", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/AskAgent/useAskEcho.ts", "file_name": "useAskEcho.ts", "file_size": 5907, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "6e5a5092263f22255cb6520e00a19acda0ec61edd6105e87ad64d5b817fda25d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d833d335-b802-46b7-9b92-565823cf6e3a", "node_type": "1", "metadata": {"file_path": "/app/frontend/src/components/AskAgent/useAskEcho.ts", "file_name": "useAskEcho.ts", "file_size": 5907, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "c152f4a7cdd466fe35616c757c4d247280cd9ea3b19c4861cb65720486665781", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"approved\" : \"denied\",\n            };\n          }\n          return updated;\n        });\n      } catch {\n        alert(\"Error approving/denying action.\");\n      }\n    },\n    []\n  );\n\n  // Send user input to the backend (MCP entrypoint), add both user and agent messages\n  const sendMessage = useCallback(async () => {\n    if (!input.trim() || loading) return;\n\n    const userMessage = input;\n    setMessages((msgs) => [...msgs, { role: \"user\", content: toMDString(userMessage) }]);\n    setInput(\"\");\n    setLoading(true);\n\n    try {\n      // Prepare the payload, parsing files/topics as arrays, include selected agent role\n      const payload = {\n        query: userMessage, // could also use \"question\", but \"query\" is unified\n        files: files ? files.split(\",\").map((f) => f.trim()).filter(Boolean) : [],\n        topics: topics ? topics.split(\",\").map((t) => t.trim()).filter(Boolean) : [],\n        role,        // \"planner\", \"codex\", etc. (add a UI selector for more roles)\n        debug: true, // always enable debug for richer agent responses\n      };\n\n      const res = await fetch(`${API_ROOT}/mcp/run`, {\n        method: \"POST\",\n        headers: {\n          \"Content-Type\": \"application/json\",\n          \"X-User-Id\": USER_ID,\n        },\n        body: JSON.stringify(payload),\n      });\n\n      const data = await res.json();\n\n      // Compose assistant's reply (try multiple possible keys)\n      const result = data?.result || data;\n        // Helper: always coerce to string for SafeMarkdown\n\n      setMessages((msgs) => [\n        ...msgs,\n        {\n          role: \"assistant\",\n          content:\n            toMDString(\n              result?.plan?.objective ||\n              result?.plan?.recommendation ||\n              result?.recommendation ||\n              result?.response ||\n              data?.response ||\n              \"[no answer]\"\n            ),\n          context: toMDString(result?.context || data?.context),\n          action: result?.action,\n          id: result?.id,\n          status: result?.id ? \"pending\" : undefined,\n        },\n      ]);\n\n    } catch {\n      setMessages((msgs) => [\n        ...msgs,\n        { role: \"assistant\", content: toMDString(\"[error] Unable to get response.\") },\n      ]);\n    }\n\n    setLoading(false);\n  }, [input, loading, files, topics, role]);\n\n  return {\n    input,\n    setInput,\n    messages,\n    sendMessage,\n    loading,\n    bottomRef,\n    files,\n    setFiles,\n    topics,\n    setTopics,\n    role,\n    setRole, // Expose role setter so UI can allow agent role selection\n    showContext,\n    toggleContext,\n    updateActionStatus,\n  };\n}", "mimetype": "text/plain", "start_char_idx": 3307, "end_char_idx": 5906, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "507c082f-4284-4889-84a4-6cea0ae01d1a": {"__data__": {"id_": "507c082f-4284-4889-84a4-6cea0ae01d1a", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/AuditPanel/AuditPanel.tsx", "file_name": "AuditPanel.tsx", "file_size": 14146, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4c35eb16-b549-439c-9138-dcbe2dca99c0", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/AuditPanel/AuditPanel.tsx", "file_name": "AuditPanel.tsx", "file_size": 14146, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "5a439a03eae2d23031bf9e97f613f5e6197b7037eb6c0bec6829aad968489601", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "92b71366-6182-4452-9371-72eff4fce54a", "node_type": "1", "metadata": {}, "hash": "bdac90020375847179f8526b33179ba0f59d95ded2f3c7f6a0aed75e6e13f87e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: frontend/src/components/AuditPanel.tsx\n// Purpose: Unified agent audit dashboard with drilldown into agent actions/patches and related context.\n//          All comments, context, rationales, and diffs now render via SafeMarkdown for clarity and security.\n\n\"use client\";\n\nimport { useEffect, useState } from \"react\";\nimport { Button } from \"@/components/ui/button\";\nimport { Badge } from \"@/components/ui/badge\";\nimport { API_ROOT } from \"@/lib/api\";\nimport SafeMarkdown from \"@/components/SafeMarkdown\";\n\n// Bulletproof Markdown stringifier for all content/comments/diffs/rationales/etc.\nfunction toMDString(val: unknown): string {\n  if (val == null) return \"\";\n  if (typeof val === \"string\") return val;\n  if (Array.isArray(val)) return val.map(toMDString).join(\"\\n\\n\");\n  try {\n    return \"```json\\n\" + JSON.stringify(val, null, 2) + \"\\n```\";\n  } catch {\n    return String(val);\n  }\n}\n\n\n// === Types ===\ntype LogEntry = {\n  id: string;\n  type?: string;\n  path?: string;\n  timestamp: string;\n  status: string;\n  user?: string;\n  comment?: string;\n  result?: unknown;\n};\ntype ActionDetail = {\n  id: string;\n  action: {\n    context?: string;\n    rationale?: string;\n    diff?: string;\n  };\n  history?: {\n    timestamp: string;\n    status: string;\n    user?: string;\n    comment?: string;\n  }[];\n};\n\nexport default function AuditPanel() {\n  const [logs, setLogs] = useState<LogEntry[]>([]);\n  const [filter, setFilter] = useState<{ user?: string; type?: string; status?: string }>({});\n  const [search, setSearch] = useState(\"\");\n  const [exporting, setExporting] = useState(false);\n  const [selected, setSelected] = useState<LogEntry | null>(null);\n  const [relatedAction, setRelatedAction] = useState<ActionDetail | null>(null);\n\n  // === Fetch audit logs from backend ===\n  async function fetchLog() {\n    try {\n      const res = await fetch(`${API_ROOT}/control/list_log`, {\n        headers: { \"X-API-Key\": process.env.NEXT_PUBLIC_API_KEY || \"\" }\n      });\n      if (!res.ok) throw new Error(\"Bad response\");\n      const data = await res.json();\n      const mapped = (data.log || []).map((l: LogEntry) => ({\n        ...l,\n        comment: toMDString(l.comment),\n        result: toMDString(l.result)\n      }));\n      setLogs(mapped);\n    } catch (err) {\n      console.error(\"[AuditPanel] Failed to fetch logs:\", err);\n      setLogs([]);\n    }\n  }\n\n  // === Fetch related queue action by id ===\n  async function fetchRelated(id: string) {\n    try {\n      const res = await fetch(`${API_ROOT}/control/list_queue`, {\n        headers: { \"X-API-Key\": process.env.NEXT_PUBLIC_API_KEY || \"\" }\n      });\n      if (!res.ok) throw new Error(\"Bad response\");\n      const data = await res.json();\n      const action: ActionDetail | undefined = (data.actions as ActionDetail[] | undefined)?.find(a => a.id === id);\n      const mapped = action\n        ? {\n            ...action,\n            action: {\n              ...action.action,\n              context: toMDString(action.action?.context),\n              rationale: toMDString(action.action?.rationale),\n              diff: toMDString(action.action?.diff)\n            },\n            history: Array.isArray(action.history)\n              ? action.history.map(h => ({\n                  ...h,\n                  comment: toMDString(h.comment)\n                }))\n              : action.history\n          }\n        : null;\n      setRelatedAction(mapped);\n    } catch (err) {\n      console.error(\"[AuditPanel] Failed to fetch related action:\", err);\n      setRelatedAction(null);\n    }\n  }\n\n  useEffect(() => {\n    fetchLog();\n    const interval = setInterval(fetchLog, 15000);\n    return () => clearInterval(interval);\n  }, []);\n\n  // === Filtered/search results ===\n  const filtered = logs.filter(entry =>\n    (!filter.user || entry.user === filter.user) &&\n    (!filter.type || entry.type === filter.type) &&\n    (!filter.status || entry.status === filter.status) &&\n    (search.trim() === \"\" ||\n      (entry.comment?.toLowerCase().includes(search.toLowerCase()) ?? false) ||\n      (entry.type?.toLowerCase().includes(search.toLowerCase()) ?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4084, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "92b71366-6182-4452-9371-72eff4fce54a": {"__data__": {"id_": "92b71366-6182-4452-9371-72eff4fce54a", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/AuditPanel/AuditPanel.tsx", "file_name": "AuditPanel.tsx", "file_size": 14146, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4c35eb16-b549-439c-9138-dcbe2dca99c0", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/AuditPanel/AuditPanel.tsx", "file_name": "AuditPanel.tsx", "file_size": 14146, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "5a439a03eae2d23031bf9e97f613f5e6197b7037eb6c0bec6829aad968489601", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "507c082f-4284-4889-84a4-6cea0ae01d1a", "node_type": "1", "metadata": {"file_path": "/app/frontend/src/components/AuditPanel/AuditPanel.tsx", "file_name": "AuditPanel.tsx", "file_size": 14146, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "cc0f92652b2c031fe9ff807828dffa3c3d8d3a809ce18aa4a846abdf8bc5545d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "83084774-e814-4af2-9f7c-82382d96fec6", "node_type": "1", "metadata": {}, "hash": "c56c2ad2f9b8153f6bad5218482a9a374f64486b8886f687b0fe1a5c0861eba8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "action.history.map(h => ({\n                  ...h,\n                  comment: toMDString(h.comment)\n                }))\n              : action.history\n          }\n        : null;\n      setRelatedAction(mapped);\n    } catch (err) {\n      console.error(\"[AuditPanel] Failed to fetch related action:\", err);\n      setRelatedAction(null);\n    }\n  }\n\n  useEffect(() => {\n    fetchLog();\n    const interval = setInterval(fetchLog, 15000);\n    return () => clearInterval(interval);\n  }, []);\n\n  // === Filtered/search results ===\n  const filtered = logs.filter(entry =>\n    (!filter.user || entry.user === filter.user) &&\n    (!filter.type || entry.type === filter.type) &&\n    (!filter.status || entry.status === filter.status) &&\n    (search.trim() === \"\" ||\n      (entry.comment?.toLowerCase().includes(search.toLowerCase()) ?? false) ||\n      (entry.type?.toLowerCase().includes(search.toLowerCase()) ?? false) ||\n      (entry.path?.toLowerCase().includes(search.toLowerCase()) ?? false) ||\n      (entry.id?.toLowerCase().includes(search.toLowerCase()) ?? false))\n  );\n\n  // === Export as JSON/CSV ===\n  function exportLog(format: \"json\" | \"csv\") {\n    setExporting(true);\n    let blob;\n    if (format === \"json\") {\n      blob = new Blob([JSON.stringify(filtered, null, 2)], { type: \"application/json\" });\n    } else {\n      const header = [\"id\", \"type\", \"path\", \"timestamp\", \"status\", \"user\", \"comment\"];\n      const csv = [\n        header.join(\",\"),\n        ...filtered.map(l => header.map(k => `\"${(l as Record<string, string | undefined>)[k] ?? \"\"}\"`).join(\",\"))\n      ].join(\"\\n\");\n      blob = new Blob([csv], { type: \"text/csv\" });\n    }\n    const url = URL.createObjectURL(blob);\n    const a = document.createElement(\"a\");\n    a.href = url;\n    a.download = `relay_audit_log.${format}`;\n    a.click();\n    setTimeout(() => {\n      setExporting(false);\n      URL.revokeObjectURL(url);\n    }, 1000);\n  }\n\n  // === UI ===\n  const rows = filtered.map((entry, i) => {\n    if (entry.comment && typeof entry.comment !== \"string\") {\n      console.log(\"DEBUG 418:\", typeof entry.comment, entry.comment);\n    }\n    return (\n      <tr\n        key={i}\n        className=\"border-t border-gray-300 cursor-pointer hover:bg-blue-50\"\n        onClick={() => {\n          setSelected(entry);\n          fetchRelated(entry.id);\n        }}\n      >\n        <td className=\"px-2 py-1\">{entry.timestamp}</td>\n        <td className=\"px-2 py-1\">\n          <Badge\n            variant={\n              entry.status === \"approved\"\n                ? \"success\"\n                : entry.status === \"denied\"\n                ? \"destructive\"\n                : entry.status === \"pending\"\n                ? \"secondary\"\n                : \"default\"\n            }\n          >\n            {entry.status}\n          </Badge>\n        </td>\n        <td className=\"px-2 py-1\">{entry.user || \"\"}</td>\n        <td className=\"px-2 py-1\">{entry.type || \"\"}</td>\n        <td className=\"px-2 py-1 font-mono\">{entry.path || \"\"}</td>\n        <td className=\"px-2 py-1 font-mono\">{entry.id.slice(0, 8)}</td>\n        <td className=\"px-2 py-1\">\n          {entry.comment ?", "mimetype": "text/plain", "start_char_idx": 3185, "end_char_idx": 6298, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "83084774-e814-4af2-9f7c-82382d96fec6": {"__data__": {"id_": "83084774-e814-4af2-9f7c-82382d96fec6", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/AuditPanel/AuditPanel.tsx", "file_name": "AuditPanel.tsx", "file_size": 14146, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4c35eb16-b549-439c-9138-dcbe2dca99c0", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/AuditPanel/AuditPanel.tsx", "file_name": "AuditPanel.tsx", "file_size": 14146, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "5a439a03eae2d23031bf9e97f613f5e6197b7037eb6c0bec6829aad968489601", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "92b71366-6182-4452-9371-72eff4fce54a", "node_type": "1", "metadata": {"file_path": "/app/frontend/src/components/AuditPanel/AuditPanel.tsx", "file_name": "AuditPanel.tsx", "file_size": 14146, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "db3616ff6b67f0e512e2ff520be8bd78a7dd6b03842ffb5f64508ca9969adb38", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0760576a-0de7-420e-b981-724ffe2446fa", "node_type": "1", "metadata": {}, "hash": "d72abc6a3db9762afe8e4b39b32e575453efb92e2ae131e123408c84a4477def", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"success\"\n                : entry.status === \"denied\"\n                ? \"destructive\"\n                : entry.status === \"pending\"\n                ? \"secondary\"\n                : \"default\"\n            }\n          >\n            {entry.status}\n          </Badge>\n        </td>\n        <td className=\"px-2 py-1\">{entry.user || \"\"}</td>\n        <td className=\"px-2 py-1\">{entry.type || \"\"}</td>\n        <td className=\"px-2 py-1 font-mono\">{entry.path || \"\"}</td>\n        <td className=\"px-2 py-1 font-mono\">{entry.id.slice(0, 8)}</td>\n        <td className=\"px-2 py-1\">\n          {entry.comment ? (\n            <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n              <SafeMarkdown>{entry.comment}</SafeMarkdown>\n            </div>\n          ) : (\n            \"\"\n          )}\n        </td>\n      </tr>\n    );\n  });\n\n  if (selected && typeof selected.comment !== \"string\") {\n    console.log(\"DEBUG 418:\", typeof selected.comment, selected.comment);\n  }\n  if (relatedAction?.action?.context && typeof relatedAction.action.context !== \"string\") {\n    console.log(\"DEBUG 418:\", typeof relatedAction.action.context, relatedAction.action.context);\n  }\n  if (relatedAction?.action?.rationale && typeof relatedAction.action.rationale !== \"string\") {\n    console.log(\n      \"DEBUG 418:\",\n      typeof relatedAction.action.rationale,\n      relatedAction.action.rationale\n    );\n  }\n  if (relatedAction?.action?.diff && typeof relatedAction.action.diff !== \"string\") {\n    console.log(\"DEBUG 418:\", typeof relatedAction.action.diff, relatedAction.action.diff);\n  }\n  if (relatedAction?.history) {\n    for (const h of relatedAction.history) {\n      if (h.comment && typeof h.comment !== \"string\") {\n        console.log(\"DEBUG 418:\", typeof h.comment, h.comment);\n      }\n    }\n  }\n\n  return (\n    <div className=\"max-w-5xl mx-auto py-8\">\n      <h2 className=\"font-bold text-xl mb-6\">\ud83d\udee1\ufe0f Audit Log & Operator Panel</h2>\n      <div className=\"flex gap-2 mb-4 items-end\">\n        <input\n          placeholder=\"\ud83d\udd0e Search user/type/path/comment/ID\"\n          className=\"border rounded px-2 py-1 w-60 text-sm\"\n          value={search}\n          onChange={e => setSearch(e.target.value)}\n        />\n        <input\n          placeholder=\"Filter user\"\n          className=\"border rounded px-2 py-1 text-xs\"\n          value={filter.user || \"\"}\n          onChange={e => setFilter(f => ({ ...f, user: e.target.value }))}\n        />\n        <input\n          placeholder=\"Filter type\"\n          className=\"border rounded px-2 py-1 text-xs\"\n          value={filter.type || \"\"}\n          onChange={e => setFilter(f => ({ ...f, type: e.target.value }))}\n        />\n        <select\n          className=\"border rounded px-2 py-1 text-xs\"\n          value={filter.status || \"\"}\n          onChange={e => setFilter(f => ({ ...f, status: e.target.value }))}\n        >\n          <option value=\"\">Status</option>\n          <option value=\"approved\">approved</option>\n          <option value=\"denied\">denied</option>\n          <option value=\"executed\">executed</option>\n          <option value=\"pending\">pending</option>\n        </select>\n        <Button onClick={() => fetchLog()} className=\"ml-2\">Refresh</Button>\n        <Button\n          variant=\"outline\"\n          disabled={exporting}\n          onClick={() => exportLog(\"json\")}\n        >\n          Export JSON\n        </Button>\n        <Button\n          variant=\"outline\"\n          disabled={exporting}\n          onClick={() => exportLog(\"csv\")}\n        >\n          Export CSV\n        </Button>\n      </div>\n      <div className=\"bg-gray-100 rounded-md p-2 max-h-[60vh] overflow-auto text-xs\">\n        {filtered.length === 0 && (\n          <div className=\"text-muted-foreground text-center py-8\">\n            No log entries match the filters.", "mimetype": "text/plain", "start_char_idx": 5706, "end_char_idx": 9483, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0760576a-0de7-420e-b981-724ffe2446fa": {"__data__": {"id_": "0760576a-0de7-420e-b981-724ffe2446fa", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/AuditPanel/AuditPanel.tsx", "file_name": "AuditPanel.tsx", "file_size": 14146, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4c35eb16-b549-439c-9138-dcbe2dca99c0", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/AuditPanel/AuditPanel.tsx", "file_name": "AuditPanel.tsx", "file_size": 14146, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "5a439a03eae2d23031bf9e97f613f5e6197b7037eb6c0bec6829aad968489601", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "83084774-e814-4af2-9f7c-82382d96fec6", "node_type": "1", "metadata": {"file_path": "/app/frontend/src/components/AuditPanel/AuditPanel.tsx", "file_name": "AuditPanel.tsx", "file_size": 14146, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "dfe8ff0252c41c7398be26975ca5e780d114f2208c9773d667ed7828d03563f7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6f388a35-5a14-4ecc-9238-0c22a65d89ab", "node_type": "1", "metadata": {}, "hash": "8ae553d866a8640cf9c3e25353e62ed6aee5bd5099d52700cfdac3338b52f327", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "</div>\n        )}\n        <table className=\"w-full\">\n          <thead>\n            <tr className=\"font-semibold text-gray-700 bg-gray-200\">\n              <th className=\"px-2 py-1 text-left\">Time</th>\n              <th className=\"px-2 py-1 text-left\">Status</th>\n              <th className=\"px-2 py-1 text-left\">User</th>\n              <th className=\"px-2 py-1 text-left\">Type</th>\n              <th className=\"px-2 py-1 text-left\">Path</th>\n              <th className=\"px-2 py-1 text-left\">ID</th>\n              <th className=\"px-2 py-1 text-left\">Comment</th>\n            </tr>\n          </thead>\n          <tbody>{rows}</tbody>\n        </table>\n      </div>\n      <div className=\"text-xs text-gray-400 mt-3\">\n        Tip: Click any row for full drilldown: context, rationale, diff, timeline, and more.\n      </div>\n\n      {/* === Per-action Modal Drilldown === */}\n      {selected && (\n        <div className=\"fixed inset-0 flex items-center justify-center bg-black/30 z-50\">\n          <div className=\"bg-white p-6 rounded shadow-lg w-full max-w-xl relative\">\n            <button className=\"absolute top-2 right-3 text-xl\" onClick={() => { setSelected(null); setRelatedAction(null); }}>&times;</button>\n            <h3 className=\"font-bold mb-2\">Action Detail (#{selected.id.slice(0, 8)})</h3>\n            <div className=\"mb-2 text-xs\">\n              <strong>Status:</strong>{\" \"}\n              <Badge variant={\n                selected.status === \"approved\" ? \"success\" :\n                selected.status === \"denied\" ? \"destructive\" : \"secondary\"\n              }>\n                {selected.status}\n              </Badge><br />\n              <strong>User:</strong> {selected.user}<br />\n              <strong>Type:</strong> {selected.type}<br />\n              <strong>Path:</strong> {selected.path}<br />\n              <strong>Comment:</strong>{\" \"}\n              {selected.comment ?", "mimetype": "text/plain", "start_char_idx": 9494, "end_char_idx": 11381, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6f388a35-5a14-4ecc-9238-0c22a65d89ab": {"__data__": {"id_": "6f388a35-5a14-4ecc-9238-0c22a65d89ab", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/AuditPanel/AuditPanel.tsx", "file_name": "AuditPanel.tsx", "file_size": 14146, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4c35eb16-b549-439c-9138-dcbe2dca99c0", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/AuditPanel/AuditPanel.tsx", "file_name": "AuditPanel.tsx", "file_size": 14146, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "5a439a03eae2d23031bf9e97f613f5e6197b7037eb6c0bec6829aad968489601", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0760576a-0de7-420e-b981-724ffe2446fa", "node_type": "1", "metadata": {"file_path": "/app/frontend/src/components/AuditPanel/AuditPanel.tsx", "file_name": "AuditPanel.tsx", "file_size": 14146, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "46e38c6771b35019a1b27ab3123b71e6b077e324df71f97609dad89de98cc3e7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"success\" :\n                selected.status === \"denied\" ? \"destructive\" : \"secondary\"\n              }>\n                {selected.status}\n              </Badge><br />\n              <strong>User:</strong> {selected.user}<br />\n              <strong>Type:</strong> {selected.type}<br />\n              <strong>Path:</strong> {selected.path}<br />\n              <strong>Comment:</strong>{\" \"}\n              {selected.comment ? (\n                <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n                  <SafeMarkdown>{selected.comment}</SafeMarkdown>\n                </div>\n              ) : \"\"}\n              <br />\n              <strong>Timestamp:</strong> {selected.timestamp}\n            </div>\n            {relatedAction?.action?.context && (\n              <details>\n                <summary className=\"cursor-pointer text-blue-700 mb-2\">View Agent Context</summary>\n                <div className=\"bg-gray-50 p-2 rounded text-xs max-h-40 overflow-auto whitespace-pre-wrap\">\n                  <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n                    <SafeMarkdown>{relatedAction.action.context}</SafeMarkdown>\n                  </div>\n                </div>\n              </details>\n            )}\n            {relatedAction?.action?.rationale && (\n              <div className=\"text-xs italic mb-2\">\n                <strong>Agent rationale:</strong>{\" \"}\n                <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n                  <SafeMarkdown>{relatedAction.action.rationale}</SafeMarkdown>\n                </div>\n              </div>\n            )}\n            {relatedAction?.action?.diff && (\n              <details>\n                <summary className=\"cursor-pointer text-blue-700 mb-2\">View Diff</summary>\n                <div className=\"bg-yellow-50 p-2 rounded text-xs max-h-40 overflow-auto whitespace-pre-wrap\">\n                  <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n                    <SafeMarkdown>{relatedAction.action.diff}</SafeMarkdown>\n                  </div>\n                </div>\n              </details>\n            )}\n            {relatedAction?.history && (\n              <div>\n                <h4 className=\"font-semibold mt-2 mb-1 text-sm\">Timeline</h4>\n                <ul className=\"bg-gray-100 p-2 rounded text-xs max-h-32 overflow-auto border\">\n                  {relatedAction.history.map((h, i) => (\n                    <li key={i}>\n                      <span className=\"font-mono\">{h.timestamp}</span> \u2022 <Badge>{h.status}</Badge>\n                      {h.user && <span className=\"ml-2 text-blue-700\">{h.user}</span>}\n                      {h.comment && (\n                        <span className=\"ml-2 italic\">\n                          <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n                            <SafeMarkdown>{h.comment}</SafeMarkdown>\n                          </div>\n                        </span>\n                      )}\n                    </li>\n                  ))}\n                </ul>\n              </div>\n            )}\n          </div>\n        </div>\n      )}\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 10959, "end_char_idx": 14135, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cd5ff8b5-cd7e-4804-82ea-16ee49dd56d1": {"__data__": {"id_": "cd5ff8b5-cd7e-4804-82ea-16ee49dd56d1", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/Codex/CodexEditor.tsx", "file_name": "CodexEditor.tsx", "file_size": 842, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3e243e36-20c9-4ecd-8b9b-cffb62d32eb6", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/Codex/CodexEditor.tsx", "file_name": "CodexEditor.tsx", "file_size": 842, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "359c766dc6c1dc20c9d6bad113330e7ec021e7fadecb842b2c89abb9cbfd49f3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: src/components/Codex/CodexEditor.tsx\n// Purpose: Simple text/code editor for Codex agent\n// Updated: 2025-06-30\n\nimport { Dispatch, SetStateAction } from \"react\";\n\nexport interface Props {\n  code: string; // Source code being edited\n  setCode: Dispatch<SetStateAction<string>>; // Update function\n}\n\nexport default function CodexEditor({ code, setCode }: Props) {\n  return (\n    <div>\n      <label htmlFor=\"codex-editor\" className=\"block text-sm font-medium mb-1\">\n        Source Code\n      </label>\n      <textarea\n        id=\"codex-editor\"\n        value={code}\n        onChange={(e) => setCode(e.target.value)}\n        className=\"w-full h-48 p-2 border rounded font-mono resize-y\"\n        spellCheck={false}\n        placeholder=\"Paste or type your code here\u2026\"\n        aria-label=\"Code input for Codex\"\n      />\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 839, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7c4bede4-75ae-457f-a157-3ff01b6d6282": {"__data__": {"id_": "7c4bede4-75ae-457f-a157-3ff01b6d6282", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/Codex/CodexPatchView.tsx", "file_name": "CodexPatchView.tsx", "file_size": 1321, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a24b5ce2-14d6-49a9-8ebb-c0f3d828830e", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/Codex/CodexPatchView.tsx", "file_name": "CodexPatchView.tsx", "file_size": 1321, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "d129fbbcd7f407055fce962a818fc377f405fca14048b3bb67e289808cfc519e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: frontend/src/components/Codex/CodexPatchView.tsx\n// Purpose: Displays the generated code patch/result from the Codex agent.\n//          All Markdown/code rendering MUST go through SafeMarkdown.\n// Updated: 2025-07-01\n\n\"use client\";\n\nimport SafeMarkdown from \"@/components/SafeMarkdown\";\n\ninterface Props {\n  patch: string;\n  loading?: boolean; // Optionally show loading state (prop-driven)\n}\n\nexport default function CodexPatchView({ patch, loading = false }: Props) {\n  if (typeof patch !== \"string\") {\n    console.log(\"DEBUG 418:\", typeof patch, patch);\n  }\n  return (\n    <div className=\"mt-4\">\n      <label htmlFor=\"codex-patch\" className=\"block text-sm font-medium mb-1\">\n        Generated Patch\n      </label>\n      <div\n        id=\"codex-patch\"\n        className=\"w-full max-h-[500px] overflow-auto bg-black text-green-400 p-4 rounded text-sm whitespace-pre-wrap\"\n        aria-busy={loading}\n      >\n        {/* DO NOT render markdown/code any other way\u2014SafeMarkdown only */}\n        {loading ? (\n          \"\u23f3 Codex is generating your patch...\"\n        ) : patch?.trim() ? (\n          <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n            <SafeMarkdown>{patch}</SafeMarkdown>\n          </div>\n        ) : (\n          \"No patch yet.\"\n        )}\n      </div>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1316, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "31b283cb-c9c1-48f7-ba3a-4ec0fab1020f": {"__data__": {"id_": "31b283cb-c9c1-48f7-ba3a-4ec0fab1020f", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/Codex/CodexPromptBar.tsx", "file_name": "CodexPromptBar.tsx", "file_size": 1423, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5c2d9799-5099-4430-9244-b3e62272fe40", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/Codex/CodexPromptBar.tsx", "file_name": "CodexPromptBar.tsx", "file_size": 1423, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "e293f3c840ba43dc0cc098adcc08b992315818b0b532a2663a4a09d8f06d66a1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: frontend/src/components/Codex/CodexPromptBar.tsx\n// Purpose: Prompt input bar for Codex code editing agent\n// Updated: 2025-06-30\n\n\"use client\";\n\nimport { Input } from \"@/components/ui/input\";\nimport { Button } from \"@/components/ui/button\";\n\ninterface Props {\n  prompt: string;                 // Prompt/instruction for the code agent\n  setPrompt: (val: string) => void; // Handler to update prompt in parent state\n  onSubmit: () => void;           // Handler called when user submits\n  loading?: boolean;              // Show loading state, disable input (prop-driven)\n}\n\nexport default function CodexPromptBar({ prompt, setPrompt, onSubmit, loading = false }: Props) {\n  // Handle Enter key to submit (unless Shift is held for multi-line, if ever needed)\n  const handleKeyDown = (e: React.KeyboardEvent<HTMLInputElement>) => {\n    if (e.key === \"Enter\" && !e.shiftKey && prompt.trim() && !loading) {\n      e.preventDefault();\n      onSubmit();\n    }\n  };\n\n  return (\n    <div className=\"flex items-center gap-4\">\n      <Input\n        value={prompt}\n        onChange={(e) => setPrompt(e.target.value)}\n        onKeyDown={handleKeyDown}\n        placeholder=\"What should Codex do? (e.g., Add docstrings)\"\n        className=\"flex-1\"\n        disabled={loading}\n      />\n      <Button onClick={onSubmit} disabled={loading || !prompt.trim()}>\n        {loading ? \"Running...\" : \"Run\"}\n      </Button>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1422, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1a4f8f48-9a4f-4fd0-b9b9-6fea3a3780f3": {"__data__": {"id_": "1a4f8f48-9a4f-4fd0-b9b9-6fea3a3780f3", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/Codex/index.ts", "file_name": "index.ts", "file_size": 277, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "37ac9e21-28d5-4e6c-8632-187cec50ef3b", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/Codex/index.ts", "file_name": "index.ts", "file_size": 277, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "6ffb0264816f1c25ab968a1a8004fc04aa4fe874878ee04665e5082c9433f7e0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: frontend/src/components/Codex/index.ts\n// Purpose: Barrel exports for Codex components\n\nexport { default as CodexEditor } from \"./CodexEditor\";\nexport { default as CodexPromptBar } from \"./CodexPromptBar\";\nexport { default as CodexPatchView } from \"./CodexPatchView\";", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 276, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "877860cb-6eb5-4f1a-a141-0e17af9b763f": {"__data__": {"id_": "877860cb-6eb5-4f1a-a141-0e17af9b763f", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/Codex/page.tsx", "file_name": "page.tsx", "file_size": 2108, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b4c7cdf6-3d8f-421a-ad1e-e02af1abdb9b", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/Codex/page.tsx", "file_name": "page.tsx", "file_size": 2108, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "8d8352955437d8b8b1fa86bd1f754eb75b8f7d491abf3f1a45bedc5b135b7251", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: frontend/src/components/Codex/CodexPage.tsx\n// Purpose: UI for Codex agent with code editor, prompt bar, and streaming patch view\n// Updated: 2025-06-30\n\n\"use client\";\n\nimport { CodexEditor, CodexPromptBar, CodexPatchView } from \"@/components/Codex\";\nimport { useState } from \"react\";\nimport { API_ROOT } from \"@/lib/api\";\n\nexport default function CodexPage() {\n  const [code, setCode] = useState(\"\");           // User's source code\n  const [prompt, setPrompt] = useState(\"\");       // Editing instruction (prompt)\n  const [streamingPatch, setStreamingPatch] = useState(\"\"); // Live code patch output\n  const [loading, setLoading] = useState(false);  // Loading state for UX\n\n  // Handler for submitting the edit prompt to the Codex agent\n  const handleSubmit = async () => {\n    if (!prompt.trim() || !code.trim() || loading) return;\n\n    setStreamingPatch(\"\u23f3 Working...\");\n    setLoading(true);\n\n    try {\n      const res = await fetch(`${API_ROOT}/ask/codex_stream`, {\n        method: \"POST\",\n        headers: { \"Content-Type\": \"application/json\" },\n        body: JSON.stringify({ question: prompt, context: code }),\n      });\n\n      const reader = res.body?.getReader();\n      const decoder = new TextDecoder();\n      let patch = \"\";\n\n      while (reader) {\n        const { value, done } = await reader.read();\n        if (done) break;\n        patch += decoder.decode(value, { stream: true });\n        setStreamingPatch(patch);\n      }\n    } catch {\n      setStreamingPatch(\"\u274c Error streaming patch from Codex agent.\");\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  return (\n    <div className=\"p-6 space-y-4\">\n      <h1 className=\"text-2xl font-bold\">\ud83e\udde0 Codex \u2014 Code Editing Agent</h1>\n      {/* Code input area */}\n      <CodexEditor code={code} setCode={setCode} />\n\n      {/* Prompt bar for edit instructions */}\n      <CodexPromptBar\n        prompt={prompt}\n        setPrompt={setPrompt}\n        onSubmit={handleSubmit}\n        loading={loading}\n      />\n\n      {/* Patch/result area */}\n      <CodexPatchView patch={streamingPatch} loading={loading} />\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2098, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "26c90ccc-285c-47f4-8666-51aabf6550dd": {"__data__": {"id_": "26c90ccc-285c-47f4-8666-51aabf6550dd", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/DocsSyncPanel.tsx", "file_name": "DocsSyncPanel.tsx", "file_size": 5158, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d44bd992-6ce4-40f7-ae55-7b28865993ab", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/DocsSyncPanel.tsx", "file_name": "DocsSyncPanel.tsx", "file_size": 5158, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "8b64527db203ee5d0c52ab3449b82a007bccb892e6e41ba916421e5cdeb2d83d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "11682fed-6d09-48b0-86e0-5a1dde7b4733", "node_type": "1", "metadata": {}, "hash": "8348f415bde548b00a8639a40d4b25066ca39bef8b4dbc7f98e5f23b7ceb5d23", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: components/DocsSyncPanel.tsx\n// Purpose: UI panel for syncing, refreshing, and reindexing knowledge base docs. \n//          All status and result messages are rendered with SafeMarkdown for rich, safe output.\n\n\"use client\";\n\nimport { useState } from \"react\";\nimport { Button } from \"@/components/ui/button\";\nimport { API_ROOT } from \"@/lib/api\";\nimport SafeMarkdown from \"@/components/SafeMarkdown\";\nimport { toMDString } from \"@/lib/toMDString\";\n\nexport default function DocsSyncPanel() {\n  const [status, setStatus] = useState<string | null>(null);\n  const [files, setFiles] = useState<string[]>([]);\n  const [loading, setLoading] = useState<boolean>(false);\n\n  // New state for reindex button\n  const [reindexStatus, setReindexStatus] = useState<string | null>(null);\n  const [reindexLoading, setReindexLoading] = useState<boolean>(false);\n\n  /**\n   * Trigger a sync operation at the given endpoint and handle results.\n   * @param endpoint 'sync', 'refresh_kb', or 'full_sync'\n   */\n  const triggerSync = async (endpoint: string) => {\n    if (!API_ROOT) {\n      setStatus(toMDString(\"\u274c API URL not configured\"));\n      return;\n    }\n    setStatus(toMDString(\"\u23f3 Running...\"));\n    setFiles([]);\n    setLoading(true);\n    try {\n      const res = await fetch(`${API_ROOT}/docs/${endpoint}`, { method: \"POST\" });\n      if (!res.ok) {\n        throw new Error(`Request failed: ${res.status}`);\n      }\n      const data = await res.json();\n      if (Array.isArray(data.synced_docs)) {\n        setFiles(data.synced_docs);\n        setStatus(toMDString(`\u2705 Synced ${data.synced_docs.length} docs.`));\n      } else if (data.message) {\n        setStatus(toMDString(`\u2705 ${data.message}`));\n      } else {\n        setStatus(toMDString(\"\u2705 Operation completed.\"));\n      }\n    } catch (err) {\n      console.error(\"DocsSync error:\", err);\n      setStatus(toMDString(\"\u274c Failed to sync. See console for details.\"));\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  // --- NEW: Trigger a KB reindex (admin only) ---\n  const triggerReindex = async () => {\n    if (!API_ROOT) {\n      setReindexStatus(toMDString(\"\u274c API URL not configured\"));\n      return;\n    }\n    setReindexStatus(toMDString(\"\u23f3 Reindexing...\"));\n    setReindexLoading(true);\n    try {\n      const res = await fetch(`${API_ROOT}/admin/trigger_reindex`, {\n        method: \"POST\",\n        headers: {\n          // If you use a static admin API key for local, include it here\n          // For production, secure this!\n          \"X-API-Key\": process.env.NEXT_PUBLIC_API_KEY || \"\",\n        },\n      });\n      const data = await res.json();\n      if (res.ok) {\n        setReindexStatus(toMDString(`\u2705 ${data.message || \"Reindex complete.\"}`));\n      } else {\n        setReindexStatus(toMDString(`\u274c ${data.detail || \"Reindex failed.\"}`));\n      }\n    } catch (err) {\n      console.error(\"Reindex error:\", err);\n      setReindexStatus(toMDString(\"\u274c Failed to reindex. See console for details.\"));\n    } finally {\n      setReindexLoading(false);\n    }\n  };\n\n  if (typeof status !== \"string\") {\n    console.log(\"DEBUG 418:\", typeof status, status);\n  }\n  if (typeof reindexStatus !== \"string\") {\n    console.log(\"DEBUG 418:\", typeof reindexStatus, reindexStatus);\n  }\n\n  return (\n    <div className=\"space-y-4\">\n      <h2 className=\"text-lg font-semibold\">\ud83e\udde0 Sync & Refresh Docs</h2>\n      <div className=\"flex flex-wrap gap-2\">\n        <Button onClick={() => triggerSync(\"sync\")} disabled={loading}>\n          {loading ? \"\u23f3 Syncing...\" : \"\ud83d\udd04 Sync Google Docs\"}\n        </Button>\n        <Button onClick={() => triggerSync(\"refresh_kb\")} disabled={loading}>\n          {loading ? \"\u23f3 Refreshing...\" : \"\ud83e\udde0 Refresh KB\"}\n        </Button>\n        <Button onClick={() => triggerSync(\"full_sync\")} disabled={loading}>\n          {loading ?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3778, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "11682fed-6d09-48b0-86e0-5a1dde7b4733": {"__data__": {"id_": "11682fed-6d09-48b0-86e0-5a1dde7b4733", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/DocsSyncPanel.tsx", "file_name": "DocsSyncPanel.tsx", "file_size": 5158, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d44bd992-6ce4-40f7-ae55-7b28865993ab", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/DocsSyncPanel.tsx", "file_name": "DocsSyncPanel.tsx", "file_size": 5158, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "8b64527db203ee5d0c52ab3449b82a007bccb892e6e41ba916421e5cdeb2d83d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "26c90ccc-285c-47f4-8666-51aabf6550dd", "node_type": "1", "metadata": {"file_path": "/app/frontend/src/components/DocsSyncPanel.tsx", "file_name": "DocsSyncPanel.tsx", "file_size": 5158, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "923857c6a857e8ed0ffe2928a06c6e1ff4e10f7fdc0a1bdaed69c699822a92a7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\u23f3 Syncing...\" : \"\ud83d\udd04 Sync Google Docs\"}\n        </Button>\n        <Button onClick={() => triggerSync(\"refresh_kb\")} disabled={loading}>\n          {loading ? \"\u23f3 Refreshing...\" : \"\ud83e\udde0 Refresh KB\"}\n        </Button>\n        <Button onClick={() => triggerSync(\"full_sync\")} disabled={loading}>\n          {loading ? \"\u23f3 Working...\" : \"\ud83d\ude80 Full Sync\"}\n        </Button>\n      </div>\n\n      {/* Status messages rendered as markdown */}\n      {status && (\n        <div className=\"mt-2 text-sm text-muted-foreground\">\n          <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n            <SafeMarkdown>{status}</SafeMarkdown>\n          </div>\n        </div>\n      )}\n\n      {files.length > 0 && (\n        <ul className=\"mt-2 list-disc list-inside\">\n          {files.map((f) => (\n            <li key={f} className=\"text-sm\">{f}</li>\n          ))}\n        </ul>\n      )}\n\n      {/* Divider */}\n      <hr className=\"my-4\" />\n\n      {/* Reindex Button */}\n      <div>\n        <h3 className=\"text-base font-medium mb-2\">Admin: Reindex KB</h3>\n        <Button\n          onClick={triggerReindex}\n          disabled={reindexLoading}\n          variant=\"destructive\"\n          className=\"mb-2\"\n        >\n          {reindexLoading ? \"\u23f3 Reindexing...\" : \"\ud83d\udee0\ufe0f Reindex Now\"}\n        </Button>\n        {reindexStatus && (\n          <div className={`mt-1 text-sm ${reindexStatus.startsWith(\"\u2705\") ? \"text-green-600\" : \"text-red-500\"}`}>\n            <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n              <SafeMarkdown>{reindexStatus}</SafeMarkdown>\n            </div>\n          </div>\n        )}\n      </div>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 3471, "end_char_idx": 5108, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d1c4300f-73ed-49bd-be00-ba6a0e0a18f7": {"__data__": {"id_": "d1c4300f-73ed-49bd-be00-ba6a0e0a18f7", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/DocsViewer/DocsViewer.tsx", "file_name": "DocsViewer.tsx", "file_size": 8731, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "23799d7c-22c2-480e-ae05-ff4ec90a60e5", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/DocsViewer/DocsViewer.tsx", "file_name": "DocsViewer.tsx", "file_size": 8731, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "ce2b8dcc445f1125469cd861f8173f1be439b4cbf6dffdacab15444bc992e980", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "61d504e1-9a69-4c1c-88a1-a952e3e9e59c", "node_type": "1", "metadata": {}, "hash": "63e7876707afe439daa1522cd23f0de76dc771e33a82805a4888fcf0f8e573d7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: frontend/src/components/DocsViewer.tsx\n// Purpose: Browse, manage, and debug semantic context docs with tier-aware metadata.\n//          Renders all doc/snippet/context output via SafeMarkdown for safety/uniformity.\n\n\"use client\";\n\nimport { API_ROOT } from \"@/lib/api\";\nimport { useEffect, useState } from \"react\";\nimport { Button } from \"@/components/ui/button\";\nimport SafeMarkdown from \"@/components/SafeMarkdown\";\n\n// --- Types for KB docs and semantic search ---\ntype KBMeta = {\n  path: string;\n  doc_id?: string;\n  tier?: string;\n  source?: string;\n  last_modified?: string;\n};\n\ntype KBHit = {\n  file?: string;\n  snippet: string;\n  score?: number;\n  type?: string;\n  line?: number;\n};\n\nconst apiUrl = API_ROOT || \"\";\n\n// --- Main DocsViewer Component ---\nexport default function DocsViewer() {\n  const [tab, setTab] = useState<\"docs\" | \"search\" | \"context\">(\"docs\");\n  const [docs, setDocs] = useState<KBMeta[]>([]);\n  const [activeDoc, setActiveDoc] = useState<string | null>(null);\n  const [content, setContent] = useState<string>(\"\");\n\n  const [search, setSearch] = useState(\"\");\n  const [hits, setHits] = useState<KBHit[]>([]);\n  const [selectedHit, setSelectedHit] = useState<number | null>(null);\n  const [searchLoading, setSearchLoading] = useState(false);\n\n  const [ctxQuestion, setCtxQuestion] = useState(\"\");\n  const [ctxLoading, setCtxLoading] = useState(false);\n  const [ctxResult, setCtxResult] = useState<string>(\"\");\n\n  useEffect(() => {\n    if (tab === \"docs\") loadDocs();\n  }, [tab]);\n\n  useEffect(() => {\n    if (activeDoc) loadContent(activeDoc);\n    else setContent(\"\");\n  }, [activeDoc]);\n\n  async function loadDocs() {\n    try {\n      const res = await fetch(`${apiUrl}/docs/list`);\n      const data = await res.json();\n      setDocs(data.files || []);\n    } catch {\n      setDocs([]);\n    }\n  }\n\n  async function loadContent(path: string) {\n    try {\n      const res = await fetch(`${apiUrl}/docs/view?path=${encodeURIComponent(path)}`);\n      const data = await res.json();\n      setContent(data.content || \"\");\n    } catch {\n      setContent(\"Failed to load doc.\");\n    }\n  }\n\n  async function doSearch(e?: React.FormEvent) {\n    if (e) e.preventDefault();\n    setSearchLoading(true);\n    setHits([]);\n    setSelectedHit(null);\n    try {\n      const res = await fetch(`${apiUrl}/kb/search?query=${encodeURIComponent(search)}`);\n      const data = await res.json();\n      setHits(data.results || []);\n    } catch {\n      setHits([]);\n    }\n    setSearchLoading(false);\n  }\n\n  async function fetchContextForPrompt(e?: React.FormEvent) {\n    if (e) e.preventDefault();\n    if (!ctxQuestion) return;\n    setCtxLoading(true);\n    setCtxResult(\"\");\n    try {\n      const res = await fetch(`${apiUrl}/ask?question=${encodeURIComponent(ctxQuestion)}&debug=true`);\n      const data = await res.json();\n      setCtxResult(data.context || \"No context returned.\");\n    } catch {\n      setCtxResult(\"Failed to fetch context window.\");\n    }\n    setCtxLoading(false);\n  }\n\n  if (typeof content !== \"string\") {\n    console.log(\"DEBUG 418:\", typeof content, content);\n  }\n  for (const hit of hits) {\n    if (typeof hit.snippet !== \"string\") {\n      console.log(\"DEBUG 418:\", typeof hit.snippet, hit.snippet);\n    }\n  }\n  if (ctxResult && typeof ctxResult !== \"string\") {\n    console.log(\"DEBUG 418:\", typeof ctxResult, ctxResult);\n  }\n\n  return (\n    <div className=\"max-w-5xl mx-auto py-6\">\n      <div className=\"flex gap-4 mb-4\">\n        <Button variant={tab === \"docs\" ? \"default\" : \"outline\"} onClick={() => setTab(\"docs\")}>\ud83d\udcdd Docs</Button>\n        <Button variant={tab === \"search\" ? \"default\" : \"outline\"} onClick={() => setTab(\"search\")}>\ud83d\udd0d Semantic Search</Button>\n        <Button variant={tab === \"context\" ?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3739, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "61d504e1-9a69-4c1c-88a1-a952e3e9e59c": {"__data__": {"id_": "61d504e1-9a69-4c1c-88a1-a952e3e9e59c", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/DocsViewer/DocsViewer.tsx", "file_name": "DocsViewer.tsx", "file_size": 8731, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "23799d7c-22c2-480e-ae05-ff4ec90a60e5", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/DocsViewer/DocsViewer.tsx", "file_name": "DocsViewer.tsx", "file_size": 8731, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "ce2b8dcc445f1125469cd861f8173f1be439b4cbf6dffdacab15444bc992e980", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d1c4300f-73ed-49bd-be00-ba6a0e0a18f7", "node_type": "1", "metadata": {"file_path": "/app/frontend/src/components/DocsViewer/DocsViewer.tsx", "file_name": "DocsViewer.tsx", "file_size": 8731, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "ccb0aa7737c229fbbd8a1451398cb2cc45d01fd3a0f5c71133dac6efa65e8759", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1b1ef0a5-8ca0-4c55-9fad-ec209b4db9dd", "node_type": "1", "metadata": {}, "hash": "0a9c3d89e2f70e07a6ee363990c8c7df204a1564641ffe71a83710da1c3add3d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"default\" : \"outline\"} onClick={() => setTab(\"docs\")}>\ud83d\udcdd Docs</Button>\n        <Button variant={tab === \"search\" ? \"default\" : \"outline\"} onClick={() => setTab(\"search\")}>\ud83d\udd0d Semantic Search</Button>\n        <Button variant={tab === \"context\" ? \"default\" : \"outline\"} onClick={() => setTab(\"context\")}>\ud83e\udde0 Agent Context</Button>\n      </div>\n\n      {tab === \"docs\" && (\n        <div className=\"grid grid-cols-1 md:grid-cols-6 gap-6\">\n          <div className=\"space-y-4 col-span-1 md:col-span-1\">\n            <div>\n              <div className=\"font-semibold mb-2\">Knowledge Base Files</div>\n              <ul className=\"space-y-1 text-xs max-h-80 overflow-y-auto\">\n                {docs.map((doc) => (\n                  <li key={doc.path}>\n                    <button\n                      className={`w-full text-left py-1 px-2 rounded hover:bg-accent/40 ${activeDoc === doc.path ? \"bg-accent/30 font-bold\" : \"\"}`}\n                      onClick={() => setActiveDoc(doc.path)}\n                    >\n                      {doc.path}\n                      {doc.tier && <span className=\"ml-2 text-emerald-600 font-semibold\">[{doc.tier}]</span>}\n                      {doc.source && <span className=\"ml-1 text-xs text-gray-400\">({doc.source})</span>}\n                    </button>\n                  </li>\n                ))}\n              </ul>\n            </div>\n          </div>\n          <div className=\"col-span-5\">\n            <h2 className=\"font-semibold mb-2\">{activeDoc || \"Select a document\"}</h2>\n            <div className=\"h-[400px] overflow-auto border rounded-md p-4 whitespace-pre-wrap text-sm bg-background\">\n              {content ? (\n                <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n                  <SafeMarkdown>{content}</SafeMarkdown>\n                </div>\n              ) : (\n                \"Select a document to view its content.\"\n              )}\n            </div>\n          </div>\n        </div>\n      )}\n\n      {tab === \"search\" && (\n        <div className=\"grid grid-cols-1 md:grid-cols-6 gap-6\">\n          <div className=\"space-y-4 col-span-1\">\n            <form className=\"flex gap-2 mb-2\" onSubmit={doSearch}>\n              <input\n                className=\"border px-2 py-1 rounded w-full\"\n                placeholder=\"Search docs/knowledge base\u2026\"\n                value={search}\n                onChange={(e) => setSearch(e.target.value)}\n              />\n              <Button type=\"submit\" size=\"sm\" disabled={searchLoading}>\n                {searchLoading ? \"\u2026\" : \"Search\"}\n              </Button>\n            </form>\n            <ul className=\"space-y-1 text-xs max-h-72 overflow-y-auto\">\n              {hits.map((hit, i) => (\n                <li key={i}>\n                  <button\n                    className={`w-full text-left py-1 px-2 rounded hover:bg-accent/30 ${selectedHit === i ? \"bg-accent/40 font-bold\" : \"\"}`}\n                    onClick={() => setSelectedHit(i)}\n                  >\n                    {hit.file || \"Semantic Snippet\"}\n                  </button>\n                </li>\n              ))}\n            </ul>\n          </div>\n          <div className=\"col-span-5\">\n            {selectedHit !== null && hits[selectedHit] ? (\n              <div>\n                <div className=\"font-bold mb-2\">{hits[selectedHit].file || \"Semantic Snippet\"}</div>\n                <div className=\"bg-gray-100 p-3 rounded max-h-[70vh] overflow-y-auto whitespace-pre-wrap text-xs\">\n                  <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n                    <SafeMarkdown>{hits[selectedHit].snippet}</SafeMarkdown>\n                  </div>\n                </div>\n                <div className=\"text-xs text-gray-500 mt-2\">\n                  Score: {hits[selectedHit].score?.toFixed(2) || \"N/A\"} | Type: {hits[selectedHit].type || \"?\"}\n                </div>\n              </div>\n            ) : (\n              <div className=\"text-gray-500 text-center pt-10\">\n                {searchLoading ? \"Searching\u2026\" : \"Select a semantic hit to preview context.\"}", "mimetype": "text/plain", "start_char_idx": 3498, "end_char_idx": 7552, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1b1ef0a5-8ca0-4c55-9fad-ec209b4db9dd": {"__data__": {"id_": "1b1ef0a5-8ca0-4c55-9fad-ec209b4db9dd", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/DocsViewer/DocsViewer.tsx", "file_name": "DocsViewer.tsx", "file_size": 8731, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "23799d7c-22c2-480e-ae05-ff4ec90a60e5", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/DocsViewer/DocsViewer.tsx", "file_name": "DocsViewer.tsx", "file_size": 8731, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "ce2b8dcc445f1125469cd861f8173f1be439b4cbf6dffdacab15444bc992e980", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "61d504e1-9a69-4c1c-88a1-a952e3e9e59c", "node_type": "1", "metadata": {"file_path": "/app/frontend/src/components/DocsViewer/DocsViewer.tsx", "file_name": "DocsViewer.tsx", "file_size": 8731, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "4b61977fcd4169228d6cae49024eb07fea563616ea61d1e32535379434793e57", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "(\n              <div>\n                <div className=\"font-bold mb-2\">{hits[selectedHit].file || \"Semantic Snippet\"}</div>\n                <div className=\"bg-gray-100 p-3 rounded max-h-[70vh] overflow-y-auto whitespace-pre-wrap text-xs\">\n                  <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n                    <SafeMarkdown>{hits[selectedHit].snippet}</SafeMarkdown>\n                  </div>\n                </div>\n                <div className=\"text-xs text-gray-500 mt-2\">\n                  Score: {hits[selectedHit].score?.toFixed(2) || \"N/A\"} | Type: {hits[selectedHit].type || \"?\"}\n                </div>\n              </div>\n            ) : (\n              <div className=\"text-gray-500 text-center pt-10\">\n                {searchLoading ? \"Searching\u2026\" : \"Select a semantic hit to preview context.\"}\n              </div>\n            )}\n          </div>\n        </div>\n      )}\n\n      {tab === \"context\" && (\n        <div className=\"max-w-2xl mx-auto mt-8\">\n          <form className=\"flex gap-2 mb-4\" onSubmit={fetchContextForPrompt}>\n            <input\n              className=\"border px-2 py-1 rounded w-full\"\n              placeholder=\"Type a user/agent prompt\u2026\"\n              value={ctxQuestion}\n              onChange={(e) => setCtxQuestion(e.target.value)}\n            />\n            <Button type=\"submit\" disabled={ctxLoading}>\n              {ctxLoading ? \"\u2026\" : \"Show Context\"}\n            </Button>\n          </form>\n          <div className=\"h-[400px] overflow-auto border rounded-md p-4 whitespace-pre-wrap text-xs bg-gray-50\">\n            {ctxLoading\n              ? \"Fetching context\u2026\"\n              : ctxResult\n              ? (\n                <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n                  <SafeMarkdown>{ctxResult}</SafeMarkdown>\n                </div>\n              )\n              : \"Enter a prompt to see what context the agent would use.\"}\n          </div>\n        </div>\n      )}\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 6713, "end_char_idx": 8709, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fed6c76e-7e0c-4e4c-8dc2-6e48f4df0e2f": {"__data__": {"id_": "fed6c76e-7e0c-4e4c-8dc2-6e48f4df0e2f", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/GmailOps/GmailOpsPanel.tsx", "file_name": "GmailOpsPanel.tsx", "file_size": 3509, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0266c43c-8f5d-47fa-9597-4d31d98e5c50", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/GmailOps/GmailOpsPanel.tsx", "file_name": "GmailOpsPanel.tsx", "file_size": 3509, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "6435f81614ce92d9c54625249b508806dc7d4bd9d5a3f54be35f354fdfde1f80", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: components/GmailOps/GmailOpsPanel.tsx\n// Purpose: Panel to send and view emails, now with SafeMarkdown rendering for messages and snippets.\n\n\"use client\";\nimport { useState } from \"react\";\nimport { Button } from \"@/components/ui/button\";\nimport { API_ROOT } from \"@/lib/api\";\nimport SafeMarkdown from \"@/components/SafeMarkdown\";\nimport { toMDString } from \"@/lib/toMDString\";\n\n// Explicitly type the Email shape\ntype Email = {\n  from: string;\n  subject: string;\n  date: string;\n  snippet: string;\n};\n\nexport default function GmailOpsPanel() {\n  const [to, setTo] = useState(\"\");\n  const [subject, setSubject] = useState(\"\");\n  const [body, setBody] = useState(\"\");\n  const [msg, setMsg] = useState<string | null>(null);\n  const [emails, setEmails] = useState<Email[]>([]);\n\n  async function send() {\n    const res = await fetch(`${API_ROOT}/control/send_email`, {\n      method: \"POST\",\n      headers: { \"Content-Type\": \"application/json\", \"X-API-Key\": process.env.NEXT_PUBLIC_API_KEY || \"\" },\n      body: JSON.stringify({ to_email: to, subject, body })\n    });\n    const data = await res.json();\n    setMsg(\n      toMDString(\n        data.status === \"sent\" ? \"Email sent!\" : `Failed: ${data.detail}`\n      )\n    );\n  }\n\n  async function list() {\n    const res = await fetch(`${API_ROOT}/control/list_email`, {\n      headers: { \"X-API-Key\": process.env.NEXT_PUBLIC_API_KEY || \"\" }\n    });\n    const data = await res.json();\n    const mapped = Array.isArray(data.emails)\n      ? (data.emails as Email[]).map((em) => ({\n          ...em,\n          snippet: toMDString(em.snippet),\n        }))\n      : [];\n    setEmails(mapped);\n  }\n\n  if (msg && typeof msg !== \"string\") {\n    console.log(\"DEBUG 418:\", typeof msg, msg);\n  }\n  for (const em of emails) {\n    if (typeof em.snippet !== \"string\") {\n      console.log(\"DEBUG 418:\", typeof em.snippet, em.snippet);\n    }\n  }\n\n  return (\n    <div className=\"max-w-2xl mx-auto my-8 space-y-4\">\n      <div>\n        <h3 className=\"font-bold mb-2\">Send Email</h3>\n        <input className=\"border rounded px-2 py-1 w-full mb-1\" placeholder=\"To Email\" value={to} onChange={e => setTo(e.target.value)} />\n        <input className=\"border rounded px-2 py-1 w-full mb-1\" placeholder=\"Subject\" value={subject} onChange={e => setSubject(e.target.value)} />\n        <textarea className=\"border rounded px-2 py-1 w-full mb-2\" placeholder=\"Body\" rows={4} value={body} onChange={e => setBody(e.target.value)} />\n        <Button onClick={send}>Send Email</Button>\n        {msg && (\n          <div className=\"text-xs mt-2\">\n            <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n              <SafeMarkdown>{msg}</SafeMarkdown>\n            </div>\n          </div>\n        )}\n      </div>\n      <div>\n        <h3 className=\"font-bold mb-2\">List Recent Emails</h3>\n        <Button onClick={list}>Refresh Inbox</Button>\n        <ul className=\"mt-2 space-y-1\">\n          {emails.map((em, i) => (\n            <li key={i} className=\"bg-gray-100 rounded p-2 text-xs\">\n              <div><strong>From:</strong> {em.from}</div>\n              <div><strong>Subject:</strong> {em.subject}</div>\n              <div><strong>Date:</strong> {em.date}</div>\n              <div className=\"text-gray-500\">\n                <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n                  <SafeMarkdown>{em.snippet}</SafeMarkdown>\n                </div>\n              </div>\n            </li>\n          ))}\n        </ul>\n      </div>\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3508, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "14ab5de3-8e58-47f3-9063-fce033c5b9da": {"__data__": {"id_": "14ab5de3-8e58-47f3-9063-fce033c5b9da", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/LogsPanel/LogsPanel.tsx", "file_name": "LogsPanel.tsx", "file_size": 7092, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f9372f71-cf56-4421-b94b-ba81ef2c132c", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/LogsPanel/LogsPanel.tsx", "file_name": "LogsPanel.tsx", "file_size": 7092, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "704e7de9ad95b9046e07a6a50c680368d0d0578ae407a3e337bc00743944a05d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "70f2aa1c-d8c2-45dd-9f59-f7ca7088654b", "node_type": "1", "metadata": {}, "hash": "42a9138466db756ee0ae8859c9a76a4b7cc3b822013248a80d89766a77928a8e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: frontend/src/components/LogsPanel/LogsPanel.tsx\n// Purpose: Production-grade system log/audit/error viewer with filtering, searching, stack trace viewing, and CSV/JSON export.\n\n\"use client\";\n\nimport { useEffect, useState, useCallback } from \"react\";\nimport { Card, CardContent } from \"@/components/ui/card\";\nimport { Button } from \"@/components/ui/button\";\nimport { API_ROOT } from \"@/lib/api\";\nimport SafeMarkdown from \"@/components/SafeMarkdown\";\n\nexport interface AuditLogEntry {\n  id: string;\n  time: string;\n  source: string;\n  level: string;\n  message: string;\n  stack_trace?: string;\n  [key: string]: unknown;\n}\n\n// === Utility Export Functions =================================================\nfunction exportJSON(logs: AuditLogEntry[]) {\n  const blob = new Blob([JSON.stringify(logs, null, 2)], { type: \"application/json\" });\n  const url = URL.createObjectURL(blob);\n  const link = document.createElement(\"a\");\n  link.href = url;\n  link.download = \"logs_audit.json\";\n  link.click();\n  URL.revokeObjectURL(url);\n}\n\nfunction exportCSV(logs: AuditLogEntry[]) {\n  const headers = [\"time\", \"source\", \"level\", \"message\"];\n  const csvRows = [headers.join(\",\")];\n\n  logs.forEach(entry => {\n    const row = [\n      entry.time,\n      entry.source,\n      entry.level,\n      (entry.message || \"\").toString().replace(/\"/g, '\"\"').replace(/\\n/g, \"\\\\n\"),\n    ].map(field => `\"${field}\"`);\n    csvRows.push(row.join(\",\"));\n  });\n\n  const blob = new Blob([csvRows.join(\"\\n\")], { type: \"text/csv\" });\n  const url = URL.createObjectURL(blob);\n  const link = document.createElement(\"a\");\n  link.href = url;\n  link.download = \"logs_audit.csv\";\n  link.click();\n  URL.revokeObjectURL(url);\n}\n\n// === Main Component ============================================================\nexport default function LogsPanel() {\n  const [logs, setLogs] = useState<AuditLogEntry[]>([]);\n  const [autoRefresh, setAutoRefresh] = useState(true);\n  const [levelFilter, setLevelFilter] = useState<string>(\"\");\n  const [sourceFilter, setSourceFilter] = useState<string>(\"\");\n  const [searchText, setSearchText] = useState<string>(\"\");\n  const [error, setError] = useState<string | null>(null);\n\n  const fetchLogs = useCallback(async () => {\n    try {\n      setError(null);\n      const params = new URLSearchParams();\n      if (levelFilter) params.append(\"level_filter\", levelFilter);\n      params.append(\"n\", \"100\");\n\n      const res = await fetch(`${API_ROOT}/logs/recent?${params.toString()}`, {\n        headers: {\n          \"X-API-Key\": (process.env.NEXT_PUBLIC_API_KEY as string) || \"\",\n        },\n      });\n\n      if (!res.ok) throw new Error(`Error fetching logs: ${res.status}`);\n\n      const data = await res.json();\n\n      const mapped: AuditLogEntry[] = Array.isArray(data.logs)\n        ? data.logs.map((entry: Record<string, unknown>, idx: number) => ({\n            id: String(entry.id || entry.time || idx),\n            time: String(entry.time || \"\"),\n            source: String(entry.source || \"system\"),\n            level: String(entry.level || \"INFO\"),\n            message: String(entry.message || \"\"),\n            stack_trace: typeof entry.stack_trace === \"string\" ? entry.stack_trace : \"\",\n            ...entry,\n          }))\n        : [];\n\n      setLogs(mapped);\n    } catch (e: unknown) {\n      const err = e instanceof Error ?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3318, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "70f2aa1c-d8c2-45dd-9f59-f7ca7088654b": {"__data__": {"id_": "70f2aa1c-d8c2-45dd-9f59-f7ca7088654b", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/LogsPanel/LogsPanel.tsx", "file_name": "LogsPanel.tsx", "file_size": 7092, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f9372f71-cf56-4421-b94b-ba81ef2c132c", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/LogsPanel/LogsPanel.tsx", "file_name": "LogsPanel.tsx", "file_size": 7092, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "704e7de9ad95b9046e07a6a50c680368d0d0578ae407a3e337bc00743944a05d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "14ab5de3-8e58-47f3-9063-fce033c5b9da", "node_type": "1", "metadata": {"file_path": "/app/frontend/src/components/LogsPanel/LogsPanel.tsx", "file_name": "LogsPanel.tsx", "file_size": 7092, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "5236edbd3c57cfed57380870f711b960146ee508134f2e5940e2e1f5b0372b36", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "724a395a-dc03-412b-9572-e697902c6a5c", "node_type": "1", "metadata": {}, "hash": "d0cf512d6cfc972f411e4066734951f362966e2a51b4c8e438396a647bf5ffbd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "data.logs.map((entry: Record<string, unknown>, idx: number) => ({\n            id: String(entry.id || entry.time || idx),\n            time: String(entry.time || \"\"),\n            source: String(entry.source || \"system\"),\n            level: String(entry.level || \"INFO\"),\n            message: String(entry.message || \"\"),\n            stack_trace: typeof entry.stack_trace === \"string\" ? entry.stack_trace : \"\",\n            ...entry,\n          }))\n        : [];\n\n      setLogs(mapped);\n    } catch (e: unknown) {\n      const err = e instanceof Error ? e : new Error(\"Unknown error\");\n      setError(err.message);\n    }\n  }, [levelFilter]);\n\n  useEffect(() => {\n    fetchLogs();\n    if (!autoRefresh) return;\n    const interval = setInterval(fetchLogs, 15000);\n    return () => clearInterval(interval);\n  }, [autoRefresh, levelFilter, fetchLogs]);\n\n  const uniqueSources = Array.from(new Set(logs.map(log => log.source))).sort();\n\n  const filteredLogs = logs.filter(entry => {\n    const matchesLevel = !levelFilter || entry.level === levelFilter;\n    const matchesSource = !sourceFilter || entry.source === sourceFilter;\n    const matchesSearch =\n      !searchText ||\n      JSON.stringify(entry).toLowerCase().includes(searchText.toLowerCase());\n\n    return matchesLevel && matchesSource && matchesSearch;\n  });\n\n  if (error) {\n    return (\n      <p className=\"text-red-600 font-mono p-4 bg-red-50 rounded\">\n        Failed to load logs: {error}\n      </p>\n    );\n  }\n\n  if (!filteredLogs.length) {\n    return (\n      <p className=\"text-muted-foreground\">\n        No log entries\n        {levelFilter ? ` of level '${levelFilter}'` : \"\"}\n        {sourceFilter ? ` from '${sourceFilter}'` : \"\"} found.\n      </p>\n    );\n  }\n\n  return (\n    <div className=\"space-y-4\">\n      {/* Controls */}\n      <div className=\"flex flex-wrap gap-4 mb-4 items-center\">\n        <Button\n          variant={autoRefresh ? \"default\" : \"outline\"}\n          onClick={() => setAutoRefresh(!autoRefresh)}\n        >\n          {autoRefresh ? \"Auto-Refresh ON\" : \"Auto-Refresh OFF\"}\n        </Button>\n        <span className=\"text-sm text-gray-500\">Log updates every 15s</span>\n\n        <select\n          className=\"border rounded px-2 py-1 text-sm\"\n          value={levelFilter}\n          onChange={e => setLevelFilter(e.target.value)}\n        >\n          <option value=\"\">All Levels</option>\n          <option value=\"INFO\">INFO</option>\n          <option value=\"ERROR\">ERROR</option>\n          <option value=\"WARNING\">WARNING</option>\n        </select>\n\n        <select\n          className=\"border rounded px-2 py-1 text-sm\"\n          value={sourceFilter}\n          onChange={e => setSourceFilter(e.target.value)}\n        >\n          <option value=\"\">All Sources</option>\n          {uniqueSources.map(source => (\n            <option key={source} value={source}>\n              {source}\n            </option>\n          ))}\n        </select>\n\n        <input\n          type=\"text\"\n          placeholder=\"Search logs...\"\n          value={searchText}\n          onChange={e => setSearchText(e.target.value)}\n          className=\"border rounded px-2 py-1 text-sm w-60\"\n        />\n\n        <Button onClick={() => exportJSON(filteredLogs)} variant=\"secondary\">\n          Download JSON\n        </Button>\n        <Button onClick={() => exportCSV(filteredLogs)} variant=\"outline\">\n          Export CSV\n        </Button>\n      </div>\n\n      {/* Log Entries */}\n      {filteredLogs.map(entry => (\n        <Card key={entry.id} className={entry.level === \"ERROR\" ?", "mimetype": "text/plain", "start_char_idx": 2771, "end_char_idx": 6285, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "724a395a-dc03-412b-9572-e697902c6a5c": {"__data__": {"id_": "724a395a-dc03-412b-9572-e697902c6a5c", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/LogsPanel/LogsPanel.tsx", "file_name": "LogsPanel.tsx", "file_size": 7092, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f9372f71-cf56-4421-b94b-ba81ef2c132c", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/LogsPanel/LogsPanel.tsx", "file_name": "LogsPanel.tsx", "file_size": 7092, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "704e7de9ad95b9046e07a6a50c680368d0d0578ae407a3e337bc00743944a05d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "70f2aa1c-d8c2-45dd-9f59-f7ca7088654b", "node_type": "1", "metadata": {"file_path": "/app/frontend/src/components/LogsPanel/LogsPanel.tsx", "file_name": "LogsPanel.tsx", "file_size": 7092, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "bb20a55ecb0fc483840cb5b7fe4cc9e2148a72df71f0d7be133c2b19d07c549c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"border-red-400\" : \"\"}>\n          <CardContent className=\"p-4 space-y-2\">\n            <div className=\"text-xs font-mono text-muted-foreground\">\n              {entry.time} \u2022 <span className=\"font-bold\">{entry.source}</span> [{entry.level}]\n            </div>\n            <div className=\"text-sm break-words\">\n              <SafeMarkdown>{entry.message}</SafeMarkdown>\n            </div>\n            {entry.stack_trace && (\n              <details>\n                <summary className=\"text-red-700 cursor-pointer\">Stack trace</summary>\n                <pre className=\"bg-red-100 text-xs p-2 rounded overflow-x-auto whitespace-pre-wrap\">\n                  {entry.stack_trace}\n                </pre>\n              </details>\n            )}\n          </CardContent>\n        </Card>\n      ))}\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 6286, "end_char_idx": 7089, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2477c90a-7e6a-4ffc-81f9-8942ab49f8e9": {"__data__": {"id_": "2477c90a-7e6a-4ffc-81f9-8942ab49f8e9", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/MemoryPanel.tsx", "file_name": "MemoryPanel.tsx", "file_size": 13812, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1ea75db3-ccf0-490f-9fa0-7f528c129dc2", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/MemoryPanel.tsx", "file_name": "MemoryPanel.tsx", "file_size": 13812, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "fe471f0167c1d4d702f3817eb231e66cffb71a67a62cf06bf352053edcae43dd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "82d59c41-dafb-4aae-abd0-88f8cd260700", "node_type": "1", "metadata": {}, "hash": "22e9239df320bfd134ddccbf5e7dec143159ce88280e672b61ca9299ae777335", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: frontend/src/components/MemoryPanel.tsx\n// Purpose: Robust, scalable, tier-aware memory inspector with pagination, user filtering, tag/save, date filtering, and replay support.\n//          Now supports Markdown/code in summary, agent response, and context modals via SafeMarkdown.\n\n\"use client\"\n\nimport { useEffect, useMemo, useState } from \"react\"\nimport { Card, CardContent } from \"@/components/ui/card\"\nimport { Button } from \"@/components/ui/button\"\nimport { API_ROOT } from \"@/lib/api\"\nimport SafeMarkdown from \"@/components/SafeMarkdown\"\nimport { toMDString } from \"@/lib/toMDString\"\n\ninterface ContextSource {\n  type: string\n  title?: string\n  path?: string\n  tier?: string\n  score?: number\n  doc_id?: string\n}\n\ninterface MemoryEntry {\n  timestamp: string\n  user: string\n  query: string\n  topics?: string[]\n  files?: string[]\n  summary?: string\n  context_length?: number\n  used_global_context?: boolean\n  context_files?: string[]\n  files_used?: ContextSource[]\n  agent_response?: string\n  prompt_length?: number\n  response_length?: number\n  fallback?: boolean\n  tags?: string[]\n  saved?: boolean\n}\n\nconst isNonEmptyArray = <T,>(arr?: T[] | null): arr is T[] => Array.isArray(arr) && arr.length > 0\n\nexport default function MemoryPanel() {\n  const [memory, setMemory] = useState<MemoryEntry[]>([])\n  const [search, setSearch] = useState(\"\")\n  const [filterUser, setFilterUser] = useState(\"\")\n  const [filterGlobal, setFilterGlobal] = useState<\"any\" | \"with\" | \"without\">(\"any\")\n  const [filterDays, setFilterDays] = useState(7)\n  const [fetchInfo, setFetchInfo] = useState({\n    status: \"idle\",\n    time: 0,\n    error: undefined as string | undefined,\n  })\n  const [modalContext, setModalContext] = useState<{ path: string; content: string } | null>(null)\n\n  const [currentPage, setCurrentPage] = useState(1)\n  const pageSize = 10\n\n  useEffect(() => {\n    fetchMemory()\n  }, [])\n\n  async function fetchMemory() {\n    const start = Date.now()\n    setFetchInfo({ status: \"loading\", time: 0, error: undefined })\n\n    try {\n      const res = await fetch(`${API_ROOT}/logs/sessions/all`, {\n        headers: { \"X-API-Key\": process.env.NEXT_PUBLIC_API_KEY || \"\" },\n      })\n      if (!res.ok) throw new Error(`Status ${res.status}`)\n      const data = await res.json()\n      const mapped = (data.entries || []).map((m: unknown) => {\n        const entry = m as Partial<MemoryEntry>\n        return {\n          ...entry,\n          summary: toMDString(entry.summary),\n          agent_response: toMDString(entry.agent_response),\n        }\n      })\n      setMemory(mapped)\n      setFetchInfo({ status: \"success\", time: Date.now() - start, error: \"\" })\n    } catch (e: unknown) {\n      const errorMsg = e instanceof Error ?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2724, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "82d59c41-dafb-4aae-abd0-88f8cd260700": {"__data__": {"id_": "82d59c41-dafb-4aae-abd0-88f8cd260700", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/MemoryPanel.tsx", "file_name": "MemoryPanel.tsx", "file_size": 13812, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1ea75db3-ccf0-490f-9fa0-7f528c129dc2", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/MemoryPanel.tsx", "file_name": "MemoryPanel.tsx", "file_size": 13812, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "fe471f0167c1d4d702f3817eb231e66cffb71a67a62cf06bf352053edcae43dd", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2477c90a-7e6a-4ffc-81f9-8942ab49f8e9", "node_type": "1", "metadata": {"file_path": "/app/frontend/src/components/MemoryPanel.tsx", "file_name": "MemoryPanel.tsx", "file_size": 13812, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "3622b4df3634cf0197e81f38ecdda96cc98e173b54528ab029f6555f7e72e75b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cdce9102-8e6a-4cfc-aa04-258a04a71219", "node_type": "1", "metadata": {}, "hash": "dafe6d5c45c52f4f18659c30ea6f68530eb5079353feae41a8df26732475a72c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "e.message : String(e)\n      setFetchInfo({ status: \"error\", time: Date.now() - start, error: errorMsg })\n      setMemory([])\n    }\n  }\n\n  async function fetchContextFile(path: string) {\n    try {\n      const res = await fetch(`${API_ROOT}/files/context?path=${encodeURIComponent(path)}`, {\n        headers: { \"X-API-Key\": process.env.NEXT_PUBLIC_API_KEY || \"\" },\n      })\n      if (!res.ok) throw new Error(`Status ${res.status}`)\n      const content = await res.text()\n      setModalContext({ path, content })\n    } catch (e) {\n      setModalContext({ path, content: `Failed to fetch: ${e}` })\n    }\n  }\n\n  function toggleSave(index: number) {\n    setMemory(prev => {\n      const clone = [...prev]\n      clone[index].saved = !clone[index].saved\n      return clone\n    })\n  }\n\n  function toggleTag(index: number, tag: string) {\n    setMemory(prev => {\n      const clone = [...prev]\n      const tags = new Set(clone[index].tags || [])\n      if (tags.has(tag)) {\n        tags.delete(tag)\n      } else {\n        tags.add(tag)\n      }\n      clone[index].tags = Array.from(tags)\n      return clone\n    })\n  }\n\n  const users = useMemo(() => Array.from(new Set(memory.map(m => m.user))).sort(), [memory])\n\n  const filtered = useMemo(() => {\n    const now = Date.now()\n    const cutoff = now - filterDays * 24 * 60 * 60 * 1000\n\n    return memory\n      .filter(m => {\n        const matchUser = !filterUser || m.user === filterUser\n        const matchSearch = !search || JSON.stringify(m).toLowerCase().includes(search.toLowerCase())\n        const matchGlobal =\n          filterGlobal === \"any\"\n            ? true\n            : filterGlobal === \"with\"\n            ? !!m.used_global_context\n            : !m.used_global_context\n        const matchTime = new Date(m.timestamp).getTime() >= cutoff\n        return matchUser && matchSearch && matchGlobal && matchTime\n      })\n      .sort((a, b) => {\n        const tierScore = (tier?: string) => (tier === \"global\" ? 3 : tier === \"project\" ? 2 : tier === \"code\" ? 1 : 0)\n        const maxTier = (files?: ContextSource[]) => Math.max(...(files || []).map(f => tierScore(f.tier)), 0)\n        return maxTier(b.files_used) - maxTier(a.files_used)\n      })\n  }, [memory, search, filterUser, filterGlobal, filterDays])\n\n  const paginated = useMemo(() => {\n    const start = (currentPage - 1) * pageSize\n    return filtered.slice(start, start + pageSize)\n  }, [filtered, currentPage])\n\n  function replayQuery(query: string) {\n    window.open(`/ask?question=${encodeURIComponent(query)}`, \"_blank\")\n  }\n\n  for (const m of paginated) {\n    if (m.summary && typeof m.summary !== \"string\") {\n      console.log(\"DEBUG 418:\", typeof m.summary, m.summary)\n    }\n    if (m.agent_response && typeof m.agent_response !== \"string\") {\n      console.log(\"DEBUG 418:\", typeof m.agent_response, m.agent_response)\n    }\n  }\n  if (modalContext && typeof modalContext.content !== \"string\") {\n    console.log(\"DEBUG 418:\", typeof modalContext.content, modalContext.content)\n  }\n\n  return (\n    <div className=\"space-y-4\">\n      <div className=\"flex flex-wrap gap-4 text-xs text-gray-500 mb-2 items-center\">\n        <span>Fetch: <b>{fetchInfo.status}</b>{fetchInfo.time ?", "mimetype": "text/plain", "start_char_idx": 2725, "end_char_idx": 5904, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cdce9102-8e6a-4cfc-aa04-258a04a71219": {"__data__": {"id_": "cdce9102-8e6a-4cfc-aa04-258a04a71219", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/MemoryPanel.tsx", "file_name": "MemoryPanel.tsx", "file_size": 13812, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1ea75db3-ccf0-490f-9fa0-7f528c129dc2", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/MemoryPanel.tsx", "file_name": "MemoryPanel.tsx", "file_size": 13812, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "fe471f0167c1d4d702f3817eb231e66cffb71a67a62cf06bf352053edcae43dd", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "82d59c41-dafb-4aae-abd0-88f8cd260700", "node_type": "1", "metadata": {"file_path": "/app/frontend/src/components/MemoryPanel.tsx", "file_name": "MemoryPanel.tsx", "file_size": 13812, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "299e090a7f3db222dada8eed9a2363d588ca65ac1951bb44cad231c469c466e3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4e6a7fcb-5ccd-4ef6-83b6-ce73a987e15a", "node_type": "1", "metadata": {}, "hash": "3b06cdd63bb18eae281bfb45d566cb3c357730a99df311dc90b3b18b434c855a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "` (${fetchInfo.time}ms)` : \"\"}</span>\n        <span>Total: <b>{memory.length}</b></span>\n        <span>Filtered: <b>{filtered.length}</b></span>\n        <span>Users: <b>{users.length}</b></span>\n        <span>Global: <b>{filtered.filter(m => m.used_global_context).length}</b></span>\n        <Button onClick={fetchMemory} variant=\"outline\">Refresh</Button>\n      </div>\n\n      <div className=\"flex gap-2 mb-4\">\n        <select className=\"border rounded px-2 py-1 text-sm\" value={filterUser} onChange={e => setFilterUser(e.target.value)}>\n          <option value=\"\">All Users</option>\n          {users.map(u => <option key={u} value={u}>{u}</option>)}\n        </select>\n        <select\n          className=\"border rounded px-2 py-1 text-sm\"\n          value={filterGlobal}\n          onChange={e =>\n            setFilterGlobal(\n              e.target.value as \"any\" | \"with\" | \"without\"\n            )\n          }\n        >\n          <option value=\"any\">All Context</option>\n          <option value=\"with\">With Global</option>\n          <option value=\"without\">Without Global</option>\n        </select>\n        <input\n          className=\"border rounded px-2 py-1 text-sm w-64\"\n          placeholder=\"Search memory...\"\n          value={search}\n          onChange={e => setSearch(e.target.value)}\n        />\n        <select\n          className=\"border rounded px-2 py-1 text-sm\"\n          value={filterDays}\n          onChange={e => setFilterDays(parseInt(e.target.value))}\n        >\n          {[1, 7, 14, 30, 90].map(days => (\n            <option key={days} value={days}>Last {days} days</option>\n          ))}\n        </select>\n      </div>\n\n      {paginated.map((m, i) => (\n        <Card key={i}>\n          <CardContent className=\"p-4 space-y-2\">\n            <div className=\"text-sm font-mono text-muted-foreground\">\n              {new Date(m.timestamp).toLocaleString()} \u2022 {m.user}\n            </div>\n            <div className=\"text-sm font-semibold\">Query:</div>\n            <div className=\"text-sm\">{m.query}</div>\n\n            {isNonEmptyArray(m.topics) && <div className=\"text-xs\">Topics: {m.topics.join(\", \")}</div>}\n            {isNonEmptyArray(m.files) && <div className=\"text-xs\">Files: {m.files.join(\", \")}</div>}\n\n            {isNonEmptyArray(m.context_files) && (\n              <div className=\"text-xs text-blue-800\">\n                <strong>Context Files:</strong> {m.context_files.map((cf, idx) => (\n                  <span key={cf}>\n                    <a className=\"underline cursor-pointer\" onClick={() => fetchContextFile(cf)}>{cf}</a>\n                    {idx < m.context_files!.length - 1 ? \", \" : \"\"}\n                  </span>\n                ))}\n              </div>\n            )}\n\n            {isNonEmptyArray(m.files_used) && (\n              <div className=\"text-xs text-purple-700\">\n                <strong>Injected:</strong>{\" \"}\n                {m.files_used.map((f, idx) => (\n                  <span key={idx}>\n                    <span className=\"underline cursor-pointer\" onClick={() => f.path && fetchContextFile(f.path)}>\n                      {f.path || f.title || f.doc_id || f.type}\n                    </span>\n                    {f.tier && <span className=\"ml-1 text-gray-500\">[{f.tier}]</span>}\n                    {idx < m.files_used!.length - 1 ?", "mimetype": "text/plain", "start_char_idx": 5905, "end_char_idx": 9191, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4e6a7fcb-5ccd-4ef6-83b6-ce73a987e15a": {"__data__": {"id_": "4e6a7fcb-5ccd-4ef6-83b6-ce73a987e15a", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/MemoryPanel.tsx", "file_name": "MemoryPanel.tsx", "file_size": 13812, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1ea75db3-ccf0-490f-9fa0-7f528c129dc2", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/MemoryPanel.tsx", "file_name": "MemoryPanel.tsx", "file_size": 13812, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "fe471f0167c1d4d702f3817eb231e66cffb71a67a62cf06bf352053edcae43dd", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cdce9102-8e6a-4cfc-aa04-258a04a71219", "node_type": "1", "metadata": {"file_path": "/app/frontend/src/components/MemoryPanel.tsx", "file_name": "MemoryPanel.tsx", "file_size": 13812, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "6a6fbccea1f6acb240bc85f3c58fdfd45e640aebfb5d6d12ae6a841abcfa3741", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "77f18924-adc5-47c4-bc6b-2a5ec6aeffde", "node_type": "1", "metadata": {}, "hash": "34ec20c5588c65005965f320bfb579099551c82d3c898f38893bdaff31fa04c5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\", \" : \"\"}\n                  </span>\n                ))}\n              </div>\n            )}\n\n            {isNonEmptyArray(m.files_used) && (\n              <div className=\"text-xs text-purple-700\">\n                <strong>Injected:</strong>{\" \"}\n                {m.files_used.map((f, idx) => (\n                  <span key={idx}>\n                    <span className=\"underline cursor-pointer\" onClick={() => f.path && fetchContextFile(f.path)}>\n                      {f.path || f.title || f.doc_id || f.type}\n                    </span>\n                    {f.tier && <span className=\"ml-1 text-gray-500\">[{f.tier}]</span>}\n                    {idx < m.files_used!.length - 1 ? \", \" : \"\"}\n                  </span>\n                ))}\n              </div>\n            )}\n\n            <div className=\"text-xs text-gray-600\">\n              {typeof m.context_length === \"number\" && <>Context Length: {m.context_length} chars<br /></>}\n              {typeof m.prompt_length === \"number\" && <>Prompt: {m.prompt_length}, Response: {m.response_length}</>}\n            </div>\n\n            {m.used_global_context && (\n              <span className=\"inline-block px-2 py-1 text-xs bg-green-100 text-green-700 rounded\">Global context</span>\n            )}\n            {m.fallback && (\n              <span className=\"inline-block px-2 py-1 text-xs bg-orange-100 text-orange-700 rounded\">Fallback</span>\n            )}\n\n            {Array.isArray(m.tags) && m.tags.length > 0 && (\n              <div className=\"text-xs text-blue-600\">\n                <strong>Tags:</strong> {m.tags.join(\", \")}\n              </div>\n            )}\n\n            {/* Markdown/code for memory summary */}\n            {typeof m.summary === \"string\" && !!m.summary.trim() && (\n              <div className=\"bg-muted p-2 rounded text-xs whitespace-pre-wrap\">\n                <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n                  <SafeMarkdown>{m.summary}</SafeMarkdown>\n                </div>\n              </div>\n            )}\n\n            {/* Markdown/code for agent response */}\n            {typeof m.agent_response === \"string\" && !!m.agent_response.trim() && (\n              <div className=\"bg-muted p-2 rounded text-xs whitespace-pre-wrap mt-2\">\n                <strong>Agent Response:</strong>\n                <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n                  <SafeMarkdown>{m.agent_response}</SafeMarkdown>\n                </div>\n              </div>\n            )}\n\n            <div className=\"flex gap-2 flex-wrap text-xs mt-2\">\n              {[\"important\", \"bug\", \"training\", \"review\"].map(tag => (\n                <Button\n                  key={tag}\n                  variant={m.tags?.includes(tag) ? \"default\" : \"outline\"}\n                  size=\"sm\"\n                  onClick={() => toggleTag(i, tag)}\n                >\n                  {tag}\n                </Button>\n              ))}\n              <Button\n                variant={m.saved ? \"default\" : \"outline\"}\n                size=\"sm\"\n                onClick={() => toggleSave(i)}\n              >\n                {m.saved ?", "mimetype": "text/plain", "start_char_idx": 8515, "end_char_idx": 11640, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "77f18924-adc5-47c4-bc6b-2a5ec6aeffde": {"__data__": {"id_": "77f18924-adc5-47c4-bc6b-2a5ec6aeffde", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/MemoryPanel.tsx", "file_name": "MemoryPanel.tsx", "file_size": 13812, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1ea75db3-ccf0-490f-9fa0-7f528c129dc2", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/MemoryPanel.tsx", "file_name": "MemoryPanel.tsx", "file_size": 13812, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "fe471f0167c1d4d702f3817eb231e66cffb71a67a62cf06bf352053edcae43dd", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4e6a7fcb-5ccd-4ef6-83b6-ce73a987e15a", "node_type": "1", "metadata": {"file_path": "/app/frontend/src/components/MemoryPanel.tsx", "file_name": "MemoryPanel.tsx", "file_size": 13812, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "9543e51d607cc91e09b8550d78691b41304c1e1c4e6698db065ff68d91fc3a22", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"default\" : \"outline\"}\n                  size=\"sm\"\n                  onClick={() => toggleTag(i, tag)}\n                >\n                  {tag}\n                </Button>\n              ))}\n              <Button\n                variant={m.saved ? \"default\" : \"outline\"}\n                size=\"sm\"\n                onClick={() => toggleSave(i)}\n              >\n                {m.saved ? \"\ud83d\udcbe Saved\" : \"Save\"}\n              </Button>\n              <Button size=\"sm\" variant=\"ghost\" onClick={() => replayQuery(m.query)}>\n                \ud83d\udd01 Replay\n              </Button>\n            </div>\n\n            <details className=\"mt-2\">\n              <summary className=\"cursor-pointer text-xs text-blue-700\">Debug: Raw Entry</summary>\n              <pre className=\"bg-gray-100 p-2 rounded text-xs overflow-auto\">{JSON.stringify(m, null, 2)}</pre>\n            </details>\n          </CardContent>\n        </Card>\n      ))}\n\n      {/* Pagination controls */}\n      {filtered.length > pageSize && (\n        <div className=\"flex gap-2 justify-center mt-4\">\n          <Button\n            size=\"sm\"\n            variant=\"outline\"\n            onClick={() => setCurrentPage(p => Math.max(1, p - 1))}\n            disabled={currentPage === 1}\n          >\n            \u2b05 Prev\n          </Button>\n          <span className=\"text-xs flex items-center\">Page {currentPage} / {Math.ceil(filtered.length / pageSize)}</span>\n          <Button\n            size=\"sm\"\n            variant=\"outline\"\n            onClick={() => setCurrentPage(p => p + 1)}\n            disabled={currentPage * pageSize >= filtered.length}\n          >\n            Next \u27a1\n          </Button>\n        </div>\n      )}\n\n      {/* Modal viewer for context file contents (markdown/code-friendly) */}\n      {modalContext && (\n        <div className=\"fixed inset-0 flex items-center justify-center z-50 bg-black bg-opacity-40\">\n          <div className=\"bg-white rounded shadow-lg max-w-2xl w-full p-6 relative\">\n            <div className=\"text-sm mb-2 font-bold\">Context File: <code>{modalContext.path}</code></div>\n            <div className=\"bg-gray-100 p-4 rounded max-h-[400px] overflow-auto text-xs\">\n              <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n                <SafeMarkdown>{modalContext.content}</SafeMarkdown>\n              </div>\n            </div>\n            <Button variant=\"secondary\" onClick={() => setModalContext(null)} className=\"absolute top-2 right-2\">\n              Close\n            </Button>\n          </div>\n        </div>\n      )}\n    </div>\n  )\n}", "mimetype": "text/plain", "start_char_idx": 11257, "end_char_idx": 13799, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f8b64aea-132c-40b4-b925-d7753a67d6c2": {"__data__": {"id_": "f8b64aea-132c-40b4-b925-d7753a67d6c2", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/MetricsCharts/MetricsCharts.tsx", "file_name": "MetricsCharts.tsx", "file_size": 902, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5643dab0-45f8-4c41-b78a-fca414a354c6", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/MetricsCharts/MetricsCharts.tsx", "file_name": "MetricsCharts.tsx", "file_size": 902, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "2a0a20729aac63c1a67fcb25c389efec6444ebcb020a99a313071da019a36b55", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: src/components/MetricsChart.tsx\n\n'use client'\n\nimport { Card } from '../ui/card' \n\nimport {\n  LineChart,\n  Line,\n  XAxis,\n  YAxis,\n  Tooltip,\n  ResponsiveContainer,\n} from 'recharts'\n\nconst sampleData = [\n  { name: 'Mon', value: 400 },\n  { name: 'Tue', value: 300 },\n  { name: 'Wed', value: 500 },\n  { name: 'Thu', value: 200 },\n  { name: 'Fri', value: 650 },\n]\n\nexport default function MetricsChart() {\n  return (\n    <Card className=\"p-6\">\n      <h3 className=\"font-semibold text-lg mb-2\">Metrics Over Time</h3>\n      <ResponsiveContainer width=\"100%\" height={200}>\n        <LineChart data={sampleData}>\n          <XAxis dataKey=\"name\" />\n          <YAxis />\n          <Tooltip />\n          <Line\n            type=\"monotone\"\n            dataKey=\"value\"\n            stroke=\"#4F46E5\"\n            strokeWidth={2}\n          />\n        </LineChart>\n      </ResponsiveContainer>\n    </Card>\n  )\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 901, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "89e003f8-e791-4464-9ffa-6eacebdb5f94": {"__data__": {"id_": "89e003f8-e791-4464-9ffa-6eacebdb5f94", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/SafeMarkdown.tsx", "file_name": "SafeMarkdown.tsx", "file_size": 3365, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "98fdd749-5a87-4246-9e2d-b9c2f7997d58", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/SafeMarkdown.tsx", "file_name": "SafeMarkdown.tsx", "file_size": 3365, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "812fb6abcd33725cb6bdce8315cb2fdd312982378dfaba75a2b0d29fa24399f8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: src/components/SafeMarkdown.tsx\n// Purpose: Bulletproof, consistent, and safe Markdown rendering for all app content.\n//          Hardened against XSS, raw HTML, and rendering bugs. All code blocks are syntax-highlighted (Prism).\n//          This is the ONLY allowed way to render Markdown in the app.\n\nimport React from \"react\";\nimport ReactMarkdown, { Components } from \"react-markdown\";\nimport { Prism as SyntaxHighlighter } from \"react-syntax-highlighter\";\nimport { vscDarkPlus } from \"react-syntax-highlighter/dist/esm/styles/prism\";\n\n// Props for the SafeMarkdown component\ntype SafeMarkdownProps = {\n  /** Markdown text to render (always a string) */\n  children: string;\n  /** Optional CSS className for wrapper */\n  className?: string;\n};\n\n// Custom Markdown renderer for code blocks (uses Prism for highlighting)\nconst markdownComponents: Components = {\n  code(props) {\n    const { inline, className, children, ...rest } = props as {\n      inline?: boolean;\n      className?: string;\n      children: React.ReactNode;\n    };\n    const match = /language-(\\w+)/.exec(className || \"\");\n    const content = String(children).replace(/\\n$/, \"\");\n\n    if (!inline && match) {\n      return (\n        <SyntaxHighlighter\n          style={vscDarkPlus}\n          language={match[1]}\n          PreTag=\"div\"\n          {...rest}\n        >\n          {content}\n        </SyntaxHighlighter>\n      );\n    }\n\n    return (\n      <code {...(className ? { className } : {})} {...rest}>\n        {content}\n      </code>\n    );\n  },\n  // You can expand here for tables, images, links if needed\n};\n\nexport default function SafeMarkdown({ children, className }: SafeMarkdownProps) {\n  // Dev-only: Warn if a non-string slips through (should never happen in production)\n  if (typeof children !== \"string\" && process.env.NODE_ENV !== \"production\") {\n    console.warn(\n      \"[SafeMarkdown] Expected children to be a string, got:\",\n      typeof children,\n      children\n    );\n  }\n\n  // Always coerce to string for React safety\n  const strChildren =\n    typeof children === \"string\" ? children : children ? String(children) : \"\";\n\n  // Debug: Log if somehow a non-string is still about to render (for final #418 hunting)\n  if (typeof strChildren !== \"string\") {\n    // eslint-disable-next-line no-console\n    console.error(\"SAFE-MARKDOWN-418-DEBUG\", typeof strChildren, strChildren);\n  }\n\n  // Ultra-safe: Escape anything that looks like raw HTML before markdown parsing\n  // (belt-and-suspenders, since skipHtml & disallowedElements are also set)\n  const likelyRawHtml = /<\\s*[a-zA-Z]+[^>]*>/.test(strChildren);\n  const safeChildren = likelyRawHtml\n    ? strChildren.replace(/</g, \"&lt;\").replace(/>/g, \"&gt;\")\n    : strChildren;\n\n  return (\n    <ReactMarkdown\n      components={markdownComponents}\n      // SECURITY: Never allow any HTML passthrough from markdown\n      skipHtml={true}\n      disallowedElements={[\"html\", \"head\", \"body\", \"style\", \"script\", \"iframe\"]}\n      {...(className ? { className } : {})}\n    >\n      {safeChildren}\n    </ReactMarkdown>\n  );\n}\n\n/**\n * Usage:\n * <SafeMarkdown>{markdownString}</SafeMarkdown>\n *\n * - NEVER use ReactMarkdown directly in any other file.\n * - All markdown content (LLM, docs, search, context, etc) MUST be rendered via SafeMarkdown.\n * - Always ensure children is a string (coerce using toMDString or similar as needed).\n */", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3364, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "11b7e9a9-11fd-4f96-acf4-4939c974ac2f": {"__data__": {"id_": "11b7e9a9-11fd-4f96-acf4-4939c974ac2f", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/SearchPanel.tsx", "file_name": "SearchPanel.tsx", "file_size": 4672, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ac2489c1-6d3a-4391-90f3-5db4c484f169", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/SearchPanel.tsx", "file_name": "SearchPanel.tsx", "file_size": 4672, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "cb57bb106f60f8a453f746ebe9dbcbd75e56231994ed7b44748cbfdb97a3bba4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a1a25284-7106-470a-949c-50839f94ab3c", "node_type": "1", "metadata": {}, "hash": "a05b37f20f3dd04a8475dbcffad33196c334c135e0edbe6df5612813d74f13d0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: frontend/src/components/SearchPanel.tsx\n// Purpose: Robust, debounced UI panel for semantic KB search (GET /kb/search).\n//          Now renders result snippets with SafeMarkdown for readable markdown/code.\n// Notes: 2025\u201107\u201101 \u2013 All features preserved; only result snippet rendering is upgraded.\n\n\"use client\";\n\nimport { useEffect, useRef, useState } from \"react\";\nimport { Input } from \"@/components/ui/input\";\nimport { Button } from \"@/components/ui/button\";\nimport { API_ROOT, API_KEY } from \"@/lib/api\";\nimport SafeMarkdown from \"@/components/SafeMarkdown\";\nimport { toMDString } from \"@/lib/toMDString\";\n\nexport type KBResult = {\n  path: string;\n  title: string;\n  snippet: string;\n  updated: string;\n  similarity: number;\n};\n\nconst DEBOUNCE_MS = 400;\nconst TOP_K = 5;\n\nexport default function SearchPanel() {\n  const [query, setQuery] = useState<string>(\"\");\n  const [results, setResults] = useState<KBResult[]>([]);\n  const [loading, setLoading] = useState(false);\n  const [error, setError] = useState<string | null>(null);\n\n  const controllerRef = useRef<AbortController | null>(null);\n  const debounceRef = useRef<ReturnType<typeof setTimeout> | null>(null);\n\n  const clearDebounce = () => {\n    if (debounceRef.current) {\n      clearTimeout(debounceRef.current);\n    }\n  };\n\n  // Core fetch logic\n  const fetchResults = async (q: string) => {\n    if (!API_ROOT) {\n      setError(\"API URL not configured\");\n      return;\n    }\n    if (!API_KEY) {\n      setError(\"API key missing\");\n      return;\n    }\n\n    setError(null);\n    setLoading(true);\n\n    controllerRef.current?.abort();\n    const controller = new AbortController();\n    controllerRef.current = controller;\n\n    try {\n      const url = new URL(\"/kb/search\", API_ROOT);\n      url.searchParams.set(\"query\", q);\n      url.searchParams.set(\"k\", String(TOP_K));\n\n      const res = await fetch(url.toString(), {\n        method: \"GET\",\n        headers: {\n          \"x-api-key\": API_KEY,\n          Accept: \"application/json\",\n        },\n        signal: controller.signal,\n      });\n\n      if (res.status === 401 || res.status === 403) {\n        throw new Error(\"Unauthorized \u2013 check API key / login\");\n      }\n      if (!res.ok) {\n        throw new Error(`HTTP ${res.status}`);\n      }\n\n      const data: KBResult[] = await res.json();\n      const mapped = data.map((r) => ({\n        ...r,\n        snippet: toMDString(r.snippet),\n      }));\n      setResults(mapped);\n    } catch (err) {\n      if (err instanceof DOMException && err.name === \"AbortError\") {\n        return; // request was cancelled\n      }\n      console.error(\"KB search error\", err);\n      setError((err as Error).message ?? \"Search failed\");\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  // Debounce typing\n  useEffect(() => {\n    if (!query.trim()) {\n      setResults([]);\n      setError(null);\n      return;\n    }\n\n    clearDebounce();\n    debounceRef.current = setTimeout(() => fetchResults(query.trim()), DEBOUNCE_MS);\n\n    return () => {\n      clearDebounce();\n    };\n  }, [query]);\n\n  const onSubmit = (e: React.FormEvent) => {\n    e.preventDefault();\n    clearDebounce();\n    fetchResults(query.trim());\n  };\n\n  for (const r of results) {\n    if (typeof r.snippet !== \"string\") {\n      console.log(\"DEBUG 418:\", typeof r.snippet, r.snippet);\n    }\n  }\n\n  return (\n    <div className=\"space-y-4\" aria-busy={loading}>\n      <form onSubmit={onSubmit} className=\"flex gap-2\">\n        <label htmlFor=\"kb-query\" className=\"sr-only\">\n          Search knowledge base\n        </label>\n        <Input\n          id=\"kb-query\"\n          placeholder=\"Ask a question\u2026\"\n          value={query}\n          onChange={(e) => setQuery(e.target.value)}\n        />\n        <Button type=\"submit\" disabled={loading}>\n          {loading ? \"\u23f3\" : \"Search\"}\n        </Button>\n      </form>\n\n      {error ?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3832, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a1a25284-7106-470a-949c-50839f94ab3c": {"__data__": {"id_": "a1a25284-7106-470a-949c-50839f94ab3c", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/SearchPanel.tsx", "file_name": "SearchPanel.tsx", "file_size": 4672, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ac2489c1-6d3a-4391-90f3-5db4c484f169", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/SearchPanel.tsx", "file_name": "SearchPanel.tsx", "file_size": 4672, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "cb57bb106f60f8a453f746ebe9dbcbd75e56231994ed7b44748cbfdb97a3bba4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "11b7e9a9-11fd-4f96-acf4-4939c974ac2f", "node_type": "1", "metadata": {"file_path": "/app/frontend/src/components/SearchPanel.tsx", "file_name": "SearchPanel.tsx", "file_size": 4672, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "b5ee2bda24adf120e6d81bfb814f751ef03f948f2943f40cfb0d8b59e188eadf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\u23f3\" : \"Search\"}\n        </Button>\n      </form>\n\n      {error ? <p className=\"text-sm text-red-500\">{error}</p> : null}\n\n      {results.length > 0 && (\n        <div className=\"space-y-2\">\n          {results.map((r, i) => (\n            <article key={i} className=\"border rounded p-4 text-sm space-y-1\">\n              <header className=\"text-muted-foreground\">\n                <strong>{r.title}</strong> ({r.similarity.toFixed(2)})\n              </header>\n              <div className=\"mb-1\">\n                <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n                  <SafeMarkdown>{r.snippet}</SafeMarkdown>\n                </div>\n              </div>\n              <footer className=\"text-xs text-muted-foreground\">\n                Updated: {r.updated || \"\u2014\"}\n              </footer>\n            </article>\n          ))}\n        </div>\n      )}\n    </div>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 3769, "end_char_idx": 4657, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "124435f4-5701-402d-862a-47a47217a8ac": {"__data__": {"id_": "124435f4-5701-402d-862a-47a47217a8ac", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/Sidebar/Sidebar.tsx", "file_name": "Sidebar.tsx", "file_size": 1646, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "26c218d2-3074-4e2a-9772-4bd6ae4dc5fb", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/Sidebar/Sidebar.tsx", "file_name": "Sidebar.tsx", "file_size": 1646, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "3413c72cf522d98a80e51595334d5c5d3c1371c617a8b629f4e28aaf76ea1506", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: src/components/Sidebar/Sidebar.tsx\n\"use client\";\n\nconsole.log(\"Sidebar mounted\");\n\nimport Image from \"next/image\";\nimport Link from \"next/link\";\nimport { usePathname } from \"next/navigation\";\n\nconst links = [\n  { href: \"/ask\", label: \"Ask Echo\", icon: \"/Hoody.png\" },\n  { href: \"/codex\", label: \"Codex\", icon: \"/PlannerCop.png\" },\n  { href: \"/docs\", label: \"Docs\", icon: \"/PigTails.png\" },\n  { href: \"/control\", label: \"Control\", icon: \"/Echo.png\" },\n  { href: \"/planner\", label: \"Planner\", icon: \"/ballcap beard.png\" },\n  { href: \"/email\", label: \"Email\", icon: \"/blackbeard earing.png\" },\n  { href: \"/critic\", label: \"Critic\", icon: \"/beanie and smoke.png\" },\n  { href: \"/janitor\", label: \"Janitor\", icon: \"/sunglass shadow.png\" },\n   { href: \"/logs\", label: \"Logs\", icon: \"/echo.png\" }, // Pick a fun icon!\n];\n\nexport default function Sidebar() {\n  const pathname = usePathname();\n\n  return (\n    <aside className=\"w-48 bg-white border-r p-3 space-y-2\">\n      <h2 className=\"text-lg font-bold flex items-center gap-2\">\n        <Image src=\"/WildfireMang.png\" alt=\"logo\" width={24} height={24} />\n        Wildfire Ranch\n      </h2>\n      <nav className=\"mt-4 space-y-2 text-sm\">\n        {links.map(({ href, label, icon }) => (\n          <Link\n            key={href}\n            href={href}\n            className={`flex items-center gap-2 px-2 py-1 rounded hover:bg-gray-100 ${\n              pathname === href ? \"bg-blue-100 font-semibold\" : \"\"\n            }`}\n          >\n            <Image src={icon} alt={label} width={24} height={24} />\n            <span>{label}</span>\n          </Link>\n        ))}\n      </nav>\n    </aside>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1645, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0b4412da-676c-476f-94af-df70d44f29de": {"__data__": {"id_": "0b4412da-676c-476f-94af-df70d44f29de", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/StatusPanel.tsx", "file_name": "StatusPanel.tsx", "file_size": 4399, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d7df79dc-de66-4319-8914-e9b72e5df240", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/StatusPanel.tsx", "file_name": "StatusPanel.tsx", "file_size": 4399, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "0e5ada73ffe61ba5adad2677784f9d973464606b3bbf79564b34cd576057b7ad", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e2044897-6135-4bfa-b4fe-ea03cd6c9922", "node_type": "1", "metadata": {}, "hash": "1fe332aa0184fcfc376c8b1ad109cee26946d00eee56fb29c70271a3026a7ea3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: components/StatusPanel.tsx\n// Directory: frontend/src/components\n// Purpose: Display Relay service status and embed a UI panel for Google Docs sync and KB/context awareness\n\n\"use client\";\n\nimport { useEffect, useState } from \"react\";\nimport { Card, CardContent } from \"@/components/ui/card\";\nimport DocsSyncPanel from \"@/components/DocsSyncPanel\";\nimport { API_ROOT } from \"@/lib/api\";\n\ninterface StatusSummary {\n  version?: { git_commit?: string };\n  paths?: {\n    base_path?: string;\n    resolved_paths?: Record<string, boolean>;\n  };\n}\n\ninterface ContextFile {\n  path: string;\n  size_bytes: number;\n  last_modified: string;\n}\n\ninterface ContextStatus {\n  context_files: ContextFile[];\n  global_context_used: string;\n  global_context_manual_last_updated: string;\n  global_context_auto_last_updated: string;\n}\n\nexport default function StatusPanel() {\n  const [status, setStatus] = useState<StatusSummary | null>(null);\n  const [context, setContext] = useState<ContextStatus | null>(null);\n  const [error, setError] = useState<string | null>(null);\n  const [loading, setLoading] = useState<boolean>(true);\n\n  useEffect(() => {\n    async function fetchStatus() {\n      if (!API_ROOT) {\n        setError(\"API URL not configured.\");\n        setLoading(false);\n        return;\n      }\n      try {\n        const [statusRes, contextRes] = await Promise.all([\n          fetch(`${API_ROOT}/status/summary`),\n          fetch(`${API_ROOT}/status/context`),\n        ]);\n        if (!statusRes.ok || !contextRes.ok)\n          throw new Error(\"Failed to fetch one or more endpoints\");\n        const statusData: StatusSummary = await statusRes.json();\n        const contextData: ContextStatus = await contextRes.json();\n        setStatus(statusData);\n        setContext(contextData);\n      } catch (err) {\n        console.error(\"Status fetch error:\", err);\n        setError(\"Failed to load status.\");\n      } finally {\n        setLoading(false);\n      }\n    }\n    fetchStatus();\n  }, []);\n\n  if (loading) return <p className=\"text-sm text-muted-foreground\">Loading service status\u2026</p>;\n  if (error) return <p className=\"text-sm text-red-500\">{error}</p>;\n  if (!status) return <p className=\"text-sm\">No status data available.</p>;\n\n  return (\n    <>\n      <Card className=\"mt-6\">\n        <CardContent className=\"p-4 space-y-3\">\n          <h2 className=\"text-xl font-bold\">\ud83d\udcca Relay Service Status</h2>\n          <div><strong>Version:</strong> {status.version?.git_commit || \"unknown\"}</div>\n          <div><strong>Base Path:</strong> {status.paths?.base_path || \"\u2014\"}</div>\n          <div>\n            <strong>Docs Folder Health:</strong>\n            <ul className=\"list-disc ml-6\">\n              {Object.entries(status.paths?.resolved_paths || {}).map(\n                ([pathKey, ok]) => (\n                  <li key={pathKey} className=\"text-sm\">\n                    {pathKey}: {ok ? \"\u2705 OK\" : \"\u274c Missing\"}\n                  </li>\n                )\n              )}\n            </ul>\n          </div>\n        </CardContent>\n      </Card>\n\n      {context && (\n        <Card className=\"mt-6\">\n          <CardContent className=\"p-4 space-y-3\">\n            <h2 className=\"text-xl font-bold\">\ud83e\udde0 Context Awareness</h2>\n            <div><strong>Context Strategy:</strong> {context.global_context_used === \"manual\" ? \"\ud83d\udcdd Manual\" : context.global_context_used === \"auto\" ?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3353, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e2044897-6135-4bfa-b4fe-ea03cd6c9922": {"__data__": {"id_": "e2044897-6135-4bfa-b4fe-ea03cd6c9922", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/StatusPanel.tsx", "file_name": "StatusPanel.tsx", "file_size": 4399, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d7df79dc-de66-4319-8914-e9b72e5df240", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/StatusPanel.tsx", "file_name": "StatusPanel.tsx", "file_size": 4399, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "0e5ada73ffe61ba5adad2677784f9d973464606b3bbf79564b34cd576057b7ad", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0b4412da-676c-476f-94af-df70d44f29de", "node_type": "1", "metadata": {"file_path": "/app/frontend/src/components/StatusPanel.tsx", "file_name": "StatusPanel.tsx", "file_size": 4399, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "0cbdcece89101fb45c468a0104e315e61dc25dcae657501ab14a7c8137b5043a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\u2705 OK\" : \"\u274c Missing\"}\n                  </li>\n                )\n              )}\n            </ul>\n          </div>\n        </CardContent>\n      </Card>\n\n      {context && (\n        <Card className=\"mt-6\">\n          <CardContent className=\"p-4 space-y-3\">\n            <h2 className=\"text-xl font-bold\">\ud83e\udde0 Context Awareness</h2>\n            <div><strong>Context Strategy:</strong> {context.global_context_used === \"manual\" ? \"\ud83d\udcdd Manual\" : context.global_context_used === \"auto\" ? \"\ud83e\udd16 Auto-generated\" : \"None\"}</div>\n            <div><strong>Last Manual Update:</strong> {context.global_context_manual_last_updated}</div>\n            <div><strong>Last Auto Update:</strong> {context.global_context_auto_last_updated}</div>\n            <div>\n              <strong>Active Context Files:</strong>\n              <ul className=\"list-disc ml-6\">\n                {context.context_files.map((file) => (\n                  <li key={file.path} className=\"text-sm\">\n                    {file.path}{\" \"}\n                    <span className=\"text-xs text-gray-500\">\n                      ({Math.round(file.size_bytes / 1024)} KB,\n                      {\" \"}\n                      {new Date(file.last_modified).toLocaleString()})\n                    </span>\n                  </li>\n                ))}\n              </ul>\n            </div>\n          </CardContent>\n        </Card>\n      )}\n\n      {/* Embed DocsSyncPanel below status */}\n      <div className=\"mt-6\">\n        <DocsSyncPanel />\n      </div>\n    </>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 2877, "end_char_idx": 4378, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d72cc094-ebab-44f8-81db-92b574bd3244": {"__data__": {"id_": "d72cc094-ebab-44f8-81db-92b574bd3244", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/dashboard/Dashboard.stories.tsx", "file_name": "Dashboard.stories.tsx", "file_size": 152, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "433ab2a3-5ecf-409e-ac00-682d56a21a64", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/dashboard/Dashboard.stories.tsx", "file_name": "Dashboard.stories.tsx", "file_size": 152, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "7b9f1a485e68a397cf5ddd065a5b732b3dac2149fea73e86c84f94799d07900f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import Dashboard from \"./Dashboard\";\nexport default {\n  title: \"Dashboard/Main\",\n  component: Dashboard,\n};\nexport const Default = () => <Dashboard />;", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 151, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "49d0e78b-8af4-4c08-b32e-2c5e2a51572b": {"__data__": {"id_": "49d0e78b-8af4-4c08-b32e-2c5e2a51572b", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/dashboard/Dashboard.tsx", "file_name": "Dashboard.tsx", "file_size": 3449, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "bfcafffd-c14c-49e3-bc43-7fd2a57124b3", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/dashboard/Dashboard.tsx", "file_name": "Dashboard.tsx", "file_size": 3449, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "2036cea6af498f5720c855cbb5227abfcd0d6ff82c75c0bfdd4d54d1ef35f177", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: DashboardWizard.tsx\n// Directory: frontend/src/components/dashboard\n// Purpose: Multi-step, animated setup wizard for Command Center dashboard onboarding.\n//   - Built with shadcn/ui components for consistent styling\n//   - Uses Framer Motion for smooth step transitions\n//   - Easy to customize steps/fields for your infra/ops flows\n\n\"use client\";\nimport { useState } from \"react\";\nimport { Card, CardContent, CardHeader, CardTitle } from \"@/components/ui/card\";\nimport { Button } from \"@/components/ui/button\";\nimport { Input } from \"@/components/ui/input\";\nimport { Progress } from \"@/components/ui/progress\";\nimport { AnimatePresence, motion } from \"framer-motion\";\n\n// ---- Wizard step definitions ----\n// Each step defines a title and content (could use form logic, API calls, etc)\nconst steps = [\n  {\n    title: \"Connect Infrastructure\",\n    content: (\n      <>\n        <p className=\"mb-4 text-sm text-muted-foreground\">\n          Connect your infrastructure to begin tracking data.\n        </p>\n        <Input placeholder=\"Enter node endpoint or IP\" />\n      </>\n    ),\n  },\n  {\n    title: \"Add Notification Channel\",\n    content: (\n      <>\n        <p className=\"mb-4 text-sm text-muted-foreground\">\n          Add email or webhook to get alerts on events.\n        </p>\n        <Input placeholder=\"Email or webhook URL\" />\n      </>\n    ),\n  },\n  {\n    title: \"Finish Setup\",\n    content: (\n      <>\n        <p className=\"mb-4 text-sm text-muted-foreground\">\n          You\u2019re ready! Start using the Command Center.\n        </p>\n        <ul className=\"list-disc text-xs pl-5 text-muted-foreground\">\n          <li>Monitor live data</li>\n          <li>Configure automations</li>\n          <li>Access analytics & reports</li>\n        </ul>\n      </>\n    ),\n  },\n];\n\nexport default function DashboardWizard() {\n  // ---- State: Current wizard step ----\n  const [step, setStep] = useState(0);\n\n  // ---- Step navigation handlers ----\n  const next = () => setStep((s) => Math.min(s + 1, steps.length - 1));\n  const prev = () => setStep((s) => Math.max(s - 1, 0));\n\n  return (\n    <Card className=\"max-w-md mx-auto shadow-2xl\">\n      <CardHeader>\n        <CardTitle>\n          Setup Wizard\n          <span className=\"ml-2 text-xs font-normal text-muted-foreground\">\n            Step {step + 1} of {steps.length}\n          </span>\n        </CardTitle>\n        {/* Progress bar shows % complete */}\n        <Progress value={((step + 1) / steps.length) * 100} className=\"h-2 mt-4\" />\n      </CardHeader>\n      <CardContent>\n        {/* Animated transition between steps */}\n        <AnimatePresence mode=\"wait\">\n          <motion.div\n            key={step}\n            initial={{ opacity: 0, x: 24 }}\n            animate={{ opacity: 1, x: 0 }}\n            exit={{ opacity: 0, x: -24 }}\n            transition={{ duration: 0.25 }}\n            className=\"min-h-[110px]\"\n          >\n            <h3 className=\"font-semibold mb-2\">{steps[step].title}</h3>\n            {steps[step].content}\n          </motion.div>\n        </AnimatePresence>\n        {/* Navigation buttons */}\n        <div className=\"flex justify-between mt-6\">\n          <Button variant=\"secondary\" onClick={prev} disabled={step === 0}>\n            Back\n          </Button>\n          <Button onClick={next} disabled={step === steps.length - 1}>\n            {step === steps.length - 1 ? \"Done\" : \"Next\"}\n          </Button>\n        </div>\n      </CardContent>\n    </Card>\n  );\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3446, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ebaa16d1-8c31-457e-90b6-e912c8414fde": {"__data__": {"id_": "ebaa16d1-8c31-457e-90b6-e912c8414fde", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/index.ts", "file_name": "index.ts", "file_size": 717, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "66032114-aa83-410c-a4ea-b13cd1ac8f08", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/index.ts", "file_name": "index.ts", "file_size": 717, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "1783a8fc97f348e95d596dee3faf653d73599a0a6820febad9109f76b347eba5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: src/components/index.ts\n\nexport { default as AskEcho } from \"./AskAgent/ChatWindow\";\nexport { default as ActionQueuePanel } from \"./ActionQueue/ActionQueuePanel\";\nexport { default as AuditPanel } from \"./AuditPanel/AuditPanel\";\nexport { default as DocsViewer } from \"./DocsViewer/DocsViewer\";\nexport { default as DocsSyncPanel } from \"./DocsSyncPanel\";\nexport { default as GmailOpsPanel } from \"./GmailOps/GmailOpsPanel\";\nexport { default as LogsPanel } from \"./LogsPanel/LogsPanel\";\nexport { default as MemoryPanel } from \"./MemoryPanel\";\nexport { default as SearchPanel } from \"./SearchPanel\";\nexport { default as StatusPanel } from \"./StatusPanel\";\nexport { default as Sidebar } from \"./Sidebar/Sidebar\";", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 716, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4e253827-2c05-4c0b-91ce-82f9db3e36d6": {"__data__": {"id_": "4e253827-2c05-4c0b-91ce-82f9db3e36d6", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/ui/AskAgent/AskAgent.tsx", "file_name": "AskAgent.tsx", "file_size": 1644, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1b5114c6-13e2-4479-946d-d8e868c8fc43", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/ui/AskAgent/AskAgent.tsx", "file_name": "AskAgent.tsx", "file_size": 1644, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "fb943f1be2756583de2afab8879cb999545c1cf840c1e8eed06b031787100d3b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: src/components/ui/AskAgent/AskAgent.tsx\n\n\"use client\"\n\nimport { useState } from \"react\"\nimport { Textarea } from \"@/components/ui/textarea\"\nimport { Button } from \"@/components/ui/button\"\nimport SafeMarkdown from \"@/components/SafeMarkdown\"\n\nexport default function AskAgent() {\n  const [query, setQuery] = useState(\"\")\n  const [response, setResponse] = useState<string | null>(null)\n  const [loading, setLoading] = useState(false)\n\n  async function sendQuery() {\n    if (!query) return\n    setLoading(true)\n    setResponse(null)\n\n    const res = await fetch(\"https://relay.wildfireranch.us/ask?q=\" + encodeURIComponent(query), {\n      headers: {\n        \"X-API-Key\": process.env.NEXT_PUBLIC_API_KEY || \"\"\n      }\n    })\n\n    const data = await res.json()\n    setResponse(\n      data.answer ||\n      data.function_call?.arguments ||\n      \"No answer.\"\n    )\n    setLoading(false)\n  }\n\n  if (response && typeof response !== \"string\") {\n    console.log(\"DEBUG 418:\", typeof response, response)\n  }\n\n  return (\n    <div className=\"max-w-xl space-y-4\">\n      <Textarea\n        placeholder=\"Ask Echo something...\"\n        value={query}\n        onChange={(e) => setQuery(e.target.value)}\n        disabled={loading}\n      />\n      <Button onClick={sendQuery} disabled={loading || !query}>\n        {loading ? \"Thinking...\" : \"Ask Echo\"}\n      </Button>\n      {response && (\n        <div className=\"bg-muted p-4 rounded text-sm whitespace-pre-wrap border\">\n          <div className=\"prose prose-neutral dark:prose-invert max-w-none\">\n            <SafeMarkdown>{response}</SafeMarkdown>\n          </div>\n        </div>\n      )}\n    </div>\n  )\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1643, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cfc672c9-0db9-4c2b-ae02-3b017d00f511": {"__data__": {"id_": "cfc672c9-0db9-4c2b-ae02-3b017d00f511", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/ui/badge.tsx", "file_name": "badge.tsx", "file_size": 882, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "591b4637-9116-4e8b-83c3-154868eee270", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/ui/badge.tsx", "file_name": "badge.tsx", "file_size": 882, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "89d6962dd23b5adc6074ceaa8f2cbe0b06a494a5833cf22270cd8a9ef753981e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: components/ui/badge.tsx\n// Simple, styleable Badge component for statuses/labels\n\nimport React from \"react\";\nimport clsx from \"clsx\";\n\ntype BadgeVariant = \"default\" | \"success\" | \"destructive\" | \"secondary\";\n\nconst variantStyles: Record<BadgeVariant, string> = {\n  default: \"bg-gray-200 text-gray-700\",\n  success: \"bg-green-100 text-green-800 border border-green-300\",\n  destructive: \"bg-red-100 text-red-800 border border-red-300\",\n  secondary: \"bg-blue-100 text-blue-800 border border-blue-300\",\n};\n\nexport const Badge: React.FC<{\n  children: React.ReactNode;\n  variant?: BadgeVariant;\n  className?: string;\n}> = ({ children, variant = \"default\", className = \"\" }) => (\n  <span\n    className={clsx(\n      \"inline-block rounded px-2 py-0.5 text-xs font-semibold\",\n      variantStyles[variant],\n      className\n    )}\n  >\n    {children}\n  </span>\n);\n\nexport default Badge;", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 881, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a5bc80a9-1439-4160-876c-624bb21367a3": {"__data__": {"id_": "a5bc80a9-1439-4160-876c-624bb21367a3", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/ui/button.tsx", "file_name": "button.tsx", "file_size": 2123, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8c1db525-1b5d-4ce2-90ff-e70cfe87c4a1", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/ui/button.tsx", "file_name": "button.tsx", "file_size": 2123, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "51aa6a4b7875ff49f0beb30fe7959041e93a287415c2a87cee923f9c60680dc8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import * as React from \"react\"\nimport { Slot } from \"@radix-ui/react-slot\"\nimport { cva, type VariantProps } from \"class-variance-authority\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst buttonVariants = cva(\n  \"inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg:not([class*='size-'])]:size-4 shrink-0 [&_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive\",\n  {\n    variants: {\n      variant: {\n        default:\n          \"bg-primary text-primary-foreground shadow-xs hover:bg-primary/90\",\n        destructive:\n          \"bg-destructive text-white shadow-xs hover:bg-destructive/90 focus-visible:ring-destructive/20 dark:focus-visible:ring-destructive/40 dark:bg-destructive/60\",\n        outline:\n          \"border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50\",\n        secondary:\n          \"bg-secondary text-secondary-foreground shadow-xs hover:bg-secondary/80\",\n        ghost:\n          \"hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50\",\n        link: \"text-primary underline-offset-4 hover:underline\",\n      },\n      size: {\n        default: \"h-9 px-4 py-2 has-[>svg]:px-3\",\n        sm: \"h-8 rounded-md gap-1.5 px-3 has-[>svg]:px-2.5\",\n        lg: \"h-10 rounded-md px-6 has-[>svg]:px-4\",\n        icon: \"size-9\",\n      },\n    },\n    defaultVariants: {\n      variant: \"default\",\n      size: \"default\",\n    },\n  }\n)\n\nfunction Button({\n  className,\n  variant,\n  size,\n  asChild = false,\n  ...props\n}: React.ComponentProps<\"button\"> &\n  VariantProps<typeof buttonVariants> & {\n    asChild?: boolean\n  }) {\n  const Comp = asChild ? Slot : \"button\"\n\n  return (\n    <Comp\n      data-slot=\"button\"\n      className={cn(buttonVariants({ variant, size, className }))}\n      {...props}\n    />\n  )\n}\n\nexport { Button, buttonVariants }", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2122, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "307a6ef7-2e63-41f0-9662-7ac9e0289bcb": {"__data__": {"id_": "307a6ef7-2e63-41f0-9662-7ac9e0289bcb", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/ui/card.tsx", "file_name": "card.tsx", "file_size": 1989, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4fa9bee7-0cf6-4ec6-a89d-eb255aaeb26e", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/ui/card.tsx", "file_name": "card.tsx", "file_size": 1989, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "a65e86f990c1ead0e672aa00800e4cd07cc97a5707a7df98f621217a63324ff9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import * as React from \"react\"\n\nimport { cn } from \"@/lib/utils\"\n\nfunction Card({ className, ...props }: React.ComponentProps<\"div\">) {\n  return (\n    <div\n      data-slot=\"card\"\n      className={cn(\n        \"bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm\",\n        className\n      )}\n      {...props}\n    />\n  )\n}\n\nfunction CardHeader({ className, ...props }: React.ComponentProps<\"div\">) {\n  return (\n    <div\n      data-slot=\"card-header\"\n      className={cn(\n        \"@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-1.5 px-6 has-data-[slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6\",\n        className\n      )}\n      {...props}\n    />\n  )\n}\n\nfunction CardTitle({ className, ...props }: React.ComponentProps<\"div\">) {\n  return (\n    <div\n      data-slot=\"card-title\"\n      className={cn(\"leading-none font-semibold\", className)}\n      {...props}\n    />\n  )\n}\n\nfunction CardDescription({ className, ...props }: React.ComponentProps<\"div\">) {\n  return (\n    <div\n      data-slot=\"card-description\"\n      className={cn(\"text-muted-foreground text-sm\", className)}\n      {...props}\n    />\n  )\n}\n\nfunction CardAction({ className, ...props }: React.ComponentProps<\"div\">) {\n  return (\n    <div\n      data-slot=\"card-action\"\n      className={cn(\n        \"col-start-2 row-span-2 row-start-1 self-start justify-self-end\",\n        className\n      )}\n      {...props}\n    />\n  )\n}\n\nfunction CardContent({ className, ...props }: React.ComponentProps<\"div\">) {\n  return (\n    <div\n      data-slot=\"card-content\"\n      className={cn(\"px-6\", className)}\n      {...props}\n    />\n  )\n}\n\nfunction CardFooter({ className, ...props }: React.ComponentProps<\"div\">) {\n  return (\n    <div\n      data-slot=\"card-footer\"\n      className={cn(\"flex items-center px-6 [.border-t]:pt-6\", className)}\n      {...props}\n    />\n  )\n}\n\nexport {\n  Card,\n  CardHeader,\n  CardFooter,\n  CardTitle,\n  CardAction,\n  CardDescription,\n  CardContent,\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1988, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d0348d51-019a-4f99-a9c8-5f4c1698aef5": {"__data__": {"id_": "d0348d51-019a-4f99-a9c8-5f4c1698aef5", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/ui/input.tsx", "file_name": "input.tsx", "file_size": 967, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "00ff82b5-d559-4ef4-8119-3deb2f8f9feb", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/ui/input.tsx", "file_name": "input.tsx", "file_size": 967, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "996d6facf5dabc21dcb59cadca7b3c4563655a43c6c664e99d7f41a981d9e0b7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import * as React from \"react\"\n\nimport { cn } from \"@/lib/utils\"\n\nfunction Input({ className, type, ...props }: React.ComponentProps<\"input\">) {\n  return (\n    <input\n      type={type}\n      data-slot=\"input\"\n      className={cn(\n        \"file:text-foreground placeholder:text-muted-foreground selection:bg-primary selection:text-primary-foreground dark:bg-input/30 border-input flex h-9 w-full min-w-0 rounded-md border bg-transparent px-3 py-1 text-base shadow-xs transition-[color,box-shadow] outline-none file:inline-flex file:h-7 file:border-0 file:bg-transparent file:text-sm file:font-medium disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 md:text-sm\",\n        \"focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px]\",\n        \"aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive\",\n        className\n      )}\n      {...props}\n    />\n  )\n}\n\nexport { Input }", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 966, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "696a9378-9277-4319-8067-5185c013aced": {"__data__": {"id_": "696a9378-9277-4319-8067-5185c013aced", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/ui/label.tsx", "file_name": "label.tsx", "file_size": 611, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "412d6596-d33d-4645-9608-c6dea466fa43", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/ui/label.tsx", "file_name": "label.tsx", "file_size": 611, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "939784b785a1bb3775a83a99a3f1a35cff82de318a687473940ac74066f78879", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"use client\"\n\nimport * as React from \"react\"\nimport * as LabelPrimitive from \"@radix-ui/react-label\"\n\nimport { cn } from \"@/lib/utils\"\n\nfunction Label({\n  className,\n  ...props\n}: React.ComponentProps<typeof LabelPrimitive.Root>) {\n  return (\n    <LabelPrimitive.Root\n      data-slot=\"label\"\n      className={cn(\n        \"flex items-center gap-2 text-sm leading-none font-medium select-none group-data-[disabled=true]:pointer-events-none group-data-[disabled=true]:opacity-50 peer-disabled:cursor-not-allowed peer-disabled:opacity-50\",\n        className\n      )}\n      {...props}\n    />\n  )\n}\n\nexport { Label }", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 610, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "60bc89f8-d107-4216-99f7-5a3ed3c69400": {"__data__": {"id_": "60bc89f8-d107-4216-99f7-5a3ed3c69400", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/ui/progress.tsx", "file_name": "progress.tsx", "file_size": 698, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1aba31d0-7e4c-4c00-92dd-8e52e83b03ba", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/ui/progress.tsx", "file_name": "progress.tsx", "file_size": 698, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "d3cd2e214a434b53684a0c95fc3ed53f9b21d921435f6a942320e4746a17d3c7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: progress.tsx\n// Directory: frontend/components/ui\n// Purpose: shadcn/ui Progress bar component\n\n\"use client\";\n\nimport * as React from \"react\";\nimport { cn } from \"@/lib/utils\";\n\nconst Progress = React.forwardRef<\n  HTMLDivElement,\n  React.HTMLAttributes<HTMLDivElement> & { value?: number }\n>(({ className, value, ...props }, ref) => (\n  <div\n    ref={ref}\n    className={cn(\"relative h-2 w-full overflow-hidden rounded-full bg-secondary\", className)}\n    {...props}\n  >\n    <div\n      className=\"h-full w-full flex-1 bg-primary transition-all\"\n      style={{ transform: `translateX(-${100 - (value ?? 0)}%)` }}\n    />\n  </div>\n));\nProgress.displayName = \"Progress\";\n\nexport { Progress };", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 697, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2bb0b62f-efc2-42fa-835f-c4f9bd4e307e": {"__data__": {"id_": "2bb0b62f-efc2-42fa-835f-c4f9bd4e307e", "embedding": null, "metadata": {"file_path": "/app/frontend/src/components/ui/textarea.tsx", "file_name": "textarea.tsx", "file_size": 759, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6b01b50d-f743-464f-8591-ff57ce92874b", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/components/ui/textarea.tsx", "file_name": "textarea.tsx", "file_size": 759, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "758fdb306a3532d493104e9f40ba523de23a92756ee876e05fafe5d090464782", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import * as React from \"react\"\n\nimport { cn } from \"@/lib/utils\"\n\nfunction Textarea({ className, ...props }: React.ComponentProps<\"textarea\">) {\n  return (\n    <textarea\n      data-slot=\"textarea\"\n      className={cn(\n        \"border-input placeholder:text-muted-foreground focus-visible:border-ring focus-visible:ring-ring/50 aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive dark:bg-input/30 flex field-sizing-content min-h-16 w-full rounded-md border bg-transparent px-3 py-2 text-base shadow-xs transition-[color,box-shadow] outline-none focus-visible:ring-[3px] disabled:cursor-not-allowed disabled:opacity-50 md:text-sm\",\n        className\n      )}\n      {...props}\n    />\n  )\n}\n\nexport { Textarea }", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 758, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "583e20fa-797d-4063-9035-2ff6c215a5cb": {"__data__": {"id_": "583e20fa-797d-4063-9035-2ff6c215a5cb", "embedding": null, "metadata": {"file_path": "/app/frontend/src/lib/api.ts", "file_name": "api.ts", "file_size": 278, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a79f9fad-846d-42a7-a1ed-841576ea7cc7", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/lib/api.ts", "file_name": "api.ts", "file_size": 278, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "3dafd58c6d6a11a0549757652da56777357bf21a0eff2ba71d7c5967e38cc44b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: lib/api.ts\n// Directory: frontend/src/lib\n// Purpose: Single source of truth for backend API config\n\nexport const API_ROOT =\n  process.env.NEXT_PUBLIC_API_URL || \"http://localhost:8080\";\n\nexport const API_KEY =\n  process.env.NEXT_PUBLIC_API_KEY ?? \"\";  // \u2190 new line", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 275, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f2029156-4a07-4dba-b7fa-2ac17095c6f7": {"__data__": {"id_": "f2029156-4a07-4dba-b7fa-2ac17095c6f7", "embedding": null, "metadata": {"file_path": "/app/frontend/src/lib/toMDString.ts", "file_name": "toMDString.ts", "file_size": 422, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e3d56383-8ec4-4f60-a1d6-55af0efb02da", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/lib/toMDString.ts", "file_name": "toMDString.ts", "file_size": 422, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "425d1e3ef4e6ce1bbac0b3ca3bfba9b311ce62fe8247e29d2cfeecee1eedc9ab", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "export function toMDString(val: unknown): string {\n  if (val == null) return \"\";\n  if (typeof val === \"string\") return val;\n  if (Array.isArray(val)) {\n    return val.map((v) => toMDString(v)).join(\"\\n\\n\");\n  }\n  if (typeof val === \"object\") {\n    try {\n      return \"```json\\n\" + JSON.stringify(val, null, 2) + \"\\n```\";\n    } catch {\n      return String(val);\n    }\n  }\n  return String(val);\n}\nexport default toMDString;", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 421, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2ae03bcc-cfe6-41bc-9cad-1321dce29faf": {"__data__": {"id_": "2ae03bcc-cfe6-41bc-9cad-1321dce29faf", "embedding": null, "metadata": {"file_path": "/app/frontend/src/lib/utils.ts", "file_name": "utils.ts", "file_size": 196, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "51ed9f1a-5cb1-4abe-8a10-6b80c989e0be", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/lib/utils.ts", "file_name": "utils.ts", "file_size": 196, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "389b714364107934f9534eb07b35f6d028b980a5a751552d330eb52ecf5c9e93", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// File: src/lib/utils.ts\n\nimport { clsx, type ClassValue } from \"clsx\";\nimport { twMerge } from \"tailwind-merge\";\n\nexport function cn(...inputs: ClassValue[]) {\n  return twMerge(clsx(inputs));\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 195, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "81a8ad59-0214-493c-a562-d21ec84f393c": {"__data__": {"id_": "81a8ad59-0214-493c-a562-d21ec84f393c", "embedding": null, "metadata": {"file_path": "/app/frontend/src/types/react-syntax-highlighter.d.ts", "file_name": "react-syntax-highlighter.d.ts", "file_size": 173, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c3e48bdd-d448-4c6b-8eb0-9318f858698a", "node_type": "4", "metadata": {"file_path": "/app/frontend/src/types/react-syntax-highlighter.d.ts", "file_name": "react-syntax-highlighter.d.ts", "file_size": 173, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "402713ab6b2fceaaecae24a956e0080d043f4bbf0a57aca9c9a659191f10704a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "declare module \"react-syntax-highlighter\";\ndeclare module \"react-syntax-highlighter/dist/esm/styles/prism\";\ndeclare module \"react-syntax-highlighter/dist/cjs/styles/prism\";", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 172, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f4f632a4-96cd-4add-a588-5af2bdd9f062": {"__data__": {"id_": "f4f632a4-96cd-4add-a588-5af2bdd9f062", "embedding": null, "metadata": {"file_path": "/app/frontend/sync/sync_google_docs.py", "file_name": "sync_google_docs.py", "file_type": "text/x-python", "file_size": 4982, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4702d470-b5e3-423d-98b4-b8ce9496c83e", "node_type": "4", "metadata": {"file_path": "/app/frontend/sync/sync_google_docs.py", "file_name": "sync_google_docs.py", "file_type": "text/x-python", "file_size": 4982, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "aa0475676c85c49d255d34d0e510b44280d6d37d521f486d1b49613b9be904a9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "352c48a0-8fda-44d2-8de7-781cea9bc56f", "node_type": "1", "metadata": {}, "hash": "79de0970ce49e39017540c8720e30d4e56e7392169ead85846748ced62d82d31", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: services/google_docs_sync.py\n# Purpose: Google Docs sync for COMMAND_CENTER folder \u2192 local /docs/imported\n# Directory Structure:\n# - GOOGLE_CREDS_JSON is decoded at runtime into /tmp/credentials.json\n# - GOOGLE_TOKEN_JSON is decoded (if present) into frontend/sync/token.json\n# - Synced .md files are saved into docs/imported/\n# - OAuth flow is launched only if token is missing or invalid\n\nimport os\nimport json\nimport base64\nfrom pathlib import Path\nfrom google.oauth2.credentials import Credentials\nfrom google_auth_oauthlib.flow import InstalledAppFlow\nfrom googleapiclient.discovery import build\nfrom googleapiclient.errors import HttpError\nfrom markdownify import markdownify as md\nfrom google.auth.transport.requests import Request\n\n# === Config ===\nSCOPES = [\n    \"https://www.googleapis.com/auth/drive.readonly\",\n    \"https://www.googleapis.com/auth/documents.readonly\"\n]\nCREDENTIALS_PATH = Path(\"/tmp/credentials.json\")\nTOKEN_PATH = Path(\"frontend/sync/token.json\")\nIMPORT_PATH = Path(\"docs/imported\")\nCOMMAND_CENTER_FOLDER_NAME = \"COMMAND_CENTER\"\nIMPORT_PATH.mkdir(parents=True, exist_ok=True)\n\n# === Auth ===\ndef get_google_service():\n    creds = None\n\n    # Decode credentials from env at runtime only\n    if not CREDENTIALS_PATH.exists():\n        if os.getenv(\"ENV\") == \"local\":\n            local_path = Path(\"frontend/sync/credentials.json\")\n            print(\"\ud83d\udd27 Using local credentials.json from frontend/sync/\")\n            if not local_path.exists():\n                raise FileNotFoundError(\"\u274c Local credentials.json not found at frontend/sync/\")\n            CREDENTIALS_PATH.write_text(local_path.read_text())\n        else:\n            raw = os.getenv(\"GOOGLE_CREDS_JSON\")\n            print(\"\ud83e\uddea Length of GOOGLE_CREDS_JSON:\", len(raw) if raw else \"Not Found\")\n            if not raw:\n                raise FileNotFoundError(\"\u274c Missing GOOGLE_CREDS_JSON in environment variables\")\n            decoded = base64.b64decode(raw.encode()).decode()\n            CREDENTIALS_PATH.write_text(decoded)\n            print(f\"\u2705 credentials.json written to: {CREDENTIALS_PATH}\")\n\n    # Decode token from env at runtime only (optional bootstrap)\n    if not TOKEN_PATH.exists():\n        token_raw = os.getenv(\"GOOGLE_TOKEN_JSON\")\n        print(\"\ud83e\uddea GOOGLE_TOKEN_JSON found:\", bool(token_raw))\n        if token_raw:\n            TOKEN_PATH.write_text(base64.b64decode(token_raw).decode())\n            print(f\"\u2705 token.json written to: {TOKEN_PATH}\")\n\n    # Load token if available\n    if TOKEN_PATH.exists():\n        creds = Credentials.from_authorized_user_file(TOKEN_PATH, SCOPES)\n\n    # If token missing or expired, launch interactive auth flow\n    if not creds or not creds.valid:\n        if creds and creds.expired and creds.refresh_token:\n            creds.refresh(Request())\n        else:\n            flow = InstalledAppFlow.from_client_secrets_file(str(CREDENTIALS_PATH), SCOPES)\n            print(\"\ud83c\udf10 Launching OAuth flow on dynamic localhost port...\")\n            creds = flow.run_local_server(port=0)\n        # Save new token\n        with open(TOKEN_PATH, 'w') as token:\n            token.write(creds.to_json())\n\n    # Build API clients\n    drive_service = build('drive', 'v3', credentials=creds)\n    docs_service = build('docs', 'v1', credentials=creds)\n    return drive_service, docs_service\n\n# === Google Docs Operations ===\ndef find_folder_id(drive_service, folder_name):\n    results = drive_service.files().list(\n        q=f\"mimeType='application/vnd.google-apps.folder' and name='{folder_name}'\",\n        spaces='drive',\n        fields=\"files(id, name)\",\n    ).execute()\n    folders = results.get('files', [])\n    return folders[0]['id'] if folders else None\n\ndef get_docs_in_folder(drive_service, folder_id):\n    query = f\"'{folder_id}' in parents and mimeType='application/vnd.google-apps.document'\"\n    results = drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n    return results.get('files', [])\n\ndef fetch_and_save_doc(docs_service, file):\n    doc = docs_service.documents().get(documentId=file['id']).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4050, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "352c48a0-8fda-44d2-8de7-781cea9bc56f": {"__data__": {"id_": "352c48a0-8fda-44d2-8de7-781cea9bc56f", "embedding": null, "metadata": {"file_path": "/app/frontend/sync/sync_google_docs.py", "file_name": "sync_google_docs.py", "file_type": "text/x-python", "file_size": 4982, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4702d470-b5e3-423d-98b4-b8ce9496c83e", "node_type": "4", "metadata": {"file_path": "/app/frontend/sync/sync_google_docs.py", "file_name": "sync_google_docs.py", "file_type": "text/x-python", "file_size": 4982, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "aa0475676c85c49d255d34d0e510b44280d6d37d521f486d1b49613b9be904a9", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f4f632a4-96cd-4add-a588-5af2bdd9f062", "node_type": "1", "metadata": {"file_path": "/app/frontend/sync/sync_google_docs.py", "file_name": "sync_google_docs.py", "file_type": "text/x-python", "file_size": 4982, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "e923e22cdd212700442d4f8f1170c7192275436f6cc29612c7fcd84b86e73857", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "'v1', credentials=creds)\n    return drive_service, docs_service\n\n# === Google Docs Operations ===\ndef find_folder_id(drive_service, folder_name):\n    results = drive_service.files().list(\n        q=f\"mimeType='application/vnd.google-apps.folder' and name='{folder_name}'\",\n        spaces='drive',\n        fields=\"files(id, name)\",\n    ).execute()\n    folders = results.get('files', [])\n    return folders[0]['id'] if folders else None\n\ndef get_docs_in_folder(drive_service, folder_id):\n    query = f\"'{folder_id}' in parents and mimeType='application/vnd.google-apps.document'\"\n    results = drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n    return results.get('files', [])\n\ndef fetch_and_save_doc(docs_service, file):\n    doc = docs_service.documents().get(documentId=file['id']).execute()\n    title = file['name'].replace(\" \", \"_\").lower()\n    content = doc.get(\"body\", {}).get(\"content\", [])\n    html = \"\"\n    for element in content:\n        if 'paragraph' in element:\n            for el in element['paragraph'].get('elements', []):\n                html += el.get('textRun', {}).get('content', '')\n            html += \"\\n\"\n    markdown = md(html)\n    out_path = IMPORT_PATH / f\"{title}.md\"\n    out_path.write_text(markdown, encoding='utf-8')\n    return out_path.name\n\n# === Main Sync Function ===\ndef sync_google_docs():\n    drive_service, docs_service = get_google_service()\n    folder_id = find_folder_id(drive_service, COMMAND_CENTER_FOLDER_NAME)\n    if not folder_id:\n        raise RuntimeError(f\"Folder '{COMMAND_CENTER_FOLDER_NAME}' not found in Google Drive\")\n    files = get_docs_in_folder(drive_service, folder_id)\n    return [fetch_and_save_doc(docs_service, f) for f in files]", "mimetype": "text/plain", "start_char_idx": 3243, "end_char_idx": 4959, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8378ca07-03b3-4bd5-85d2-2c017fc57bd8": {"__data__": {"id_": "8378ca07-03b3-4bd5-85d2-2c017fc57bd8", "embedding": null, "metadata": {"file_path": "/app/frontend/tailwind.config.js", "file_name": "tailwind.config.js", "file_type": "application/javascript", "file_size": 907, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "23bfc72b-9aa6-429c-a479-4f297d928fdc", "node_type": "4", "metadata": {"file_path": "/app/frontend/tailwind.config.js", "file_name": "tailwind.config.js", "file_type": "application/javascript", "file_size": 907, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "550c773ac5f62af6b3d675b5e770bd5da5680d7e77fb91be0f07fd5dee832014", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "/** @type {import('tailwindcss').Config} */\nmodule.exports = {\n  content: [\n    './app/**/*.{js,ts,jsx,tsx,mdx}',\n    './components/**/*.{js,ts,jsx,tsx,mdx}',\n    './src/app/**/*.{js,ts,jsx,tsx,mdx}',\n    './src/components/**/*.{js,ts,jsx,tsx,mdx}',\n    './src/layouts/**/*.{js,ts,jsx,tsx,mdx}',\n    './src/**/*.mdx'\n  ],\n  theme: {\n    extend: {\n      fontFamily: {\n        sans: ['var(--font-geist-sans)', 'ui-sans-serif', 'system-ui'],\n        mono: ['var(--font-geist-mono)', 'ui-monospace', 'SFMono-Regular']\n      },\n      borderRadius: {\n        sm: 'calc(var(--radius) - 4px)',\n        md: 'calc(var(--radius) - 2px)',\n        lg: 'var(--radius)',\n        xl: 'calc(var(--radius) + 4px)'\n      },\n      colors: {\n        border: 'var(--border)'\n        // You can add more: e.g., background, foreground, etc.\n      }\n    }\n  },\n  darkMode: 'class',\n  plugins: [require('@tailwindcss/typography')]\n};", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 907, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a7a8c658-3b25-45ac-908b-4a4d99608463": {"__data__": {"id_": "a7a8c658-3b25-45ac-908b-4a4d99608463", "embedding": null, "metadata": {"file_path": "/app/frontend/types/next-auth.d.ts", "file_name": "next-auth.d.ts", "file_size": 655, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "66cc2062-33de-4764-b8c6-e57609ddd7be", "node_type": "4", "metadata": {"file_path": "/app/frontend/types/next-auth.d.ts", "file_name": "next-auth.d.ts", "file_size": 655, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "2dd0004ff8584d3d793b8d9820b16ae73cc1ff427512848103ecf6d7aa3c9988", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "// /types/next-auth.d.ts\nimport NextAuth, { DefaultSession, DefaultUser, Profile as DefaultProfile } from \"next-auth\";\n\ndeclare module \"next-auth\" {\n  interface Profile extends DefaultProfile {\n    hd?: string; // Add hosted domain for Google SSO\n    picture?: string; // Add picture if you want it\n  }\n  interface Session {\n    user?: {\n      name?: string | null;\n      email?: string | null;\n      image?: string | null;\n      hd?: string | null;     // Add this line\n      picture?: string | null; // If you want it\n    };\n    accessToken?: string;\n  }\n  interface User extends DefaultUser {\n    hd?: string | null;\n    picture?: string | null;\n  }\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 654, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "effa620f-ffcb-41e7-9c3c-fd3b4001d9d1": {"__data__": {"id_": "effa620f-ffcb-41e7-9c3c-fd3b4001d9d1", "embedding": null, "metadata": {"file_path": "/app/frontend/vitest.config.ts", "file_name": "vitest.config.ts", "file_size": 1230, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "01473aef-6ebb-4465-8de0-bbdef5c0964f", "node_type": "4", "metadata": {"file_path": "/app/frontend/vitest.config.ts", "file_name": "vitest.config.ts", "file_size": 1230, "creation_date": "2025-07-01", "last_modified_date": "2025-07-01", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "e6cadf71d63609b72813f34c8561758dfbf231be0e972a97b648547506270e94", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import path from 'node:path';\nimport { fileURLToPath } from 'node:url';\n\nimport { defineConfig } from 'vitest/config';\n\nimport { storybookTest } from '@storybook/addon-vitest/vitest-plugin';\n\nconst dirname =\n  typeof __dirname !== 'undefined' ? __dirname : path.dirname(fileURLToPath(import.meta.url));\n\n// More info at: https://storybook.js.org/docs/next/writing-tests/integrations/vitest-addon\nexport default defineConfig({\n  test: {\n    workspace: [\n      {\n        extends: true,\n        plugins: [\n          // The plugin will run tests for the stories defined in your Storybook config\n          // See options at: https://storybook.js.org/docs/next/writing-tests/integrations/vitest-addon#storybooktest\n          storybookTest({ configDir: path.join(dirname, '.storybook') }),\n        ],\n        test: {\n          name: 'storybook',\n          browser: {\n        enabled: true,\n        headless: true,\n        provider: 'playwright',\n        instances: [{ browser: 'chromium' }]\n      },\n          setupFiles: ['.storybook/vitest.setup.ts'],\n        },\n      },\n      {\n        extends: true,\n        test: {\n          name: 'unit',\n          include: ['tests/**/*.{test,spec}.{ts,tsx}'],\n        },\n      },\n    ],\n  },\n});", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1229, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ba2dd8af-7a91-4c38-a6d2-d4f3d5ab4090": {"__data__": {"id_": "ba2dd8af-7a91-4c38-a6d2-d4f3d5ab4090", "embedding": null, "metadata": {"file_path": "/app/frontend/vitest.shims.d.ts", "file_name": "vitest.shims.d.ts", "file_size": 62, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7c7fe7f9-a8a9-4aae-9e35-58d2e32568e0", "node_type": "4", "metadata": {"file_path": "/app/frontend/vitest.shims.d.ts", "file_name": "vitest.shims.d.ts", "file_size": 62, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "ec2cc5c5aea48d035308eaf16af7a3ff56833725a6b739a4efb8ef36e41a4afc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "/// <reference types=\"@vitest/browser/providers/playwright\" />", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 62, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "dab8d5be-21c9-4a78-b599-01e15649ab96": {"__data__": {"id_": "dab8d5be-21c9-4a78-b599-01e15649ab96", "embedding": null, "metadata": {"file_path": "/app/services/_init_.py", "file_name": "_init_.py", "file_type": "text/x-python", "file_size": 98, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2a2604b2-0de1-4e80-b035-0bfbba879412", "node_type": "4", "metadata": {"file_path": "/app/services/_init_.py", "file_name": "_init_.py", "file_type": "text/x-python", "file_size": 98, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "ae560f6a8004c3db0287360608655e6ad768abbde86c6c413b9efe343007c946", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: __init__.py\n# Directory: services/\n# Purpose: Marks this as a package for Python imports.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 97, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b285176c-bfd4-4d9f-a14e-92f8b102764e": {"__data__": {"id_": "b285176c-bfd4-4d9f-a14e-92f8b102764e", "embedding": null, "metadata": {"file_path": "/app/services/agent.py", "file_name": "agent.py", "file_type": "text/x-python", "file_size": 9196, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ce8f1b4e-6cc0-4865-9ae3-88b8482ddb4e", "node_type": "4", "metadata": {"file_path": "/app/services/agent.py", "file_name": "agent.py", "file_type": "text/x-python", "file_size": 9196, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "8f9f7416235fe83580f1aba9544a59ac5ca8aa0d71143e39b0c307ac259064b1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1e58e16c-0829-4ef3-812a-b296fff5d56b", "node_type": "1", "metadata": {}, "hash": "13ed1efb51426d9698fb7ab2b676ecf6e855a79aca15cdd1e1cbeb9c876f61a0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: agent.py\r\n# Directory: services/\r\n# Purpose: Main Relay agent logic\u2014per-user, multi-turn, reflection, tools, OpenAI, and docgen\r\n\r\nimport os\r\nimport re\r\nimport json\r\nfrom pathlib import Path\r\nfrom typing import List, Dict, Any, Optional, AsyncGenerator\nfrom openai import AsyncOpenAI\nimport services.kb as kb\nimport httpx\nfrom services.context_engine import ContextEngine\nfrom utils.openai_client import create_openai_client\n\r\n# === Initialize OpenAI client ===\nclient = create_openai_client()\n\r\n# === Railway control endpoint for queueing actions/docs ===\nRAILWAY_KEY = os.getenv(\"API_KEY\")\nRAILWAY_URL = os.getenv(\"RAILWAY_URL\", \"https://relay.wildfireranch.us/control/queue_action\")\n\n# Optional reflection flag\nREFLECT_ENV = os.getenv(\"ENABLE_REFLECT_AND_PLAN\", \"false\").lower() in (\"1\", \"true\", \"yes\")\n\r\n# === System prompt to define Relay's identity and context awareness ===\r\nSYSTEM_PROMPT = \"\"\"\r\nYou are Relay, the intelligent assistant for Bret's WildfireRanch pursuits including the solar shack project (solar powered bitcoin mining) and developing a business plan for a utility scale solar farm.\r\nYou have access to:\r\n\r\n- Python source code in /services/\r\n- React and Next.js components in /frontend/src/app/ and /frontend/src/components/\r\n- FastAPI routes in /routes/\r\n- A local knowledge base in /docs/\r\n\r\nUse file paths in citations when helpful (e.g. src/components/LogsPanel/LogsPanel.tsx).\r\nIf the user asks about code, structure, or documentation, include relevant context.\r\nYou can generate and queue new documentation entries by calling /control/queue_action.\r\n\"\"\"\r\n\r\n# === Helper: detect requests to autogenerate docs ===\r\ndef wants_docgen(query: str) -> Optional[str]:\r\n    match = re.search(r\"(?:generate|create|make).*doc.*for ([\\w/\\\\.]+\\.\\w+)\", query.lower())\r\n    return match.group(1).strip() if match else None\r\n\r\n# === In-memory store for multi-turn history (per user) ===\r\nconversation_history: Dict[str, List[Dict[str, Any]]] = {}\r\n\r\n# === Tool dispatchers ===\r\nasync def search_docs(query: str, user_id: str) -> Dict[str, Any]:\r\n    hits = kb.search(query, user_id=user_id, k=5) if 'user_id' in kb.search.__code__.co_varnames else kb.search(query, k=5)\r\n    return {\"matches\": hits}\r\n\r\nasync def run_code_review(path: str) -> Dict[str, Any]:\r\n    base = Path(__file__).resolve().parents[1]\r\n    target = base / path\r\n    if not target.exists() or not target.is_file():\r\n        return {\"issues\": [{\"path\": path, \"error\": \"File not found\"}]}  \r\n    content = target.read_text()\r\n    return {\"issues\": [{\"path\": path, \"summary\": f\"File loaded, {len(content)} characters\"}]}  \r\n\r\n# === Reflection & plan generation ===\r\nasync def reflect_and_plan(user_id: str, query: str) -> Dict[str, Any]:\r\n    messages = [\r\n        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\r\n        {\"role\": \"assistant\", \"content\": f\"Previous context:\\n{kb.get_recent_summaries(user_id)}\" if hasattr(kb, \"get_recent_summaries\") else \"\"},\r\n        {\"role\": \"user\", \"content\": f\"Reflect on this query for planning: {query}\"},\r\n    ]\r\n    response = await client.chat.completions.create(\r\n        model=\"gpt-4o\",\r\n        messages=messages,\r\n        temperature=0.0,\r\n        stream=False\r\n    )\r\n    try:\r\n        return json.loads(response.choices[0].message.content)\r\n    except json.JSONDecodeError:\r\n        return {\"plan\": []}\r\n\r\n# === Main answer function supporting multi-turn, tools, and reflection ===\r\nasync def answer(\n    user_id: str,\n    query: str,\n    context: Optional[str] = None,\n    stream: bool = False,\n    reflect: Optional[bool] = None,\n) -> Any:\n    \"\"\"Main agent entry point.\n\n    Parameters\n    ----------\n    user_id: str\n        Unique user identifier used for history and KB.\n    query: str\n        Raw user question.\n    context: Optional[str]\n        Pre-built context window. If not supplied the ContextEngine will\n        generate one from the user's query.\n    stream: bool\n        If ``True`` yield tokens as they are produced by OpenAI.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3982, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1e58e16c-0829-4ef3-812a-b296fff5d56b": {"__data__": {"id_": "1e58e16c-0829-4ef3-812a-b296fff5d56b", "embedding": null, "metadata": {"file_path": "/app/services/agent.py", "file_name": "agent.py", "file_type": "text/x-python", "file_size": 9196, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ce8f1b4e-6cc0-4865-9ae3-88b8482ddb4e", "node_type": "4", "metadata": {"file_path": "/app/services/agent.py", "file_name": "agent.py", "file_type": "text/x-python", "file_size": 9196, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "8f9f7416235fe83580f1aba9544a59ac5ca8aa0d71143e39b0c307ac259064b1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b285176c-bfd4-4d9f-a14e-92f8b102764e", "node_type": "1", "metadata": {"file_path": "/app/services/agent.py", "file_name": "agent.py", "file_type": "text/x-python", "file_size": 9196, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "b9360c12045479b39c51bde4786b80ed1d245edd6d4b652e953faaa3db92a79d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1290e127-c2c0-480b-9a25-9ec9598b3cf0", "node_type": "1", "metadata": {}, "hash": "ac968d87f6337a724eb94f545672e67ffdc77b2a39f4ec65316b6f6f0675b098", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Parameters\n    ----------\n    user_id: str\n        Unique user identifier used for history and KB.\n    query: str\n        Raw user question.\n    context: Optional[str]\n        Pre-built context window. If not supplied the ContextEngine will\n        generate one from the user's query.\n    stream: bool\n        If ``True`` yield tokens as they are produced by OpenAI.  Otherwise\n        return the complete assistant message as a string.\n    reflect: Optional[bool]\n        If ``True`` run ``reflect_and_plan`` before answering. Defaults to\n        ``ENABLE_REFLECT_AND_PLAN`` environment variable when ``None``.\n    \"\"\"\n\n    print(f\"[agent] Incoming query from {user_id}: {query}\")\n\n    # --- Check for doc generation ---\n    target_path = wants_docgen(query)\n    if target_path:\n        return await generate_doc_for_path(target_path)\n\n    # --- Build context if not provided ---\n    if context is None:\n        engine = ContextEngine(user_id=user_id)\n        context = engine.build_context(query)\n    print(f\"[agent] Built context length: {len(context)} chars\")\n\r\n    # --- Reflection & planning (optional) ---\n    use_reflection = reflect if reflect is not None else REFLECT_ENV\n    if use_reflection:\n        plan = await reflect_and_plan(user_id, query)\n        print(f\"[agent] Reflection plan: {plan}\")\n    else:\n        plan = {\"plan\": []}\n\r\n    # --- Update conversation history ---\r\n    history = conversation_history.setdefault(user_id, [])\r\n    history.append({\"role\": \"user\", \"content\": query})\r\n    \r\n    # --- Compose messages with history and plan ---\r\n    messages: List[Dict[str, Any]] = [\r\n        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\r\n        {\"role\": \"system\", \"content\": f\"Context:\\n{context}\"},\r\n        {\"role\": \"assistant\", \"content\": f\"Plan: {json.dumps(plan)}\"},\r\n    ] + history\r\n\r\n    try:\n        response = await client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=messages,\n            stream=stream,\n            temperature=0.3,\n            functions=[\n                {\n                    \"name\": \"search_docs\",\n                    \"description\": \"Search the local /docs/ for keywords\",\n                    \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\":\"string\"}, \"user_id\": {\"type\":\"string\"}}, \"required\":[\"query\",\"user_id\"]}\n                },\r\n                {\r\n                    \"name\": \"run_code_review\",\r\n                    \"description\": \"Run static analysis on a source file path\",\r\n                    \"parameters\": {\"type\":\"object\",\"properties\":{\"path\":{\"type\":\"string\"}},\"required\":[\"path\"]}\r\n                }\r\n            ],\r\n            function_call=\"auto\"\r\n        )\r\n        if stream:\n            async def gen() -> AsyncGenerator[str, None]:\n                collected: List[str] = []\n                async for chunk in response:\n                    delta = chunk.choices[0].delta\n                    if delta and delta.content:\n                        collected.append(delta.content)\n                        yield delta.content\n                history.append({\"role\": \"assistant\", \"content\": \"\".join(collected)})\n\n            return gen()\n        else:\n            message = response.choices[0].message\n            if hasattr(message, \"function_call\") and message.function_call:\n                fname = message.function_call.name\n                fargs = json.loads(message.function_call.arguments)\n                if fname == \"search_docs\":\n                    result = await search_docs(**fargs)\n                elif fname == \"run_code_review\":\n                    result = await run_code_review(**fargs)\n                else:\n                    result = {\"error\": f\"Unknown function: {fname}\"}\n                return json.dumps(result)\n            else:\n                history.append({\"role\": \"assistant\", \"content\": message.content})\n                return message.content\n\r\n    except Exception as e:\r\n        print(\"\u274c OpenAI call failed:\", str(e))\r\n        return f\"[error] OpenAI call failed. {str(e)}\"\r\n\r\n# === Generate and queue documentation for a specific source file ===\r\nasync def generate_doc_for_path(rel_path: str) -> str:\r\n    base = Path(__file__).resolve().parents[1]\r\n    full_path = base / rel_path\r\n\r\n    if not full_path.exists():\r\n        return f\"[error] File not found: {rel_path}\"\r\n\r\n    content = full_path.read_text()\r\n    prompt = f\"\"\"\r\nYou are a helpful documentation bot. Read the following source file and write a useful Markdown documentation entry about what it is, what it does, and how it's used. Keep it concise and developer-friendly.", "mimetype": "text/plain", "start_char_idx": 3616, "end_char_idx": 8204, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1290e127-c2c0-480b-9a25-9ec9598b3cf0": {"__data__": {"id_": "1290e127-c2c0-480b-9a25-9ec9598b3cf0", "embedding": null, "metadata": {"file_path": "/app/services/agent.py", "file_name": "agent.py", "file_type": "text/x-python", "file_size": 9196, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ce8f1b4e-6cc0-4865-9ae3-88b8482ddb4e", "node_type": "4", "metadata": {"file_path": "/app/services/agent.py", "file_name": "agent.py", "file_type": "text/x-python", "file_size": 9196, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "8f9f7416235fe83580f1aba9544a59ac5ca8aa0d71143e39b0c307ac259064b1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1e58e16c-0829-4ef3-812a-b296fff5d56b", "node_type": "1", "metadata": {"file_path": "/app/services/agent.py", "file_name": "agent.py", "file_type": "text/x-python", "file_size": 9196, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "705722a968285202d91b53c382dcd2e3b1ff6d6e5a0b7687afc5cb49c3bd67e6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "{str(e)}\"\r\n\r\n# === Generate and queue documentation for a specific source file ===\r\nasync def generate_doc_for_path(rel_path: str) -> str:\r\n    base = Path(__file__).resolve().parents[1]\r\n    full_path = base / rel_path\r\n\r\n    if not full_path.exists():\r\n        return f\"[error] File not found: {rel_path}\"\r\n\r\n    content = full_path.read_text()\r\n    prompt = f\"\"\"\r\nYou are a helpful documentation bot. Read the following source file and write a useful Markdown documentation entry about what it is, what it does, and how it's used. Keep it concise and developer-friendly.\r\n\r\nFile: {rel_path}\r\n{content[:3000]}\r\n\"\"\"\r\n\r\n    response = await client.chat.completions.create(\r\n        model=\"gpt-4o\",\r\n        messages=[\r\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\r\n            {\"role\": \"user\", \"content\": prompt},\r\n        ],\r\n        stream=False,\r\n        temperature=0.3,\r\n    )\r\n\r\n    doc_markdown = response.choices[0].message.content\r\n    doc_path = f\"docs/generated/{rel_path.replace('/', '_').replace('.', '-')}.md\"\r\n\r\n    payload = {\r\n        \"type\": \"write_file\",\r\n        \"path\": doc_path,\r\n        \"content\": doc_markdown\r\n    }\r\n\r\n    async with httpx.AsyncClient() as http_client:\r\n        res = await http_client.post(\r\n            RAILWAY_URL,\r\n            headers={\"X-API-Key\": RAILWAY_KEY},\r\n            json=payload\r\n        )\r\n        if res.status_code == 200:\r\n            return f\"\u2705 Documentation queued to: {doc_path}\"\r\n        else:\r\n            return f\"\u274c Failed to queue documentation: {res.status_code} {res.text}\"", "mimetype": "text/plain", "start_char_idx": 7631, "end_char_idx": 9186, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ba9efcf4-99fd-4857-ac01-9535326e112b": {"__data__": {"id_": "ba9efcf4-99fd-4857-ac01-9535326e112b", "embedding": null, "metadata": {"file_path": "/app/services/config.py", "file_name": "config.py", "file_type": "text/x-python", "file_size": 541, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "db1c1dd4-e446-4a36-bbeb-6f062184d226", "node_type": "4", "metadata": {"file_path": "/app/services/config.py", "file_name": "config.py", "file_type": "text/x-python", "file_size": 541, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "728d3ee9a7bf56c475964215c23bf9c43cba7079c334eaaeeb37b8242e2482ef", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "import os\nfrom pathlib import Path\n\n# Use current working directory as fallback\nDEFAULT_PROJECT_ROOT = Path.cwd()\n\nENV_NAME = os.getenv(\"ENV\", \"dev\")\nMODEL_NAME = (\n    os.getenv(\"KB_EMBED_MODEL\")\n    or os.getenv(\"OPENAI_EMBED_MODEL\")\n    or \"text-embedding-3-large\"\n)\n\n# Safer defaults: allow override, but don't break in test/dev\nINDEX_ROOT = Path(os.getenv(\"INDEX_ROOT\", str(DEFAULT_PROJECT_ROOT / \"index\" / ENV_NAME)))\nINDEX_DIR = Path(os.getenv(\"INDEX_DIR\", str(INDEX_ROOT / MODEL_NAME)))\n\nINDEX_DIR.mkdir(parents=True, exist_ok=True)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 540, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "576cae6c-ea8a-438a-97b1-48378a4fa730": {"__data__": {"id_": "576cae6c-ea8a-438a-97b1-48378a4fa730", "embedding": null, "metadata": {"file_path": "/app/services/context_engine.py", "file_name": "context_engine.py", "file_type": "text/x-python", "file_size": 864, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1935e98d-a918-4965-aa8c-42100ea35d84", "node_type": "4", "metadata": {"file_path": "/app/services/context_engine.py", "file_name": "context_engine.py", "file_type": "text/x-python", "file_size": 864, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "b72b2ae33b911aaff35184a74d27a614b9e2bed683e59c7d5f2104d033d064d0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: services/context_engine.py\n# Purpose: Drop-in ContextEngine class for all context operations (build, clear cache, etc.)\n\nfrom services.context_injector import build_context\n\nclass ContextEngine:\n    \"\"\"\n    Facade for agent context building, cache clearing, and future extensions.\n    Call anywhere as ContextEngine.build(...) or ContextEngine.clear_cache().\n    \"\"\"\n\n    @staticmethod\n    async def build(\n        query: str, \n        files: list[str], \n        topics: list[str] = [], \n        debug: bool = False\n    ):\n        \"\"\"\n        Build multi-source context for agent prompts.\n        \"\"\"\n        return await build_context(query, files, topics, debug)\n\n    @staticmethod\n    def clear_cache():\n        \"\"\"\n        Placeholder for clearing context/semantic/graph/global caches.\n        Expand as needed for production.\n        \"\"\"\n        pass", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 863, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e255bed3-abfc-491a-8360-7f037dcd93b0": {"__data__": {"id_": "e255bed3-abfc-491a-8360-7f037dcd93b0", "embedding": null, "metadata": {"file_path": "/app/services/context_injector.py", "file_name": "context_injector.py", "file_type": "text/x-python", "file_size": 6823, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a117da46-3a36-43ae-ba92-2cd106769ebb", "node_type": "4", "metadata": {"file_path": "/app/services/context_injector.py", "file_name": "context_injector.py", "file_type": "text/x-python", "file_size": 6823, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "bfa461031936b927e82717df3f9bcf123de3f1eb51f3dd430d21bee6661bca30", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d7c1ed8d-42ac-466a-88b5-b53ffdf3a1ad", "node_type": "1", "metadata": {}, "hash": "4c366a55829db5786484fa1dd8fe2a31eaeac9e9f9d92c216e0b6b38017edd69", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: services/context_injector.py\n# Purpose: Build optimal multi-source context blocks for agent prompts (code, docs, external topics, global context, knowledge base, and graph memory), \n#           leveraging LlamaIndex for semantic search and aggressive filtering.\n# Updated: 2025-07-02\n\nimport os\nfrom pathlib import Path\nfrom typing import List, Dict, Any, Union\n\nfrom services.semantic_retriever import get_semantic_context      # LlamaIndex semantic search\nfrom services.kb import query_index                              # Legacy KB (for optional hybrid)\nfrom services.graph import summarize_recent_context              # Graph-based memory (optional)\nfrom services.summarize_memory import summarize_memory_entry     # For summarizing recent memory, optional\n\n# === Section limits/config ===\nMAX_PROJECT_SUMMARY_CHARS = 2000\nMAX_SEMANTIC_CONTEXT_CHARS = 6000\nMAX_GRAPH_MEMORY_CHARS = 1500\nMAX_EXTERNAL_CONTEXT_CHARS = 1500\nMAX_GLOBAL_CONTEXT_CHARS = 2000\n\ndef safe_truncate(text: str, max_chars: int) -> str:\n    \"\"\"Truncates text safely, appends ellipsis if needed.\"\"\"\n    if not text: return \"\"\n    if len(text) <= max_chars: return text\n    return text[:max_chars] + \"\\n...[truncated]\"\n\n# === Load Project Summary ===\ndef load_summary(summary_file: str = \"./docs/PROJECT_SUMMARY.md\") -> str:\n    \"\"\"Loads and safely truncates the project summary file.\"\"\"\n    if os.path.exists(summary_file):\n        with open(summary_file, \"r\", encoding=\"utf-8\") as f:\n            return safe_truncate(f.read(), MAX_PROJECT_SUMMARY_CHARS)\n    return \"Project summary not available.\"\n\n# === Load Global Context ===\ndef load_global_context(path: str = \"./docs/generated/global_context.md\") -> str:\n    \"\"\"Loads and safely truncates global project context file.\"\"\"\n    if Path(path).exists():\n        with open(path, \"r\", encoding=\"utf-8\") as f:\n            return safe_truncate(f.read(), MAX_GLOBAL_CONTEXT_CHARS)\n    return \"Global project context not available.\"\n\n# === Load Markdown snippets from /context/<topic>.md files ===\ndef load_context(topics: List[str], base_dir: str = \"./context/\") -> str:\n    \"\"\"Loads and concatenates markdown for each requested topic.\"\"\"\n    chunks = []\n    for topic in topics:\n        path = Path(base_dir) / f\"{topic}.md\"\n        if path.exists():\n            with open(path, \"r\", encoding=\"utf-8\") as f:\n                content = f.read()\n                chunks.append(f\"\\n# {topic.title()}\\n{safe_truncate(content, MAX_EXTERNAL_CONTEXT_CHARS)}\")\n    return \"\\n\".join(chunks) if chunks else \"No external context available.\"\n\n# === Recent Memory Summaries (optional, using your summarizer) ===\nasync def build_recent_memory_summaries(entries: List[Dict[str, str]], max_entries: int = 5) -> str:\n    \"\"\"Summarizes recent user/agent memory entries.\"\"\"\n    if not entries: return \"No recent memory summaries.\"\n    summaries = []\n    for e in entries[-max_entries:]:\n        try:\n            summary = await summarize_memory_entry(e.get(\"question\", \"\"), e.get(\"response\", \"\"), e.get(\"context\", \"\"))\n            summaries.append(f\"- {summary}\")\n        except Exception as ex:\n            summaries.append(f\"- [Summary failed: {str(ex)}]\")\n    return \"\\n\".join(summaries)\n\n# === MAIN CONTEXT BUILDER ===\nasync def build_context(\n    query: str,\n    files: List[str] = [],\n    topics: List[str] = [],\n    debug: bool = False,\n    top_k_semantic: int = 6,\n    memory_entries: List[Dict[str, str]] = None,  # Optionally pass recent memory\n) -> Union[str, Dict[str, Any]]:\n    \"\"\"\n    Builds a multi-layered markdown context block for agent prompts:\n      - Project summary\n      - LlamaIndex-powered semantic retrieval (best chunks from code/docs)\n      - External project context (topics)\n      - Global context\n      - (Optionally) summarized graph memory\n      - (Optionally) recent memory summaries\n\n    Returns full context string, or dict with metadata if debug=True.\n    \"\"\"\n    files_used: List[Dict[str, Any]] = []\n\n    # === 1.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3961, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d7c1ed8d-42ac-466a-88b5-b53ffdf3a1ad": {"__data__": {"id_": "d7c1ed8d-42ac-466a-88b5-b53ffdf3a1ad", "embedding": null, "metadata": {"file_path": "/app/services/context_injector.py", "file_name": "context_injector.py", "file_type": "text/x-python", "file_size": 6823, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a117da46-3a36-43ae-ba92-2cd106769ebb", "node_type": "4", "metadata": {"file_path": "/app/services/context_injector.py", "file_name": "context_injector.py", "file_type": "text/x-python", "file_size": 6823, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "bfa461031936b927e82717df3f9bcf123de3f1eb51f3dd430d21bee6661bca30", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e255bed3-abfc-491a-8360-7f037dcd93b0", "node_type": "1", "metadata": {"file_path": "/app/services/context_injector.py", "file_name": "context_injector.py", "file_type": "text/x-python", "file_size": 6823, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "9ca9648feaccf5f4d2e13e772425321213c7337707ecbf7107f0cbcb8cb46f2a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "files_used: List[Dict[str, Any]] = []\n\n    # === 1. Project Summary ===\n    project_summary = load_summary()\n    if \"not available\" not in project_summary:\n        files_used.append({\"type\": \"summary\", \"source\": \"docs/PROJECT_SUMMARY.md\"})\n\n    # === 2. Semantic Retrieval (LlamaIndex) ===\n    semantic_context = get_semantic_context(query, top_k=top_k_semantic)\n    semantic_context = safe_truncate(semantic_context, MAX_SEMANTIC_CONTEXT_CHARS)\n    files_used.append({\"type\": \"semantic\", \"desc\": f\"LlamaIndex top-{top_k_semantic} semantic retrieval\"})\n\n    # === 3. External Topic Context ===\n    external_context = load_context(topics)\n    if external_context.strip() and external_context != \"No external context available.\":\n        for topic in topics:\n            files_used.append({\"type\": \"external\", \"source\": f\"context/{topic}.md\"})\n\n    # === 4. Global Project Context ===\n    global_context = load_global_context()\n    if \"not available\" not in global_context:\n        files_used.append({\"type\": \"global\", \"source\": \"docs/generated/global_context.md\"})\n\n    # === 5. Graph Memory Context (summarized) ===\n    try:\n        graph_context = await summarize_recent_context(query)\n        graph_context = safe_truncate(graph_context, MAX_GRAPH_MEMORY_CHARS)\n        if graph_context.strip() and \"No graph memory matches\" not in graph_context:\n            files_used.append({\"type\": \"graph\", \"source\": \"neo4j\"})\n    except Exception as ex:\n        graph_context = f\"[Graph memory error: {str(ex)}]\"\n\n    # === 6. Recent Memory Summaries (optional) ===\n    memory_summaries = \"\"\n    if memory_entries:\n        try:\n            memory_summaries = await build_recent_memory_summaries(memory_entries)\n        except Exception as ex:\n            memory_summaries = f\"[Memory summary error: {str(ex)}]\"\n\n    # === Assemble final context block ===\n    full_context = f\"\"\"\n## \ud83e\udde0 Project Summary:\n{project_summary}\n\n## \ud83e\udd99 Semantic Retrieval (Top Matches):\n{semantic_context}\n\n## \ud83c\udf0d External Project Context:\n{external_context}\n\n## \ud83c\udf10 Global Project Context:\n{global_context}\n\n## \ud83e\udde0 Graph Memory Summary:\n{graph_context}\n\n## \ud83d\udcdd Recent Memory Summaries:\n{memory_summaries}\n\"\"\".strip()\n\n    # === Logging for debugging ===\n    print(f\"[CTX] Length: {len(full_context)} chars | Files used: {files_used}\")\n    if len(full_context) > 12000:\n        print(\"[CTX] WARNING: Full context exceeds 12k chars, consider increasing truncation/aggressive filtering.\")\n\n    if debug:\n        return {\n            \"context\": full_context,\n            \"files_used\": files_used,\n            \"sections\": {\n                \"summary\": project_summary,\n                \"semantic\": semantic_context,\n                \"external\": external_context,\n                \"global\": global_context,\n                \"graph\": graph_context,\n                \"memory_summaries\": memory_summaries\n            }\n        }\n\n    return full_context", "mimetype": "text/plain", "start_char_idx": 3910, "end_char_idx": 6804, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c48f4f8a-f3fb-469b-8256-4c6c789f28ef": {"__data__": {"id_": "c48f4f8a-f3fb-469b-8256-4c6c789f28ef", "embedding": null, "metadata": {"file_path": "/app/services/delete_embeddings.py", "file_name": "delete_embeddings.py", "file_type": "text/x-python", "file_size": 2361, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4abdbf37-7742-4096-afdb-0dac6aef33d3", "node_type": "4", "metadata": {"file_path": "/app/services/delete_embeddings.py", "file_name": "delete_embeddings.py", "file_type": "text/x-python", "file_size": 2361, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "c6e2ca3dcc125e746f10639877d8596800c5547e5f08fb1c1dbeeb103fa4c4c9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# services/embeddings.py\n\n\"\"\"\nRelay Embeddings Service\n-----------------------------------\n- Indexes project docs and code with OpenAI embeddings.\n- Supports semantic search for agent context, docs, and Q&A.\n- Simple CLI: build index, search index.\n\"\"\"\n\nimport os\nimport openai\nimport numpy as np\nimport pickle\n\n# Config (tweak paths/extensions as needed for your codebase)\nSEARCH_DIRS = [\"./docs\", \"./core\", \"./agents\", \"./services\"]\nEXTS = [\".md\", \".py\", \".ts\", \".tsx\"]\nEMBED_MODEL = \"text-embedding-3-small\"\nEMBED_INDEX = \"file_embeddings.pkl\"\n\nopenai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n\ndef iter_files():\n    for root in SEARCH_DIRS:\n        for dirpath, _, filenames in os.walk(root):\n            for fname in filenames:\n                if any(fname.endswith(ext) for ext in EXTS):\n                    yield os.path.join(dirpath, fname)\n\ndef embed_text(text):\n    \"\"\"Get OpenAI embedding for input text.\"\"\"\n    resp = openai.embeddings.create(input=text, model=EMBED_MODEL)\n    return np.array(resp.data[0].embedding)\n\ndef build_index():\n    \"\"\"Build and save the file embedding index.\"\"\"\n    index = []\n    for fpath in iter_files():\n        with open(fpath, encoding=\"utf-8\", errors=\"ignore\") as f:\n            text = f.read()[:8000]  # Truncate for OpenAI limit\n        emb = embed_text(text)\n        index.append({\n            \"file\": fpath,\n            \"embedding\": emb,\n            \"snippet\": text[:400]  # Preview for UI/context\n        })\n        print(f\"Indexed: {fpath}\")\n    with open(EMBED_INDEX, \"wb\") as out:\n        pickle.dump(index, out)\n    print(f\"Embedding index saved to {EMBED_INDEX}\")\n\ndef search_index(query, top_k=5):\n    \"\"\"Return top_k most relevant files/snippets for a query.\"\"\"\n    with open(EMBED_INDEX, \"rb\") as f:\n        index = pickle.load(f)\n    q_emb = embed_text(query)\n    scores = []\n    for doc in index:\n        sim = np.dot(q_emb, doc[\"embedding\"])\n        scores.append((sim, doc))\n    scores.sort(reverse=True, key=lambda x: x[0])\n    return [doc for _, doc in scores[:top_k]]\n\nif __name__ == \"__main__\":\n    import sys\n    if len(sys.argv) > 1 and sys.argv[1] == \"search\":\n        query = \" \".join(sys.argv[2:]) or \"relay agent context\"\n        results = search_index(query)\n        for doc in results:\n            print(f\"{doc['file']}\\n---\\n{doc['snippet'][:200]}\\n\")\n    else:\n        build_index()", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2360, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "63157a55-9fe6-4b76-bfdb-dad8893079e3": {"__data__": {"id_": "63157a55-9fe6-4b76-bfdb-dad8893079e3", "embedding": null, "metadata": {"file_path": "/app/services/docs_utils.py", "file_name": "docs_utils.py", "file_type": "text/x-python", "file_size": 4321, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0ef2a7dd-3795-467d-b5d3-6d04b8b239c9", "node_type": "4", "metadata": {"file_path": "/app/services/docs_utils.py", "file_name": "docs_utils.py", "file_type": "text/x-python", "file_size": 4321, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "4d359ee4a585a99c433324790b3e71f9f266ab7ed371bb959a1c0d5094aa4d78", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# File: docs_utils.py\n# Directory: services/\n# Purpose : Support utilities for Relay doc tiering\n#           \u2022 Extract doc_id from file\n#           \u2022 Build registry of all docs grouped by ID\n#           \u2022 Determine which file version is canonical\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nimport re\nfrom collections import defaultdict\nfrom pathlib import Path\nfrom typing import Dict, List\n\n# \u2500\u2500\u2500 Constants \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nPROJECT_ROOT = Path(__file__).resolve().parents[1]\nBASE_DIR = PROJECT_ROOT / \"docs\"\nDOC_FOLDERS = [\"\", \"imported\", \"generated\"]  # relative to /docs/\n\n# \u2500\u2500\u2500 Extract doc_id from YAML frontmatter or filename \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ndef extract_doc_id(path: Path) -> str:\n    \"\"\"\n    Extract doc_id from a file's frontmatter or fallback to filename stem.\n    Assumes optional comment-style frontmatter: `doc_id: foo`\n    \"\"\"\n    try:\n        lines = path.read_text(encoding=\"utf-8\").splitlines()\n        for line in lines[:10]:\n            if \"doc_id:\" in line:\n                match = re.search(r\"doc_id:\\s*(\\S+)\", line)\n                if match:\n                    return match.group(1).strip()\n    except Exception:\n        pass\n\n    return path.stem  # fallback to filename without extension\n\n\n# \u2500\u2500\u2500 Build registry of doc_id \u2192 [all versions] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ndef build_doc_registry() -> Dict[str, List[Path]]:\n    \"\"\"\n    Scans /docs folders and groups files by doc_id.\n    Returns dict of doc_id -> list of Path objects.\n    \"\"\"\n    registry: Dict[str, List[Path]] = defaultdict(list)\n\n    for folder in DOC_FOLDERS:\n        base = BASE_DIR / folder if folder else BASE_DIR\n        if not base.exists():\n            continue\n        for f in base.rglob(\"*.md\"):\n            try:\n                doc_id = extract_doc_id(f)\n                registry[doc_id].append(f)\n            except Exception:\n                continue\n\n    return registry\n\n\n# \u2500\u2500\u2500 Choose best version of a doc \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ndef choose_canonical_path(paths: List[Path]) -> Path:\n    \"\"\"\n    Select the canonical version of a doc from multiple paths.\n    Prefers root-level /docs/ files, else chooses most recently modified.\n    \"\"\"\n    for p in paths:\n        if p.parent == BASE_DIR:  # root /docs/\n            return p\n    return max(paths, key=lambda p: p.stat().st_mtime)\n\ndef write_doc_metadata(path: Path, updates: dict):\n    \"\"\"\n    Updates or inserts a metadata block (as comment) at the top of the markdown file.\n\n    Example block:\n    <!--\n    doc_id: foo\n    tier: global\n    pinned: true\n    -->\n    \"\"\"\n    if not path.exists():\n        raise FileNotFoundError(f\"{path} does not exist\")\n\n    lines = path.read_text(encoding=\"utf-8\").splitlines()\n    start, end = None, None\n\n    # Detect existing block\n    for i, line in enumerate(lines[:20]):\n        if line.strip() == \"<!--\":\n            start = i\n        elif line.strip() == \"-->\":\n            end = i\n            break\n\n    # Build updated block\n    metadata = {**updates}\n    if \"doc_id\" not in metadata:\n        metadata[\"doc_id\"] = extract_doc_id(path)\n\n    block = [\"<!--\"]\n    for key, val in metadata.items():\n        if val is not None:\n            block.append(f\"{key}: {str(val).lower() if isinstance(val, bool) else val}\")\n    block.append(\"-->\")\n\n    # Inject or replace block\n    if start is not None and end is not None:\n        new_lines = lines[:start] + block + lines[end + 1:]\n    else:\n        new_lines = block + [\"\"] + lines\n\n    path.write_text(\"\\n\".join(new_lines), encoding=\"utf-8\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3676, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e89b2379-ba7b-41f8-9105-6b7b0c46745b": {"__data__": {"id_": "e89b2379-ba7b-41f8-9105-6b7b0c46745b", "embedding": null, "metadata": {"file_path": "/app/services/env_checker.py", "file_name": "env_checker.py", "file_type": "text/x-python", "file_size": 1231, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a08d3dd5-68ad-4891-b394-d319d909c70c", "node_type": "4", "metadata": {"file_path": "/app/services/env_checker.py", "file_name": "env_checker.py", "file_type": "text/x-python", "file_size": 1231, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "be0c528a2cda24b9f66419f88715065eb8316f9913f78f264540632cbe878553", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# services/env_checker.py\nimport os\nimport re\nfrom pathlib import Path\nfrom dotenv import dotenv_values\n\nSERVICES_DIR = Path(__file__).resolve().parents[1] / \"services\"\nENV_FILE = Path(__file__).resolve().parents[1] / \".env\"\n\nGETENV_REGEX = re.compile(r\"os\\.getenv\\([\"'](.+?)[\"']\")\n\ndef find_env_keys_in_code(path: Path):\n    found = {}\n    for file in path.rglob(\"*.py\"):\n        matches = GETENV_REGEX.findall(file.read_text(encoding=\"utf-8\"))\n        if matches:\n            found[file.name] = list(set(matches))\n    return found\n\ndef check_env_keys():\n    code_env_usage = find_env_keys_in_code(SERVICES_DIR)\n    used_keys = sorted({k for keys in code_env_usage.values() for k in keys})\n    \n    # Load .env if available\n    env_file_values = dotenv_values(dotenv_path=ENV_FILE)\n    env_file_keys = set(env_file_values.keys())\n    runtime_env_keys = set(os.environ.keys())\n\n    # Compare\n    missing_keys = [k for k in used_keys if k not in env_file_keys and k not in runtime_env_keys]\n    unused_env_keys = sorted(env_file_keys - set(used_keys))\n\n    return {\n        \"used_keys\": used_keys,\n        \"missing_in_env\": missing_keys,\n        \"defined_but_unused\": unused_env_keys,\n        \"used_in_files\": code_env_usage,\n    }", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1230, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6a788492-a0a2-4470-8ef2-44554310a889": {"__data__": {"id_": "6a788492-a0a2-4470-8ef2-44554310a889", "embedding": null, "metadata": {"file_path": "/app/services/gmail.py", "file_name": "gmail.py", "file_type": "text/x-python", "file_size": 2867, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "56e75de5-4d2b-4e1b-a4ab-978a1ae93d10", "node_type": "4", "metadata": {"file_path": "/app/services/gmail.py", "file_name": "gmail.py", "file_type": "text/x-python", "file_size": 2867, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "64ac62d0d8708ad8a6dee605a09c73c5684ea81dcd1ee74d52791ac45aa7561c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: services/gmail.py\n# Directory: services/\n# Purpose: Gmail read/write utility using Google OAuth creds (Relay control/email ops)\n\nimport os\nfrom googleapiclient.discovery import build\nfrom email.mime.text import MIMEText\nimport base64\nfrom pathlib import Path\nfrom google.oauth2.service_account import Credentials\n\nGMAIL_SCOPES = ['https://www.googleapis.com/auth/gmail.send', 'https://www.googleapis.com/auth/gmail.readonly']\nGOOGLE_CREDS_JSON = os.getenv(\"GOOGLE_CREDS_JSON\")  # Path to service account JSON\n\ndef get_gmail_service():\n    \"\"\"Build a Gmail API client using service account credentials.\"\"\"\n    creds = Credentials.from_service_account_file(\n        GOOGLE_CREDS_JSON,\n        scopes=GMAIL_SCOPES,\n    )\n    delegated_email = os.getenv(\"NOTIFY_FROM_EMAIL\")\n    if delegated_email:\n        creds = creds.with_subject(delegated_email)\n    return build('gmail', 'v1', credentials=creds)\n\ndef send_email(to_email, subject, body):\n    \"\"\"Send an email via Gmail API.\"\"\"\n    service = get_gmail_service()\n    message = MIMEText(body)\n    message['to'] = to_email\n    message['from'] = os.getenv(\"NOTIFY_FROM_EMAIL\")\n    message['subject'] = subject\n    raw = base64.urlsafe_b64encode(message.as_bytes()).decode()\n    return service.users().messages().send(userId=\"me\", body={'raw': raw}).execute()\n\ndef list_emails(query=\"\", max_results=10):\n    \"\"\"List email messages in the inbox (by search query).\"\"\"\n    service = get_gmail_service()\n    results = service.users().messages().list(userId='me', q=query, maxResults=max_results).execute()\n    messages = results.get('messages', [])\n    emails = []\n    for m in messages:\n        msg = service.users().messages().get(userId='me', id=m['id'], format='metadata').execute()\n        headers = {h['name']: h['value'] for h in msg['payload']['headers']}\n        snippet = msg.get('snippet', '')\n        emails.append({\n            \"id\": m['id'],\n            \"snippet\": snippet,\n            \"from\": headers.get(\"From\"),\n            \"subject\": headers.get(\"Subject\"),\n            \"date\": headers.get(\"Date\"),\n        })\n    return emails\n\ndef get_email(email_id):\n    \"\"\"Fetch full content of a given email by ID.\"\"\"\n    service = get_gmail_service()\n    msg = service.users().messages().get(userId='me', id=email_id, format='full').execute()\n    headers = {h['name']: h['value'] for h in msg['payload']['headers']}\n    body = \"\"\n    if 'parts' in msg['payload']:\n        for part in msg['payload']['parts']:\n            if part['mimeType'] == 'text/plain':\n                body = base64.urlsafe_b64decode(part['body']['data']).decode()\n    else:\n        body = base64.urlsafe_b64decode(msg['payload']['body']['data']).decode()\n    return {\n        \"id\": email_id,\n        \"from\": headers.get(\"From\"),\n        \"subject\": headers.get(\"Subject\"),\n        \"date\": headers.get(\"Date\"),\n        \"body\": body\n    }", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2866, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3b2a14f9-d284-42da-ab8d-a7acc0f767dc": {"__data__": {"id_": "3b2a14f9-d284-42da-ab8d-a7acc0f767dc", "embedding": null, "metadata": {"file_path": "/app/services/google.py", "file_name": "google.py", "file_type": "text/x-python", "file_size": 1139, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2e8a5bb5-6e7a-45e5-9e14-0972f9d30772", "node_type": "4", "metadata": {"file_path": "/app/services/google.py", "file_name": "google.py", "file_type": "text/x-python", "file_size": 1139, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "e2e8ca2000e32730b38b557f68af4bba115f81a150f446f3cb76e95e082a5f5d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: services/google.py\n\"\"\"Utility helpers for fetching Google Docs content.\"\"\"\n\nfrom typing import List, Tuple\nfrom markdownify import markdownify as md\n\nfrom .google_docs_sync import (\n    get_google_service,\n    find_folder_id,\n    get_docs_in_folder,\n    COMMAND_CENTER_FOLDER_NAME,\n)\n\n\ndef fetch_drive_docs() -> List[Tuple[str, str]]:\n    \"\"\"Return (title, markdown) for docs in the COMMAND_CENTER folder.\"\"\"\n    drive_service, docs_service = get_google_service()\n    folder_id = find_folder_id(\n        drive_service, COMMAND_CENTER_FOLDER_NAME\n    )\n    files = get_docs_in_folder(drive_service, folder_id)\n\n    docs = []\n    for file in files:\n        doc = docs_service.documents().get(documentId=file[\"id\"]).execute()\n        elements = doc.get(\"body\", {}).get(\"content\", [])\n        html = \"\"\n        for element in elements:\n            if \"paragraph\" in element:\n                for part in element[\"paragraph\"].get(\"elements\", []):\n                    html += part.get(\"textRun\", {}).get(\"content\", \"\")\n                html += \"\\n\"\n        markdown = md(html)\n        docs.append((file[\"name\"], markdown))\n    return docs", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1138, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f7764192-f68e-4f6b-9f32-1be6e7fc23b1": {"__data__": {"id_": "f7764192-f68e-4f6b-9f32-1be6e7fc23b1", "embedding": null, "metadata": {"file_path": "/app/services/google_docs_sync.py", "file_name": "google_docs_sync.py", "file_type": "text/x-python", "file_size": 6032, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "959b81b8-ef4f-4389-89e3-027ea2780c94", "node_type": "4", "metadata": {"file_path": "/app/services/google_docs_sync.py", "file_name": "google_docs_sync.py", "file_type": "text/x-python", "file_size": 6032, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "264084325c703aa0e68d72775ca3771cc1a3f1ede2d9fbafdf720d099574860e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fc8b4473-afdc-4c68-b503-e5d5fd355710", "node_type": "1", "metadata": {}, "hash": "f1bf46cf8f7cf5da4901d553e89532e645c9f0379a159d677420a5d6c7187a1b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: services/google_docs_sync.py\n# Directory: /services\n# Purpose: Synchronize Google Docs from the COMMAND_CENTER Drive folder into local Markdown files\n# Usage:\n#   1. Set env var GOOGLE_CREDS_JSON to a base64-encoded Google client secret JSON\n#   2. (Optional) Set env var GOOGLE_TOKEN_JSON to a base64-encoded OAuth token JSON for bootstrapping\n#   3. For local development, set ENV=local to allow interactive OAuth login\n#   4. Call sync_google_docs() to fetch and convert all docs into docs/imported/\n\nimport os\nimport base64\nfrom pathlib import Path\n\nfrom google.oauth2.credentials import Credentials\nfrom google_auth_oauthlib.flow import InstalledAppFlow\nfrom google.auth.transport.requests import Request\nfrom googleapiclient.discovery import build\nfrom markdownify import markdownify as md\n\n# === Configuration Constants ===\nSCOPES = [\n    \"https://www.googleapis.com/auth/drive.readonly\",\n    \"https://www.googleapis.com/auth/documents.readonly\",\n]\nCREDENTIALS_PATH = Path(\"/tmp/credentials.json\")\nTOKEN_PATH = Path(\"frontend/sync/token.json\")\nIMPORT_PATH = Path(\"docs/imported\")\nIMPORT_PATH.mkdir(parents=True, exist_ok=True)\nCOMMAND_CENTER_FOLDER_NAME = \"COMMAND_CENTER\"\n\n# === Authentication and Service Setup ===\ndef get_google_service():\n    \"\"\"\n    Ensure we have valid Google API credentials, then build Drive and Docs services.\n    - Writes out credentials.json from GOOGLE_CREDS_JSON if missing\n    - Bootstraps token.json from GOOGLE_TOKEN_JSON env var or runs interactive OAuth\n    \"\"\"\n    creds = None\n\n    # Write out credentials.json if not already present\n    if not CREDENTIALS_PATH.exists():\n        raw = os.getenv(\"GOOGLE_CREDS_JSON\")\n        if not raw:\n            raise FileNotFoundError(\"Missing GOOGLE_CREDS_JSON environment variable.\")\n        decoded = base64.b64decode(raw.encode()).decode()\n        CREDENTIALS_PATH.write_text(decoded)\n        print(f\"\u2705 Wrote client secrets to {CREDENTIALS_PATH}\")\n\n    # Bootstrap token.json from env, if provided\n    if not TOKEN_PATH.exists() and os.getenv(\"GOOGLE_TOKEN_JSON\"):\n        token_raw = os.getenv(\"GOOGLE_TOKEN_JSON\")\n        try:\n            TOKEN_PATH.write_text(base64.b64decode(token_raw).decode())\n            print(f\"\u2705 Bootstrapped token.json to {TOKEN_PATH}\")\n        except Exception as e:\n            print(f\"\u274c Failed to decode GOOGLE_TOKEN_JSON: {e}\")\n\n    # Load existing credentials\n    if TOKEN_PATH.exists():\n        creds = Credentials.from_authorized_user_file(str(TOKEN_PATH), SCOPES)\n\n    # Refresh or start OAuth flow\n    if not creds or not creds.valid:\n        if creds and creds.expired and creds.refresh_token:\n            creds.refresh(Request())\n        else:\n            # Interactive login only allowed in local dev\n            if os.getenv(\"ENV\") == \"local\":\n                flow = InstalledAppFlow.from_client_secrets_file(str(CREDENTIALS_PATH), SCOPES)\n                creds = flow.run_local_server(port=0)\n                TOKEN_PATH.parent.mkdir(parents=True, exist_ok=True)\n                TOKEN_PATH.write_text(creds.to_json())\n                print(f\"\u2705 Saved new token.json to {TOKEN_PATH}\")\n            else:\n                raise RuntimeError(\n                    \"Missing valid credentials and interactive login is disabled in production.\"\n                )\n\n    # Build and return API clients\n    drive_service = build(\"drive\", \"v3\", credentials=creds)\n    docs_service = build(\"docs\", \"v1\", credentials=creds)\n    return drive_service, docs_service\n\n# === Google Docs Fetching Utilities ===\ndef find_folder_id(drive_service, folder_name: str) -> str:\n    \"\"\"\n    Find the Drive folder ID by name.\n    Returns folder ID or raises if not found.\n    \"\"\"\n    query = f\"mimeType='application/vnd.google-apps.folder' and name='{folder_name}'\"\n    result = (\n        drive_service.files()\n        .list(q=query, spaces=\"drive\", fields=\"files(id, name)\")\n        .execute()\n    )\n    files = result.get(\"files\", [])\n    if not files:\n        raise RuntimeError(f\"Folder '{folder_name}' not found in Drive.\")\n    return files[0][\"id\"]", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4056, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fc8b4473-afdc-4c68-b503-e5d5fd355710": {"__data__": {"id_": "fc8b4473-afdc-4c68-b503-e5d5fd355710", "embedding": null, "metadata": {"file_path": "/app/services/google_docs_sync.py", "file_name": "google_docs_sync.py", "file_type": "text/x-python", "file_size": 6032, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "959b81b8-ef4f-4389-89e3-027ea2780c94", "node_type": "4", "metadata": {"file_path": "/app/services/google_docs_sync.py", "file_name": "google_docs_sync.py", "file_type": "text/x-python", "file_size": 6032, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "264084325c703aa0e68d72775ca3771cc1a3f1ede2d9fbafdf720d099574860e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f7764192-f68e-4f6b-9f32-1be6e7fc23b1", "node_type": "1", "metadata": {"file_path": "/app/services/google_docs_sync.py", "file_name": "google_docs_sync.py", "file_type": "text/x-python", "file_size": 6032, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "c74e86022393aa31593b37aed565920585397625acc9756bb6d23bf2bffce8e9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "def get_docs_in_folder(drive_service, folder_id: str) -> list:\n    \"\"\"\n    List all Google Docs files within the given folder ID.\n    \"\"\"\n    query = f\"'{folder_id}' in parents and mimeType='application/vnd.google-apps.document'\"\n    result = (\n        drive_service.files()\n        .list(q=query, fields=\"files(id, name)\")\n        .execute()\n    )\n    return result.get(\"files\", [])\n\n\ndef fetch_and_save_doc(docs_service, file: dict) -> str:\n    \"\"\"\n    Fetch a Google Doc by ID, convert its content to Markdown, and save locally.\n    Returns the filename of the saved Markdown file.\n    \"\"\"\n    doc = docs_service.documents().get(documentId=file[\"id\"]).execute()\n    # Build plain-text HTML-like content\n    elements = doc.get(\"body\", {}).get(\"content\", [])\n    html = \"\"\n    for element in elements:\n        if \"paragraph\" in element:\n            for part in element[\"paragraph\"].get(\"elements\", []):\n                html += part.get(\"textRun\", {}).get(\"content\", \"\")\n            html += \"\\n\"\n    # Convert to Markdown\n    markdown = md(html)\n    # Prepare output filename\n    title_slug = file[\"name\"].replace(\" \", \"_\").lower()\n    out_path = IMPORT_PATH / f\"{title_slug}.md\"\n    out_path.write_text(markdown, encoding=\"utf-8\")\n    return out_path.name\n\n# === Main Entry Point ===\ndef sync_google_docs() -> list:\n    \"\"\"\n    Main sync function.\n    - Authenticates\n    - Finds the COMMAND_CENTER folder\n    - Fetches and saves each doc to docs/imported/\n    Returns a list of saved filenames.\n    \"\"\"\n    drive_service, docs_service = get_google_service()\n    folder_id = find_folder_id(drive_service, COMMAND_CENTER_FOLDER_NAME)\n    files = get_docs_in_folder(drive_service, folder_id)\n    saved_files = [fetch_and_save_doc(docs_service, f) for f in files]\n    print(f\"\u2705 Synced {len(saved_files)} files:\", saved_files)\n    return saved_files\n\n# If run as a script, perform sync immediately\nenabled = __name__ == \"__main__\"\nif enabled:\n    sync_google_docs()", "mimetype": "text/plain", "start_char_idx": 4059, "end_char_idx": 6021, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "377808f0-1771-452a-a38a-24ec23b99988": {"__data__": {"id_": "377808f0-1771-452a-a38a-24ec23b99988", "embedding": null, "metadata": {"file_path": "/app/services/graph.py", "file_name": "graph.py", "file_type": "text/x-python", "file_size": 3089, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c5b1e32c-db86-4e4b-9bee-8e859bb390ae", "node_type": "4", "metadata": {"file_path": "/app/services/graph.py", "file_name": "graph.py", "file_type": "text/x-python", "file_size": 3089, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "acb57875a4c622d36de68ba6aa4bf765ec95de710df0fa39a6630db9ca8fd3d6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: services/graph.py\n# Purpose: Graph query helpers for MetaPlanner (e.g. similar query lookup)\n\nfrom services.neo4j_driver import neo4j_driver  # assumes driver is initialized separately\nfrom core.logging import log_event\n\n# === Fulltext similarity query using Neo4j index ===\nasync def query_similar_routes(query: str, top_k: int = 5) -> list[dict]:\n    \"\"\"\n    Returns top K similar past queries and their associated routes and critic scores.\n    Requires a fulltext index on :Query(text) and proper ROUTED_TO links.\n    \"\"\"\n    try:\n        cypher = \"\"\"\n        CALL db.index.fulltext.queryNodes('queryTextIndex', $q) YIELD node, score\n        MATCH (node)-[:PLANNED_WITH]->(plan:Plan)-[:RAN_ON]->(agent:Agent)\n        OPTIONAL MATCH (plan)-[:VALIDATED_BY]->(c:Critic)\n        WITH plan, agent, score, COUNT(c) AS total, SUM(CASE WHEN c.passes THEN 1 ELSE 0 END) AS passed\n        RETURN agent.name AS route,\n               score,\n               passed * 1.0 / CASE WHEN total = 0 THEN 1 ELSE total END AS confidence\n        ORDER BY confidence DESC, score DESC\n        LIMIT $top_k\n        \"\"\"\n\n        records = await neo4j_driver.execute_read(\n            cypher,\n            parameters={\"q\": query, \"top_k\": top_k}\n        )\n\n        return [\n            {\n                \"route\": record[\"route\"],\n                \"confidence\": float(record[\"confidence\"]),\n                \"score\": float(record[\"score\"])\n            }\n            for record in records\n            if record[\"route\"]\n        ]\n\n    except Exception as e:\n        log_event(\"graph_query_fail\", {\"error\": str(e)})\n        return []\n# === Generate text summary of relevant prior routes ===\nasync def summarize_recent_context(query: str, top_k: int = 5) -> str:\n    \"\"\"\n    Returns a markdown-style summary of recent graph memory relevant to the query.\n    Used for injecting graph-derived intelligence into planner context.\n    \"\"\"\n    try:\n        cypher = \"\"\"\n        CALL db.index.fulltext.queryNodes('queryTextIndex', $q) YIELD node, score\n        MATCH (node)-[:PLANNED_WITH]->(plan:Plan)-[:RAN_ON]->(agent:Agent)\n        OPTIONAL MATCH (plan)-[:VALIDATED_BY]->(c:Critic)\n        WITH plan, agent, score,\n             COUNT(c) AS total,\n             SUM(CASE WHEN c.passes THEN 1 ELSE 0 END) AS passed\n        RETURN plan.route AS route,\n               agent.name AS agent,\n               passed * 1.0 / CASE WHEN total = 0 THEN 1 ELSE total END AS confidence,\n               score\n        ORDER BY confidence DESC, score DESC\n        LIMIT $top_k\n        \"\"\"\n\n        records = await neo4j_driver.execute_read(cypher, {\"q\": query, \"top_k\": top_k})\n        if not records:\n            return \"\"\n\n        summary = [\"### \ud83d\udd0e Graph Memory Summary\"]\n        for r in records:\n            summary.append(\n                f\"- `{r['route']}` via `{r['agent']}` \u2192 \"\n                f\"Confidence: {r['confidence']:.0%} \u00b7 Relevance Score: {r['score']:.2f}\"\n            )\n\n        return \"\\n\".join(summary)\n\n    except Exception as e:\n        log_event(\"graph_summary_fail\", {\"error\": str(e)})\n        return \"\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3082, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "332d7869-5785-40ec-ad68-1d40d369be26": {"__data__": {"id_": "332d7869-5785-40ec-ad68-1d40d369be26", "embedding": null, "metadata": {"file_path": "/app/services/indexer.py", "file_name": "indexer.py", "file_type": "text/x-python", "file_size": 6973, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9f263501-0017-4b4f-8785-7a61dddd3e72", "node_type": "4", "metadata": {"file_path": "/app/services/indexer.py", "file_name": "indexer.py", "file_type": "text/x-python", "file_size": 6973, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "16313de8335ea3bcc0af458a33f1b4567de6b812b4d199f06a039513a3861a32", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5fe08f27-8fcc-4d85-ba32-a009510eb810", "node_type": "1", "metadata": {}, "hash": "cdd51b24f8be6325e54597d0dfe60fc2de31e8ec71bd9f9a7167a5e34eb45844", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: services/indexer.py\n# Purpose: Recursively index code and docs with tier metadata for prioritized semantic search.\n# Stack: LlamaIndex, OpenAI, Python 3.12+\n# Usage:\n#   - For dev, run: WIPE_INDEX=true python services/indexer.py\n#   - For prod, run WITHOUT WIPE_INDEX, and only if you intend to update the index.\n\nimport os\nimport glob\nimport sys\nfrom pathlib import Path\nfrom llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Document\nfrom llama_index.embeddings.openai import OpenAIEmbedding\nfrom llama_index.core.node_parser import CodeSplitter, SentenceSplitter\nfrom services.config import INDEX_DIR\n\nimport shutil\n\n# --- Guard: WIPE_INDEX only deletes if explicitly set ---\nWIPE_INDEX = os.getenv(\"WIPE_INDEX\", \"false\").lower() == \"true\"\nif WIPE_INDEX:\n    if os.path.exists(INDEX_DIR):\n        print(\"WARNING: WIPE_INDEX is set\u2014deleting and recreating index directory.\")\n        shutil.rmtree(INDEX_DIR)\n    os.makedirs(INDEX_DIR, exist_ok=True)\nelse:\n    print(\"WIPE_INDEX not set\u2014existing index will be updated or extended if run.\")\n\n# ---- 1. Define priority tiers and associated paths ----\nPRIORITY_INDEX_PATHS = [\n    (\"global\", [\"./docs/generated/global_context.md\", \"./docs/generated/global_context.auto.md\"]),\n    (\"context\", [\"./context/\"]),  # Cross-project overlays\n    (\"project_summary\", [\"./docs/PROJECT_SUMMARY.md\", \"./docs/RELAY_CODE_UPDATE.md\", \"./docs/context-commandcenter.md\"]),\n    (\"project_docs\", [\"./docs/imported/\", \"./docs/kb/\", \"./docs/*.md\"]),\n    (\"code\", [\"./services/\", \"./routes/\", \"./frontend/\", \"./src/\", \"./backend/\"]),\n]\n\n# ---- 2. Exclude Rules for Files, Extensions, and Folders ----\nIGNORED_FILENAMES = {\n    \"package-lock.json\", \"yarn.lock\", \".env\", \".DS_Store\", \".gitignore\",\n}\nIGNORED_EXTENSIONS = {\n    \".lock\", \".log\", \".exe\", \".bin\", \".jpg\", \".jpeg\", \".png\", \".gif\", \".pdf\", \".ico\",\n}\nIGNORED_FOLDERS = {\n    \"node_modules\", \".git\", \"__pycache__\", \"dist\", \"build\", \".venv\", \"env\",\n}\nMAX_FILE_SIZE_MB = 2  # Optional: skip files over 2 MB (adjust as needed)\n\ndef should_index_file(filepath: str, tier: str) -> bool:\n    \"\"\"Returns True if a file should be indexed, otherwise False.\"\"\"\n    filename = os.path.basename(filepath)\n    ext = os.path.splitext(filename)[1].lower()\n    if filename in IGNORED_FILENAMES or ext in IGNORED_EXTENSIONS:\n        return False\n    # Ignore by folder in path\n    parts = filepath.replace(\"\\\\\", \"/\").split(\"/\")\n    if any(folder in parts for folder in IGNORED_FOLDERS):\n        return False\n    # Ignore big files\n    if os.path.isfile(filepath):\n        if os.path.getsize(filepath) > MAX_FILE_SIZE_MB * 1024 * 1024:\n            return False\n    # For code tier, allow a broad set of code/doc files for review\n    if tier == \"code\":\n        return ext in {\".py\", \".js\", \".ts\", \".tsx\", \".java\", \".go\", \".cpp\", \".json\", \".md\"}\n    return True\n\n# ---- 3. Embedding Model ----\nmodel_name = (\n    os.getenv(\"KB_EMBED_MODEL\")\n    or os.getenv(\"OPENAI_EMBED_MODEL\")\n    or \"text-embedding-3-large\"\n)\nembed_model = OpenAIEmbedding(\n    model=model_name,\n    dimensions=3072 if model_name == \"text-embedding-3-large\" else None\n)\n\n# ---- 4. Language detection for code files ----\ndef get_language_from_path(file_path: str) -> str:\n    \"\"\"Returns the code language for a given file path by extension.\"\"\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3300, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5fe08f27-8fcc-4d85-ba32-a009510eb810": {"__data__": {"id_": "5fe08f27-8fcc-4d85-ba32-a009510eb810", "embedding": null, "metadata": {"file_path": "/app/services/indexer.py", "file_name": "indexer.py", "file_type": "text/x-python", "file_size": 6973, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9f263501-0017-4b4f-8785-7a61dddd3e72", "node_type": "4", "metadata": {"file_path": "/app/services/indexer.py", "file_name": "indexer.py", "file_type": "text/x-python", "file_size": 6973, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "16313de8335ea3bcc0af458a33f1b4567de6b812b4d199f06a039513a3861a32", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "332d7869-5785-40ec-ad68-1d40d369be26", "node_type": "1", "metadata": {"file_path": "/app/services/indexer.py", "file_name": "indexer.py", "file_type": "text/x-python", "file_size": 6973, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "004980a49b6b2e01c7fe1b9f6bedecac26f5711193e73f394a53b1f45fd7447a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Embedding Model ----\nmodel_name = (\n    os.getenv(\"KB_EMBED_MODEL\")\n    or os.getenv(\"OPENAI_EMBED_MODEL\")\n    or \"text-embedding-3-large\"\n)\nembed_model = OpenAIEmbedding(\n    model=model_name,\n    dimensions=3072 if model_name == \"text-embedding-3-large\" else None\n)\n\n# ---- 4. Language detection for code files ----\ndef get_language_from_path(file_path: str) -> str:\n    \"\"\"Returns the code language for a given file path by extension.\"\"\"\n    file_path = file_path.lower()\n    if file_path.endswith(\".py\"):\n        return \"python\"\n    elif file_path.endswith((\".js\", \".jsx\")):\n        return \"javascript\"\n    elif file_path.endswith((\".ts\", \".tsx\")):\n        return \"typescript\"\n    elif file_path.endswith(\".java\"):\n        return \"java\"\n    elif file_path.endswith(\".go\"):\n        return \"go\"\n    elif file_path.endswith(\".cpp\"):\n        return \"cpp\"\n    return \"python\"  # fallback\n\ndef collect_code_context(files: list[str], base_dir: str = \"./\") -> str:\n    \"\"\"Read and join contents of files for prompt context.\"\"\"\n    contents: list[str] = []\n    for f in files:\n        path = Path(base_dir) / f\n        if path.exists() and path.is_file():\n            try:\n                contents.append(f\"### {f}\\n\" + path.read_text())\n            except Exception:\n                continue\n    return \"\\n\\n\".join(contents)\n\ndef index_directories():\n    \"\"\"Scans all PRIORITY_INDEX_PATHS, splits, tags with tier, and embeds for semantic search.\"\"\"\n    documents = []\n    print(f\"[Indexer] Starting directory scan for priority tiers...\")\n    for tier, paths in PRIORITY_INDEX_PATHS:\n        for path in paths:\n            if path.endswith(\"/\"):\n                if os.path.exists(path):\n                    docs = SimpleDirectoryReader(path, recursive=True).load_data()\n                    filtered_docs = []\n                    for d in docs:\n                        file_path = d.metadata.get(\"file_path\") or d.metadata.get(\"filename\") or \"\"\n                        if should_index_file(file_path, tier):\n                            d.metadata = d.metadata or {}\n                            d.metadata[\"tier\"] = tier\n                            filtered_docs.append(d)\n                    documents.extend(filtered_docs)\n            elif \"*\" in path or path.endswith(\".md\"):\n                for f in glob.glob(path):\n                    if os.path.isfile(f) and should_index_file(f, tier):\n                        with open(f, \"r\", encoding=\"utf-8\") as file:\n                            text = file.read()\n                        doc = Document(\n                            text=text,\n                            metadata={\"tier\": tier, \"file_path\": f}\n                        )\n                        documents.append(doc)\n    print(f\"[Indexer] Total documents collected: {len(documents)}\")\n\n    # --- 5. Chunking: Get nodes (split text/code), flatten for indexing ---\n    all_chunked_nodes = []\n    text_splitter = SentenceSplitter(chunk_size=1024)\n    for doc in documents:\n        file_path = doc.metadata.get('file_path', '')\n        if file_path.endswith(('.py', '.js', '.ts', '.tsx', '.java', '.go', '.cpp')):\n            language = get_language_from_path(file_path)\n            code_splitter = CodeSplitter(language=language, max_chars=1024, chunk_lines=30)\n            nodes = code_splitter.get_nodes_from_documents([doc])\n            all_chunked_nodes.extend(nodes)\n        else:\n            nodes = text_splitter.get_nodes_from_documents([doc])\n            all_chunked_nodes.extend(nodes)\n    print(f\"[Indexer] Total nodes to index: {len(all_chunked_nodes)}\")\n\n    if not all_chunked_nodes:\n        print(\"[ERROR] No nodes to index! Aborting persist step.\")\n        sys.exit(1)\n\n    # --- 6. Index & Persist ---\n    index = VectorStoreIndex(\n        nodes=all_chunked_nodes,\n        embed_model=embed_model,\n        show_progress=True\n    )\n    index.storage_context.persist(persist_dir=\"./data/index\")\n    index.storage_context.persist(persist_dir=str(INDEX_DIR))\n    print(\"[Indexer] Indexing complete! Prioritized tiers saved to ./data/index.\")\n\nif __name__ == \"__main__\":\n    index_directories()", "mimetype": "text/plain", "start_char_idx": 2860, "end_char_idx": 6968, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9dc94475-a6bd-427d-98ae-6f8b8e488e01": {"__data__": {"id_": "9dc94475-a6bd-427d-98ae-6f8b8e488e01", "embedding": null, "metadata": {"file_path": "/app/services/kb.py", "file_name": "kb.py", "file_type": "text/x-python", "file_size": 14796, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d7bf643d-235d-4a2f-a75b-e873a491dbf7", "node_type": "4", "metadata": {"file_path": "/app/services/kb.py", "file_name": "kb.py", "file_type": "text/x-python", "file_size": 14796, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "9cfff192ee02e21f4238d14322a3d8a4c55a94b08989b1d1698d7b6fec5622e2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "131049c8-831a-4900-a463-2b9ea6c7cce4", "node_type": "1", "metadata": {}, "hash": "5b55ab877e244d33065640387c87e5c3ae1ffe6159eaabbcb1d048b14ee8d6a6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# File: services/kb.py\n# Purpose: Full-featured semantic KB for LlamaIndex (robust chunking, tiering, filtering, search)\n#           - Aggressive junk filtering & deduplication\n#           - Tier-aware, content-boosted ranking\n#           - Context-rich node metadata for intelligent agent answers\n#           - CLI & debug\n# Updated: 2025-06-30 (Debug hardening for startup hangs)\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nimport os\nimport json\nimport shutil\nimport logging\nfrom pathlib import Path\nfrom typing import List, Optional, Dict, Any\n\nfrom services.config import INDEX_DIR, INDEX_ROOT\n\nfrom llama_index.core import (\n    SimpleDirectoryReader,\n    StorageContext,\n    VectorStoreIndex,\n    load_index_from_storage,\n)\nfrom llama_index.core.extractors import TitleExtractor\nfrom llama_index.core.ingestion import IngestionPipeline\nfrom llama_index.core.node_parser import SentenceSplitter\nfrom llama_index.embeddings.openai import OpenAIEmbedding\n\n# \u2500\u2500\u2500 Logging \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s %(levelname)-7s %(name)s  %(message)s\",\n    datefmt=\"%Y-%m-%d %H:%M:%S\",\n)\nlogger = logging.getLogger(__name__)\nlogger.info(\"\ud83d\udd25 Robust KB loaded (Echo edition)\")\n\n# \u2500\u2500\u2500 Model configuration \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nMODEL_NAME = (\n    os.getenv(\"KB_EMBED_MODEL\")\n    or os.getenv(\"OPENAI_EMBED_MODEL\")\n    or \"text-embedding-3-large\"\n)\nif MODEL_NAME == \"text-embedding-3-large\":\n    EMBED_MODEL = OpenAIEmbedding(model=MODEL_NAME, dimensions=3072)\nelse:\n    EMBED_MODEL = OpenAIEmbedding(model=MODEL_NAME)\n\n# \u2500\u2500\u2500 Aggressive filtering \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nIGNORED_FILENAMES = {\n    \"package-lock.json\", \"yarn.lock\", \"pnpm-lock.yaml\", \".env\", \".DS_Store\", \".gitignore\",\n    \"poetry.lock\", \"Pipfile.lock\", \"requirements.txt\", \".dockerignore\",\n    \"Dockerfile\", \"Makefile\", \"tsconfig.json\", \"jsconfig.json\", \"node_modules\",\n    \"README.md\", \"LICENSE\", \"Thumbs.db\", \"desktop.ini\", \"mypy.ini\", \"pyrightconfig.json\",\n}\nIGNORED_EXTENSIONS = {\n    \".lock\", \".log\", \".exe\", \".bin\", \".jpg\", \".jpeg\", \".png\", \".gif\", \".pdf\", \".ico\",\n    \".tgz\", \".zip\", \".tar\", \".gz\", \".mp4\", \".mov\", \".wav\", \".pyc\", \".so\", \".dll\",\n}\nIGNORED_FOLDERS = {\n    \"node_modules\", \".git\", \"__pycache__\", \"dist\", \"build\", \".venv\", \"env\", \".mypy_cache\", \".pytest_cache\",\n}\nMAX_FILE_SIZE_MB = 2\n\ndef should_index_file(filepath: str, tier: str) -> bool:\n    filename = os.path.basename(filepath)\n    ext = os.path.splitext(filename)[1].lower()\n    if filename in IGNORED_FILENAMES or ext in IGNORED_EXTENSIONS:\n        return False\n    parts = filepath.replace(\"\\\\\", \"/\").split(\"/\")\n    if any(folder in parts for folder in IGNORED_FOLDERS):\n        return False\n    if os.path.isfile(filepath):\n        if os.path.getsize(filepath) > MAX_FILE_SIZE_MB * 1024 * 1024:\n            return False\n    if tier == \"code\":\n        return ext in {\".py\", \".js\", \".ts\", \".tsx\", \".java\", \".go\", \".cpp\", \".json\", \".md\"}\n    return True\n\n# \u2500\u2500\u2500 Index cache \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n_INDEX_CACHE: Optional[VectorStoreIndex] = None\n\n# \u2500\u2500\u2500 Scrub any stale model folders \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nfor path in INDEX_ROOT.iterdir():\n    if path.is_dir() and path.name != MODEL_NAME:\n        logger.warning(\"Removing stale index folder %s\", path)\n        shutil.rmtree(path,", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3540, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "131049c8-831a-4900-a463-2b9ea6c7cce4": {"__data__": {"id_": "131049c8-831a-4900-a463-2b9ea6c7cce4", "embedding": null, "metadata": {"file_path": "/app/services/kb.py", "file_name": "kb.py", "file_type": "text/x-python", "file_size": 14796, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d7bf643d-235d-4a2f-a75b-e873a491dbf7", "node_type": "4", "metadata": {"file_path": "/app/services/kb.py", "file_name": "kb.py", "file_type": "text/x-python", "file_size": 14796, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "9cfff192ee02e21f4238d14322a3d8a4c55a94b08989b1d1698d7b6fec5622e2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9dc94475-a6bd-427d-98ae-6f8b8e488e01", "node_type": "1", "metadata": {"file_path": "/app/services/kb.py", "file_name": "kb.py", "file_type": "text/x-python", "file_size": 14796, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "36bcb19af5be93d546d3f12c27f5ed2894f5eb88df1aa817f6379f22f5c34c96", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bc971bf8-7112-406c-884d-149e509337b0", "node_type": "1", "metadata": {}, "hash": "264bb1647f268118e27506e61c4cfb5a4abe08d7118481beb9f2467861521bce", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "replace(\"\\\\\", \"/\").split(\"/\")\n    if any(folder in parts for folder in IGNORED_FOLDERS):\n        return False\n    if os.path.isfile(filepath):\n        if os.path.getsize(filepath) > MAX_FILE_SIZE_MB * 1024 * 1024:\n            return False\n    if tier == \"code\":\n        return ext in {\".py\", \".js\", \".ts\", \".tsx\", \".java\", \".go\", \".cpp\", \".json\", \".md\"}\n    return True\n\n# \u2500\u2500\u2500 Index cache \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n_INDEX_CACHE: Optional[VectorStoreIndex] = None\n\n# \u2500\u2500\u2500 Scrub any stale model folders \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nfor path in INDEX_ROOT.iterdir():\n    if path.is_dir() and path.name != MODEL_NAME:\n        logger.warning(\"Removing stale index folder %s\", path)\n        shutil.rmtree(path, ignore_errors=True)\n\n# \u2500\u2500\u2500 Ingestion pipeline \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nROOT = Path(__file__).resolve().parent\nCODE_DIRS = [ROOT.parent / p for p in (\"src\", \"backend\", \"frontend\", \"services\", \"routes\")]\nDOCS_DIR = ROOT.parent / \"docs\"\nCHUNK_SIZE, CHUNK_OVERLAP = 1024, 200\n\nINGEST_PIPELINE = IngestionPipeline(\n    transformations=[\n        TitleExtractor(llm=None),\n        SentenceSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP),\n        EMBED_MODEL,\n    ]\n)\n\n# \u2500\u2500\u2500 Dimension helpers \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef _vector_dim_current() -> int:\n    return len(EMBED_MODEL.get_text_embedding(\"dim_check\"))\n\ndef _vector_dim_stored() -> int:\n    vs_file = INDEX_DIR / \"vector_store.json\"\n    if not vs_file.exists():\n        return -1\n    store = json.loads(vs_file.read_text())\n    for rec in store.values():\n        if isinstance(rec, dict) and isinstance(rec.get(\"embedding\"), list):\n            return len(rec[\"embedding\"])\n    return -1\n\nEXPECTED_DIM = None  # placeholder\n\ndef ensure_vector_dim_initialized():\n    global EXPECTED_DIM\n    if EXPECTED_DIM is None:\n        EXPECTED_DIM = _vector_dim_current()\n\n# \u2500\u2500\u2500 Public helpers \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef index_is_valid() -> bool:\n    stored = _vector_dim_stored()\n    valid = stored == EXPECTED_DIM and stored > 0\n    logger.info(\"[index_is_valid] stored=%s current=%d \u2192 %s\", stored, EXPECTED_DIM, valid)\n    return valid\n\ndef embed_all(verbose: bool = False) -> None:\n    \"\"\"Rebuild the full semantic index, applying file exclusion and content deduplication.\"\"\"", "mimetype": "text/plain", "start_char_idx": 2790, "end_char_idx": 5162, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bc971bf8-7112-406c-884d-149e509337b0": {"__data__": {"id_": "bc971bf8-7112-406c-884d-149e509337b0", "embedding": null, "metadata": {"file_path": "/app/services/kb.py", "file_name": "kb.py", "file_type": "text/x-python", "file_size": 14796, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d7bf643d-235d-4a2f-a75b-e873a491dbf7", "node_type": "4", "metadata": {"file_path": "/app/services/kb.py", "file_name": "kb.py", "file_type": "text/x-python", "file_size": 14796, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "9cfff192ee02e21f4238d14322a3d8a4c55a94b08989b1d1698d7b6fec5622e2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "131049c8-831a-4900-a463-2b9ea6c7cce4", "node_type": "1", "metadata": {"file_path": "/app/services/kb.py", "file_name": "kb.py", "file_type": "text/x-python", "file_size": 14796, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "e56fcf20bc9fa2ac105d632139a47ae73f824b81ba48826fca48f715c89fa81d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f9f4c5a0-8a79-404f-b02d-7fdb43490628", "node_type": "1", "metadata": {}, "hash": "e9c72ffec81e059aca58d62c0042e6ddc78d884a854025b0a540c7ea98e0eee5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "loads(vs_file.read_text())\n    for rec in store.values():\n        if isinstance(rec, dict) and isinstance(rec.get(\"embedding\"), list):\n            return len(rec[\"embedding\"])\n    return -1\n\nEXPECTED_DIM = None  # placeholder\n\ndef ensure_vector_dim_initialized():\n    global EXPECTED_DIM\n    if EXPECTED_DIM is None:\n        EXPECTED_DIM = _vector_dim_current()\n\n# \u2500\u2500\u2500 Public helpers \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef index_is_valid() -> bool:\n    stored = _vector_dim_stored()\n    valid = stored == EXPECTED_DIM and stored > 0\n    logger.info(\"[index_is_valid] stored=%s current=%d \u2192 %s\", stored, EXPECTED_DIM, valid)\n    return valid\n\ndef embed_all(verbose: bool = False) -> None:\n    \"\"\"Rebuild the full semantic index, applying file exclusion and content deduplication.\"\"\"\n    logger.info(\"\ud83d\udcda Re-indexing KB with model %s\", MODEL_NAME)\n\n    docs: List = []\n    tier_paths = [\n        (\"global\", [DOCS_DIR / \"generated/global_context.md\", DOCS_DIR / \"generated/global_context.auto.md\"]),\n        (\"context\", [ROOT.parent / \"context/\"]),\n        (\"project_summary\", [\n            DOCS_DIR / \"PROJECT_SUMMARY.md\",\n            DOCS_DIR / \"RELAY_CODE_UPDATE.md\",\n            DOCS_DIR / \"context-commandcenter.md\"\n        ]),\n        (\"project_docs\", [DOCS_DIR / \"imported/\", DOCS_DIR / \"kb/\", DOCS_DIR.glob(\"*.md\")]),\n        (\"code\", CODE_DIRS),\n    ]\n\n    # Aggressively filter and tag all docs with tier/metadata\n    for tier, paths in tier_paths:\n        for path in paths:\n            # Folder: Use LlamaIndex reader (recursively)\n            if isinstance(path, Path) and path.is_dir():\n                docs_ = SimpleDirectoryReader(str(path), recursive=True).load_data() if path.exists() else []\n                docs_ = [d for d in docs_ if should_index_file(\n                    d.metadata.get(\"file_path\") or d.metadata.get(\"filename\") or \"\", tier)]\n                for d in docs_:\n                    d.metadata = d.metadata or {}\n                    d.metadata[\"tier\"] = tier\n                docs.extend(docs_)\n            # Glob or single file\n            elif hasattr(path, \"__iter__\") and not isinstance(path, str):\n                for f in path:\n                    if f and os.path.isfile(f) and should_index_file(str(f), tier):\n                        with open(f, \"r\", encoding=\"utf-8\") as file:\n                            text = file.read()\n                        from llama_index.core import Document\n                        doc = Document(text=text, metadata={\"tier\": tier, \"file_path\": str(f)})\n                        docs.append(doc)\n            elif isinstance(path, Path) and path.is_file():\n                if should_index_file(str(path), tier):\n                    with open(path, \"r\", encoding=\"utf-8\") as file:\n                        text = file.read()\n                    from llama_index.core import Document\n                    doc = Document(text=text, metadata={\"tier\": tier, \"file_path\": str(path)})\n                    docs.append(doc)\n\n    # Deduplicate by file_path and text hash\n    seen = set()\n    deduped_docs = []\n    import hashlib\n    for d in docs:\n        fp = d.metadata.get(\"file_path\", \"NOFILE\")\n        content_hash = hashlib.md5(d.text.encode(\"utf-8\")).hexdigest()\n        key = (fp, content_hash)\n        if key not in seen:\n            seen.add(key)\n            deduped_docs.append(d)\n    docs = deduped_docs\n\n    # \u2500\u2500\u2500 NEW: Debug output for document loading \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    logger.info(f\"[KB] Docs loaded for indexing: {len(docs)}\")\n    for d in docs[:5]:\n        logger.info(f\"[KB] Sample doc: {d.metadata.get('file_path')} ({len(d.text)} chars)\")\n    if len(docs) == 0:\n        logger.error(\"[KB] No valid docs to index! Aborting index build to avoid hang.\")\n        raise RuntimeError(\"No valid docs for KB index. Please check your docs/code directory population.\")", "mimetype": "text/plain", "start_char_idx": 4359, "end_char_idx": 8215, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f9f4c5a0-8a79-404f-b02d-7fdb43490628": {"__data__": {"id_": "f9f4c5a0-8a79-404f-b02d-7fdb43490628", "embedding": null, "metadata": {"file_path": "/app/services/kb.py", "file_name": "kb.py", "file_type": "text/x-python", "file_size": 14796, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d7bf643d-235d-4a2f-a75b-e873a491dbf7", "node_type": "4", "metadata": {"file_path": "/app/services/kb.py", "file_name": "kb.py", "file_type": "text/x-python", "file_size": 14796, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "9cfff192ee02e21f4238d14322a3d8a4c55a94b08989b1d1698d7b6fec5622e2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bc971bf8-7112-406c-884d-149e509337b0", "node_type": "1", "metadata": {"file_path": "/app/services/kb.py", "file_name": "kb.py", "file_type": "text/x-python", "file_size": 14796, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "b00b085c0d29b4ad736f76506c5ba5282799b75f61088b497a46d4857b5a77a8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7749f07e-fa8a-4393-9208-7e2017335135", "node_type": "1", "metadata": {}, "hash": "96bbcd534f2aaaf92696c272a4eef887bc511e26d27bbe2a9322328a1bdc7a69", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Aborting index build to avoid hang.\")\n        raise RuntimeError(\"No valid docs for KB index. Please check your docs/code directory population.\")\n\n    # \u2500\u2500\u2500 NEW: Wrap embedding in try/except for logging \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    try:\n        nodes = INGEST_PIPELINE.run(documents=docs)\n    except Exception as e:\n        logger.exception(\"[KB] Failed in INGEST_PIPELINE.run\")\n        raise\n\n    logger.info(\"Generated %d vector nodes\", len(nodes))\n    index = VectorStoreIndex(nodes=nodes, embed_model=EMBED_MODEL)\n    index.storage_context.persist(persist_dir=str(INDEX_DIR))\n    logger.info(\"\u2705 Index persisted \u2192 %s\", INDEX_DIR)\n\ndef get_index() -> VectorStoreIndex:\n    \"\"\"Return a cached or loaded index, rebuilding if missing or mismatched.\"\"\"\n    global _INDEX_CACHE\n    if _INDEX_CACHE is not None and index_is_valid():\n        return _INDEX_CACHE\n    if not index_is_valid():\n        embed_all()\n    ctx = StorageContext.from_defaults(persist_dir=str(INDEX_DIR))\n    _INDEX_CACHE = load_index_from_storage(ctx, embed_model=EMBED_MODEL)\n    return _INDEX_CACHE\n\n# \u2500\u2500\u2500 Core search used by routes \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef search(\n    query: str,\n    k: int = 8,\n    search_type: str = \"all\",\n    score_threshold: Optional[float] = None,\n    user_id: Optional[str] = None,\n    explain: bool = False,\n    min_global: int = 1,\n) -> List[dict]:\n    \"\"\"\n    Tier-priority semantic search: returns top results ordered by tier.\n    - Always tries to surface global/context/project summary results first.\n    - Still returns code/project_docs if more space is available.\n    - Junk/unknown tier results are de-prioritized unless nothing else is found.\n    \"\"\"\n    PRIORITY_TIERS = [\n        \"global\", \"context\", \"project_summary\", \"project_docs\", \"code\",\n    ]\n\n    qe = get_index().as_query_engine(similarity_top_k=k * 3)\n    raw = qe.query(query)\n    tiered: Dict[str, List[Any]] = {tier: [] for tier in PRIORITY_TIERS}\n    unknown = []\n    for n in getattr(raw, \"source_nodes\", []):\n        if score_threshold is not None and n.score < score_threshold:\n            continue\n        tier = n.node.metadata.get(\"tier\", \"unknown\")\n        hit = {\n            \"id\": n.node.node_id,\n            \"snippet\": n.node.text,\n            \"similarity\": n.score,\n            \"tier\": tier,\n            \"path\": n.node.metadata.get(\"file_path\"),\n            \"title\": n.node.metadata.get(\"title\", n.node.metadata.get(\"file_path\") or \"Untitled\"),\n            \"meta\": n.node.metadata,\n        }\n        if tier in PRIORITY_TIERS:\n            tiered[tier].append(hit)\n        else:\n            unknown.append(hit)\n\n    # 1. First, fill with all global/context/summary docs, up to at least min_global if available\n    prioritized = []\n    for tier in [\"global\", \"context\", \"project_summary\"]:\n        prioritized.extend(tiered[tier][:k])\n    if len(prioritized) < min_global:\n        for tier in [\"project_docs\"]:\n            prioritized.extend(tiered[tier][:k - len(prioritized)])\n    if len(prioritized) < k:\n        prioritized.extend(tiered[\"code\"][:k - len(prioritized)])\n    if len(prioritized) < k:\n        prioritized.extend(unknown[:(k - len(prioritized))])\n\n    # Remove exact duplicates (by snippet or file path)\n    seen = set()\n    out = []\n    for h in prioritized:\n        key = (h[\"snippet\"], h[\"path\"])\n        if key not in seen:\n            seen.add(key)\n            out.append(h)\n\n    # If explain, add debug info\n    if explain:\n        print(\"[KB Search Debug]\")\n        for idx, h in enumerate(out):\n            print(f\"{idx+1:2d}.", "mimetype": "text/plain", "start_char_idx": 8070, "end_char_idx": 11612, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7749f07e-fa8a-4393-9208-7e2017335135": {"__data__": {"id_": "7749f07e-fa8a-4393-9208-7e2017335135", "embedding": null, "metadata": {"file_path": "/app/services/kb.py", "file_name": "kb.py", "file_type": "text/x-python", "file_size": 14796, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d7bf643d-235d-4a2f-a75b-e873a491dbf7", "node_type": "4", "metadata": {"file_path": "/app/services/kb.py", "file_name": "kb.py", "file_type": "text/x-python", "file_size": 14796, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "9cfff192ee02e21f4238d14322a3d8a4c55a94b08989b1d1698d7b6fec5622e2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f9f4c5a0-8a79-404f-b02d-7fdb43490628", "node_type": "1", "metadata": {"file_path": "/app/services/kb.py", "file_name": "kb.py", "file_type": "text/x-python", "file_size": 14796, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "c92a1745c58120da4ebcae329502f0f4a638fe41a759d6cecc0f6e1602a9d46d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "{h['tier']}: {h['title']} (score={h['similarity']:.3f})\")\n            print(f\"    Path: {h['path']}\")\n            print(f\"    Snippet: {h['snippet'][:200].replace(chr(10),' ')}\")\n        print(f\"\\nReturned {len(out)} results (out of {len(prioritized)})\")\n\n    return out[:k]\n\ndef api_search(query: str, k: int = 4, search_type: str = \"all\") -> List[dict]:\n    return search(query=query, k=k, search_type=search_type)\n\ndef query_index(query: str, k: int = 4) -> str:\n    \"\"\"Return formatted search snippets for a query.\"\"\"\n    results = search(query, k=k)\n    return \"\\n\\n\".join(f\"{r['title']}:\\n{r['snippet']}\" for r in results)\n\ndef api_reindex(verbose: bool = False) -> dict:\n    global _INDEX_CACHE\n    embed_all(verbose=verbose)\n    _INDEX_CACHE = None\n    return {\n        \"status\": \"ok\",\n        \"message\": \"Re-index complete\",\n        \"index_dir\": str(INDEX_DIR),\n        \"model\": MODEL_NAME,\n    }\n\ndef get_recent_summaries(user_id: str) -> list[str]:\n    return [\"No summary implemented yet.\"]\n\n# \u2500\u2500\u2500 CLI tools & debugging \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef _kb_cli():\n    import sys\n    import time\n    if len(sys.argv) > 1 and sys.argv[1] == \"search\":\n        q = \" \".join(sys.argv[2:]) or \"test\"\n        print(f\"\\n[KB CLI] Query: {q}\\n\")\n        t0 = time.time()\n        hits = search(q, k=10, explain=True)\n        print(f\"\u23f1\ufe0f  Search time: {time.time() - t0:.2f}s\\n\")\n        for h in hits:\n            print(f\"{h['title']} (score={h['similarity']:.2f}): {h['snippet'][:120].replace(chr(10),' ')}\u2026\")\n    else:\n        print(\"[KB CLI] Rebuilding index...\")\n        embed_all(verbose=True)\n        print(\"Index rebuild complete.\")\n\nif __name__ == \"__main__\":\n    _kb_cli()", "mimetype": "text/plain", "start_char_idx": 11613, "end_char_idx": 13315, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b24154f2-2a02-49cc-bb2f-30d43e44d0b6": {"__data__": {"id_": "b24154f2-2a02-49cc-bb2f-30d43e44d0b6", "embedding": null, "metadata": {"file_path": "/app/services/logger.py", "file_name": "logger.py", "file_type": "text/x-python", "file_size": 546, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7c8d4488-eb87-4860-b29b-b5b89fb20648", "node_type": "4", "metadata": {"file_path": "/app/services/logger.py", "file_name": "logger.py", "file_type": "text/x-python", "file_size": 546, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "96997997b3745954c8e9120c2e589709c2e647a40cef146946a5a188edcd259b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# services/logger.py\r\n\r\nimport logging\r\nfrom datetime import datetime\r\n\r\n# Basic logging config\r\nlogging.basicConfig(\r\n    level=logging.INFO,\r\n    format=\"%(asctime)s - %(levelname)s - %(message)s\",\r\n)\r\n\r\ndef log_info(message: str):\r\n    logging.info(message)\r\n\r\ndef log_warning(message: str):\r\n    logging.warning(message)\r\n\r\ndef log_error(message: str):\r\n    logging.error(message)\r\n\r\ndef log_event(event: str, data: dict = {}):\r\n    timestamp = datetime.utcnow().isoformat()\r\n    logging.info(f\"{timestamp} - EVENT: {event} | DATA: {data}\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 544, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "af68c9d7-b876-4933-94a2-e2f06269304b": {"__data__": {"id_": "af68c9d7-b876-4933-94a2-e2f06269304b", "embedding": null, "metadata": {"file_path": "/app/services/logs.py", "file_name": "logs.py", "file_type": "text/x-python", "file_size": 1687, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "602f5530-509c-4fcc-aa3f-c88265be5e34", "node_type": "4", "metadata": {"file_path": "/app/services/logs.py", "file_name": "logs.py", "file_type": "text/x-python", "file_size": 1687, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "8e820fbf4f4d3c655bebc1a3b575e438e598810f946feef5a3e6214b8ba3f405", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: services/logs.py\nfrom datetime import datetime\nimport json\nimport pathlib\nimport requests\nimport traceback\n\nLOG_PATH = pathlib.Path(\"logs/session_log.jsonl\")\nLOG_PATH.parent.mkdir(parents=True, exist_ok=True)\n\ndef log_entry(source: str, message: str, level: str = \"INFO\", extra: dict = None):\n    \"\"\"\n    Write a new line to the session log, optionally with level and extra fields.\n    \"\"\"\n    entry = {\n        \"time\": datetime.utcnow().isoformat(),\n        \"source\": source,\n        \"level\": level,\n        \"message\": message,\n    }\n    if extra:\n        entry.update(extra)\n    with LOG_PATH.open(\"a\", encoding=\"utf-8\") as f:\n        f.write(json.dumps(entry) + \"\\n\")\n\ndef log_exception(source: str, exc: Exception, context: str = \"\"):\n    \"\"\"\n    Log an exception with stack trace and context.\n    \"\"\"\n    stack = traceback.format_exc()\n    log_entry(\n        source=source,\n        message=f\"Exception: {exc} | Context: {context}\",\n        level=\"ERROR\",\n        extra={\"stack_trace\": stack}\n    )\n\ndef get_recent_logs(n=100, level_filter=None):\n    \"\"\"\n    Retrieve the last n log entries, optionally filtering by log level.\n    \"\"\"\n    if not LOG_PATH.exists():\n        return []\n    lines = LOG_PATH.read_text(encoding=\"utf-8\").splitlines()\n    logs = [json.loads(line) for line in lines[-n:]]\n    if level_filter:\n        logs = [log for log in logs if log.get(\"level\") == level_filter]\n    return logs\n\ndef log_and_refresh(source: str, message: str):\n    log_entry(source, message)\n    try:\n        requests.post(\"http://localhost:8000/context/update\", timeout=2)\n    except Exception as e:\n        log_exception(\"log_and_refresh\", e, \"Failed to auto-refresh context\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1686, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "dc66ab2b-ab0f-496c-9942-aa4e8bde009c": {"__data__": {"id_": "dc66ab2b-ab0f-496c-9942-aa4e8bde009c", "embedding": null, "metadata": {"file_path": "/app/services/memory.py", "file_name": "memory.py", "file_type": "text/x-python", "file_size": 2117, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b2d6d84a-5f71-4edf-adfa-9ad02b15c391", "node_type": "4", "metadata": {"file_path": "/app/services/memory.py", "file_name": "memory.py", "file_type": "text/x-python", "file_size": 2117, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "c1b40188ff11f5500f7092930e37b5dd6656ba1d8b4be788f071651eda33f2e9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: services/memory.py\n# Directory: services/\n# Purpose: Persist detailed session memory logs for /ask endpoint with deep context/usage auditing.\n# Features:\n#   - Logs timestamp, user, query, topics, files, and summary\n#   - Adds context_files, context_length, prompt_length, response_length, global_context_used, fallback flag\n#   - Used for MemoryPanel deep analysis and context diagnostics\n\nimport os\nimport json\nimport datetime\n\nSESSION_DIR = \"./logs/sessions\"\n\ndef summarize_memory_entry(\n    prompt: str,\n    response: str,\n    context: str = \"\",\n    actions: list = None,\n    user_id: str = \"anonymous\",\n    topics: list = None,\n    files: list = None,\n    context_files: list = None,\n    used_global_context: bool = False,\n    fallback: bool = False,\n    prompt_length: int = None,\n    response_length: int = None\n):\n    \"\"\"\n    Build a detailed memory entry for each session event.\n    Includes advanced context diagnostics for frontend insight.\n    \"\"\"\n    return {\n        \"timestamp\": datetime.datetime.utcnow().isoformat(),\n        \"user\": user_id,\n        \"query\": prompt,\n        \"topics\": topics or [],\n        \"files\": files or [],\n        \"context_files\": context_files or [],\n        \"context_length\": len(context or \"\"),\n        \"prompt_length\": prompt_length or (len(prompt) + len(context or \"\")),\n        \"response_length\": response_length or len(response or \"\"),\n        \"used_global_context\": used_global_context,\n        \"fallback\": fallback,\n        \"actions\": actions or [],\n        \"summary\": response  # Optionally replace with GPT summary if you want\n    }\n\ndef save_memory_entry(user_id: str, summary: dict):\n    \"\"\"\n    Write a single memory entry to the per-user log file as JSONL.\n    \"\"\"\n    os.makedirs(SESSION_DIR, exist_ok=True)\n    path = os.path.join(SESSION_DIR, f\"{user_id}.jsonl\")\n    with open(path, \"a\") as f:\n        f.write(json.dumps(summary) + \"\\n\")\n\n# === Utility: For debugging/logging what gets stored ===\ndef debug_log_entry(entry: dict):\n    print(\"[Memory] Log Entry Debug:\")\n    print(json.dumps(entry, indent=2)[:1200], \"...\\n\")  # Print first 1200 chars", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2116, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f18d7aa4-7b03-4185-9271-50379c7a331a": {"__data__": {"id_": "f18d7aa4-7b03-4185-9271-50379c7a331a", "embedding": null, "metadata": {"file_path": "/app/services/mqtt_client.py", "file_name": "mqtt_client.py", "file_type": "text/x-python", "file_size": 0, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ab8a1d89-290c-442d-bcec-6f85597bcb05", "node_type": "4", "metadata": {"file_path": "/app/services/mqtt_client.py", "file_name": "mqtt_client.py", "file_type": "text/x-python", "file_size": 0, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "7d33ee145b1848736ddab2d91f437129fd46877aa0bf4e93af615dda17294fc5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 0, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8e83629c-5b77-4256-88fc-51b973dd64ca": {"__data__": {"id_": "8e83629c-5b77-4256-88fc-51b973dd64ca", "embedding": null, "metadata": {"file_path": "/app/services/neo4j_driver.py", "file_name": "neo4j_driver.py", "file_type": "text/x-python", "file_size": 2143, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e42008b8-f2d0-4f7f-9bef-2726ab6e8774", "node_type": "4", "metadata": {"file_path": "/app/services/neo4j_driver.py", "file_name": "neo4j_driver.py", "file_type": "text/x-python", "file_size": 2143, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "c3b7dda5c32d03b5a7df48b15a7c7771d9e06a287656f8e86e4652ebf3e13f05", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: services/neo4j_driver.py\n# Purpose: Shared async Neo4j driver for Relay agent memory graph\n# Notes:\n#   - Supports async read/write using Neo4j Aura\n#   - Uses single internal driver instance (AsyncGraphDatabase)\n#   - Logs errors and can be safely imported from anywhere in the app\n\nimport os\nfrom neo4j import AsyncGraphDatabase, AsyncDriver\nfrom contextlib import asynccontextmanager\nfrom core.logging import log_event\n\n# === Load Neo4j credentials from environment ===\nNEO4J_URI = os.getenv(\"NEO4J_URI\", \"neo4j+s://localhost:7687\")\nNEO4J_USER = os.getenv(\"NEO4J_USER\", \"neo4j\")\nNEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\", \"password\")\n\n# === Initialize Neo4j driver (singleton) ===\n# Aura users: DO NOT include `database=\"neo4j\"` in session()\n_driver: AsyncDriver = AsyncGraphDatabase.driver(\n    NEO4J_URI,\n    auth=(NEO4J_USER, NEO4J_PASSWORD)\n)\n\n# Optional export if needed elsewhere\nneo4j_driver = _driver\n\n# === Async context manager for clean session usage ===\n@asynccontextmanager\nasync def get_session():\n    async with _driver.session() as session:\n        yield session\n\n# === Execute a read query and return results ===\nasync def execute_read(query: str, parameters: dict = {}) -> list[dict]:\n    try:\n        async with get_session() as session:\n            result = await session.execute_read(lambda tx: tx.run(query, parameters))\n            return [record.data() async for record in result]\n    except Exception as e:\n        print(\"\u274c Neo4j read error:\", e)\n        log_event(\"neo4j_read_fail\", {\"error\": str(e), \"query\": query})\n        return []\n\n# === Execute a write query with debug logging ===\nasync def execute_write(query: str, parameters: dict = {}) -> None:\n    try:\n        print(\"\ud83d\ude80 Neo4j write executing...\")\n        print(\"\ud83e\uddfe Cypher:\", query[:120] + \"...\" if len(query) > 120 else query)\n        print(\"\ud83d\udce6 Params:\", parameters)\n        async with get_session() as session:\n            await session.execute_write(lambda tx: tx.run(query, parameters))\n    except Exception as e:\n        print(\"\u274c Neo4j write error:\", e)\n        log_event(\"neo4j_write_fail\", {\"error\": str(e), \"query\": query})", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2129, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b332a5ed-e458-4928-890e-0cbd2164efc3": {"__data__": {"id_": "b332a5ed-e458-4928-890e-0cbd2164efc3", "embedding": null, "metadata": {"file_path": "/app/services/queue.py", "file_name": "queue.py", "file_type": "text/x-python", "file_size": 169, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a7ed14a0-2fd9-4cfe-b0eb-ef3d8459d285", "node_type": "4", "metadata": {"file_path": "/app/services/queue.py", "file_name": "queue.py", "file_type": "text/x-python", "file_size": 169, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "702846c45c29eea1e755ca4b3a48b25622226082563e567040439168f9762bc2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# services/queue.py\n\ndef queue_action(*args, **kwargs):\n    # TODO: Replace with actual queue logic\n    print(\"queue_action called with:\", args, kwargs)\n    return None", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 168, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "63cd2d92-dfe7-4b81-9d8f-2a88c4636228": {"__data__": {"id_": "63cd2d92-dfe7-4b81-9d8f-2a88c4636228", "embedding": null, "metadata": {"file_path": "/app/services/semantic_retriever.py", "file_name": "semantic_retriever.py", "file_type": "text/x-python", "file_size": 1407, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "caa94eed-711c-481b-8ef0-1ca1636f6ff5", "node_type": "4", "metadata": {"file_path": "/app/services/semantic_retriever.py", "file_name": "semantic_retriever.py", "file_type": "text/x-python", "file_size": 1407, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "f21df35a6ab961fc68713c4438c2b324403c6bf449da99d9443290bf2241e0da", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: services/semantic_retriever.py\n# Purpose: Provide top-K semantic context for agent prompts using LlamaIndex vector store.\n\nfrom llama_index.core import load_index_from_storage, StorageContext\nfrom llama_index.embeddings.openai import OpenAIEmbedding\nimport sys\nimport traceback\n\n# === Configuration ===\nINDEX_DIR = \"./data/index\"\nEMBED_MODEL_NAME = \"text-embedding-3-large\"\n\n# === Embedding Model and Storage Context ===\n_embed_model = OpenAIEmbedding(model=EMBED_MODEL_NAME)\ntry:\n    storage_context = StorageContext.from_defaults(persist_dir=INDEX_DIR)\n    _index = load_index_from_storage(storage_context=storage_context, embed_model=_embed_model)\nexcept Exception as e:\n    print(\"LlamaIndex load_index_from_storage FAILED:\")\n    traceback.print_exc()\n    sys.exit(1)\n\n# === Main Retrieval Function ===\ndef get_semantic_context(query: str, top_k: int = 5) -> str:\n    \"\"\"\n    Retrieves the top_k most semantically relevant code/docs chunks for the query.\n    Returns concatenated context string (with file path/title if possible).\n    \"\"\"\n    results = _index.query(query, top_k=top_k)\n    if not results:\n        return \"No semantically relevant context found.\"\n    lines = []\n    for r in results:\n        meta = r.metadata or {}\n        title = meta.get(\"file_path\") or meta.get(\"tier\") or \"Unknown Source\"\n        lines.append(f\"### {title}\\n{r.text.strip()}\")\n    return \"\\n\\n\".join(lines)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1406, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bb0cc5e0-a490-4853-ac65-4cf35b4810d6": {"__data__": {"id_": "bb0cc5e0-a490-4853-ac65-4cf35b4810d6", "embedding": null, "metadata": {"file_path": "/app/services/settings.py", "file_name": "settings.py", "file_type": "text/x-python", "file_size": 793, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "dc5e4917-dfc6-464f-bd61-4f49fd1aef98", "node_type": "4", "metadata": {"file_path": "/app/services/settings.py", "file_name": "settings.py", "file_type": "text/x-python", "file_size": 793, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "adbf6af0059e2bab14431c541e6b7670c00a52e0495b405f78287a60d0d2144a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# services/settings.py\nimport os\nfrom dotenv import load_dotenv\nfrom pathlib import Path\n\n# === Load .env file automatically at app startup ===\nload_dotenv(dotenv_path=Path(__file__).resolve().parents[1] / \".env\")\n\n# === Centralized environment variables ===\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nGOOGLE_CLIENT_ID = os.getenv(\"GOOGLE_CLIENT_ID\")\nGOOGLE_CLIENT_SECRET = os.getenv(\"GOOGLE_CLIENT_SECRET\")\nGOOGLE_REDIRECT_URI = os.getenv(\"GOOGLE_REDIRECT_URI\", \"http://localhost:3000/auth/callback\")\n\n# === Validation helper ===\ndef assert_env(var, hint=\"\"):\n    value = os.getenv(var)\n    if not value:\n        raise RuntimeError(f\"Missing required env var: {var}. {hint}\")\n    return value\n\n# Example usage:\n# assert_env(\"OPENAI_API_KEY\", \"Set in .env or as system environment variable\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 793, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ba274e0a-cb33-4acc-b71f-7243301cdf10": {"__data__": {"id_": "ba274e0a-cb33-4acc-b71f-7243301cdf10", "embedding": null, "metadata": {"file_path": "/app/services/summarize_memory.py", "file_name": "summarize_memory.py", "file_type": "text/x-python", "file_size": 818, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "956a5115-cce5-4de4-9c62-aa6fa3b399d3", "node_type": "4", "metadata": {"file_path": "/app/services/summarize_memory.py", "file_name": "summarize_memory.py", "file_type": "text/x-python", "file_size": 818, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "d7ab690fe4bc8a9ff2ef720d5490df54f52d57bfa93cb592a8df8b8690c52bbb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: services/summarize_memory.py\n# Directory: services/\n# Purpose: Use OpenAI to generate concise summary of a user-agent memory exchange\n\nimport os\nfrom openai import AsyncOpenAI\nfrom utils.openai_client import create_openai_client\n\nclient = create_openai_client()\n\nasync def summarize_memory_entry(question: str, response: str, context: str = \"\") -> str:\n    prompt = f\"\"\"\nYou are a concise summarizer of agent interactions.\n\nSummarize this user query and response in 1\u20132 sentences for memory recall:\n\nQ: {question}\n\nAgent response: {response}\n\nContext (if needed):\n{context[:500]}\n\nSummary:\n\"\"\"\n    result = await client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        temperature=0.2\n    )\n    return result.choices[0].message.content.strip()", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 815, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8494e05b-2944-486a-8016-3493332c19db": {"__data__": {"id_": "8494e05b-2944-486a-8016-3493332c19db", "embedding": null, "metadata": {"file_path": "/app/routes/__init__.py", "file_name": "__init__.py", "file_type": "text/x-python", "file_size": 0, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8f62a157-0cf3-4f1f-89a8-79e7c9baab88", "node_type": "4", "metadata": {"file_path": "/app/routes/__init__.py", "file_name": "__init__.py", "file_type": "text/x-python", "file_size": 0, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "dc1060b3428ab04347394ef914ec84b2bec57f08dd033246e845dbd8831d3fad", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 0, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "64b45a3c-7c71-4332-8eaf-8001094f7c2e": {"__data__": {"id_": "64b45a3c-7c71-4332-8eaf-8001094f7c2e", "embedding": null, "metadata": {"file_path": "/app/routes/admin.py", "file_name": "admin.py", "file_type": "text/x-python", "file_size": 7292, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "10507fa1-9b3e-423c-a097-6704ad6dbf00", "node_type": "4", "metadata": {"file_path": "/app/routes/admin.py", "file_name": "admin.py", "file_type": "text/x-python", "file_size": 7292, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "034eb11f0a2184816025e5454ef8cb2299c504ba72850eb2526d7e03f2ebbfde", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f2f9f571-7f9f-4630-b433-e64566a577e4", "node_type": "1", "metadata": {}, "hash": "e1e7741e7b331a32664b3f5c1b118e348d4194b4f2ac17e2b867144f75a6029e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# routes/admin.py\n# ------------------------------------------------------------------------\n# Admin and Ops Endpoints for Relay Command Center\n# Secure, auditable, and environment-driven maintenance tools.\n# ALL endpoints require a valid API key (X-API-Key header, matches API_KEY env var).\n# Review and update environment variables in Railway/Vercel/Codespaces as needed.\n# ------------------------------------------------------------------------\n\nimport os\nimport shutil\nimport psutil\nimport platform\nimport zipfile\nfrom fastapi import APIRouter, HTTPException, Request, status, Header, Depends\nfrom fastapi.responses import FileResponse\nfrom pathlib import Path\nfrom datetime import datetime\n\nfrom services.config import INDEX_DIR\n\n# ------------------------------------------------------------------------\n# ENV/CONFIG SETUP\n# ------------------------------------------------------------------------\nrouter = APIRouter(prefix=\"/admin\", tags=[\"admin-ops\"])\n\nDATA_DIR = INDEX_DIR.parent\nADMIN_LOG = DATA_DIR / \"admin_events.log\"\n\n# ------------------------------------------------------------------------\n# SECURITY: Require valid API Key (X-API-Key header) for all admin ops\n# ------------------------------------------------------------------------\ndef require_api_key(x_api_key: str = Header(..., alias=\"X-API-Key\")):\n    api_key = os.environ.get(\"API_KEY\")\n    if not api_key or x_api_key != api_key:\n        raise HTTPException(status_code=403, detail=\"Invalid or missing API key.\")\n\n# ------------------------------------------------------------------------\n# UTIL: Audit logging\u2014append all events and errors\n# ------------------------------------------------------------------------\ndef log_admin_event(msg: str):\n    timestamp = datetime.utcnow().isoformat()\n    log_entry = f\"{timestamp} | {msg}\\n\"\n    with ADMIN_LOG.open(\"a\", encoding=\"utf-8\") as f:\n        f.write(log_entry)\n\n# ------------------------------------------------------------------------\n# ENDPOINT: Clean LlamaIndex index and SQLite DBs\n# ------------------------------------------------------------------------\n@router.post(\"/clean_index\")\nasync def clean_index(\n    request: Request,\n    user: str = \"\",\n    api_key: str = Depends(require_api_key)\n):\n    \"\"\"\n    Deletes all files in the index directory and SQLite DBs.\n    Requires valid X-API-Key header.\n    \"\"\"\n    deleted_files = []\n    # --- Index directory wipe ---\n    if INDEX_DIR.exists():\n        for f in INDEX_DIR.glob(\"*\"):\n            try:\n                if f.is_file():\n                    f.unlink()\n                    deleted_files.append(str(f))\n                elif f.is_dir():\n                    shutil.rmtree(f)\n                    deleted_files.append(str(f))\n            except Exception as e:\n                log_admin_event(f\"[ERROR] Failed to delete {f}: {e}\")\n    # --- SQLite DBs wipe ---\n    for sfile in DATA_DIR.glob(\"*.sqlite*\"):\n        try:\n            sfile.unlink()\n            deleted_files.append(str(sfile))\n        except Exception as e:\n            log_admin_event(f\"[ERROR] Failed to delete {sfile}: {e}\")\n\n    # --- Audit log ---\n    client_ip = request.client.host if request.client else \"unknown\"\n    now = datetime.utcnow().isoformat()\n    log_admin_event(f\"[CLEAN_INDEX] {now} by {user or 'unknown'} from {client_ip}: Deleted {len(deleted_files)} files\")\n\n    return {\n        \"status\": \"ok\",\n        \"message\": \"Index and SQLite files cleaned.\",\n        \"deleted_files\": deleted_files,\n        \"timestamp\": now,\n        \"user\": user,\n        \"ip\": client_ip\n    }\n\n# ------------------------------------------------------------------------\n# ENDPOINT: Trigger Index Rebuild (now fully implemented)\n# ------------------------------------------------------------------------\nfrom services.indexer import index_directories  # <-- add this import at the top if missing\n\n@router.post(\"/trigger_reindex\")\nasync def trigger_reindex(\n    request: Request,\n    user: str = \"\",\n    api_key: str = Depends(require_api_key)\n):\n    \"\"\"\n    Triggers a rebuild of the LlamaIndex (semantic KB).\n    Returns status/result.\n    \"\"\"\n    try:\n        index_directories()  # This will run synchronously (blocking until finished)\n        log_admin_event(f\"[REINDEX_TRIGGER] SUCCESS by {user or 'unknown'} from {request.client.host}\")\n        return {\"status\": \"ok\", \"message\": \"Reindex complete.\"}\n    except Exception as exc:\n        log_admin_event(f\"[REINDEX_TRIGGER] ERROR by {user or 'unknown'} from {request.client.host}: {exc}\")\n        raise HTTPException(status_code=500, detail=f\"Reindex failed: {exc}\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4575, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f2f9f571-7f9f-4630-b433-e64566a577e4": {"__data__": {"id_": "f2f9f571-7f9f-4630-b433-e64566a577e4", "embedding": null, "metadata": {"file_path": "/app/routes/admin.py", "file_name": "admin.py", "file_type": "text/x-python", "file_size": 7292, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "10507fa1-9b3e-423c-a097-6704ad6dbf00", "node_type": "4", "metadata": {"file_path": "/app/routes/admin.py", "file_name": "admin.py", "file_type": "text/x-python", "file_size": 7292, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "034eb11f0a2184816025e5454ef8cb2299c504ba72850eb2526d7e03f2ebbfde", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "64b45a3c-7c71-4332-8eaf-8001094f7c2e", "node_type": "1", "metadata": {"file_path": "/app/routes/admin.py", "file_name": "admin.py", "file_type": "text/x-python", "file_size": 7292, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "a6262a770638142d2c7054a241e28dd80e1011bf19ef45b08805b2a0d222eb79", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# ------------------------------------------------------------------------\n# ENDPOINT: Health Check (disk, CPU, memory, config summary)\n# ------------------------------------------------------------------------\n@router.get(\"/health_check\")\nasync def health_check(\n    request: Request,\n    user: str = \"\",\n    api_key: str = Depends(require_api_key)\n):\n    \"\"\"\n    Returns backend, disk, memory, and config health for diagnostics.\n    Requires valid X-API-Key header.\n    \"\"\"\n    health = {\n        \"system\": platform.system(),\n        \"release\": platform.release(),\n        \"cpu_percent\": psutil.cpu_percent(),\n        \"memory\": dict(psutil.virtual_memory()._asdict()),\n        \"disk\": dict(psutil.disk_usage('/')._asdict()),\n        \"python_version\": platform.python_version(),\n        \"env\": {\n            \"index_dir\": str(INDEX_DIR),\n            \"data_dir\": str(DATA_DIR),\n        }\n    }\n    log_admin_event(f\"[HEALTH_CHECK] by {user or 'unknown'} from {request.client.host}\")\n    return health\n\n# ------------------------------------------------------------------------\n# ENDPOINT: Download Audit Log\n# ------------------------------------------------------------------------\n@router.get(\"/download_log\")\nasync def download_log(\n    request: Request,\n    user: str = \"\",\n    api_key: str = Depends(require_api_key)\n):\n    \"\"\"\n    Allows secure download of admin event log.\n    Requires valid X-API-Key header.\n    \"\"\"\n    if not ADMIN_LOG.exists():\n        raise HTTPException(status_code=404, detail=\"No log file found.\")\n    log_admin_event(f\"[DOWNLOAD_LOG] by {user or 'unknown'} from {request.client.host}\")\n    return FileResponse(str(ADMIN_LOG), media_type=\"text/plain\", filename=\"admin_events.log\")\n\n# ------------------------------------------------------------------------\n# ENDPOINT: Backup Index Directory (zip)\n# ------------------------------------------------------------------------\n@router.post(\"/backup_index\")\nasync def backup_index(\n    request: Request,\n    user: str = \"\",\n    api_key: str = Depends(require_api_key)\n):\n    \"\"\"\n    Zips the index directory for backup/offline restore.\n    Requires valid X-API-Key header.\n    \"\"\"\n    backup_path = DATA_DIR / f\"index_backup_{datetime.utcnow().strftime('%Y%m%d%H%M%S')}.zip\"\n    with zipfile.ZipFile(backup_path, \"w\") as zipf:\n        if INDEX_DIR.exists():\n            for f in INDEX_DIR.rglob(\"*\"):\n                if f.is_file():\n                    zipf.write(f, f.relative_to(DATA_DIR))\n    log_admin_event(f\"[BACKUP_INDEX] by {user or 'unknown'} from {request.client.host}\")\n    return {\n        \"status\": \"ok\",\n        \"message\": f\"Index directory backed up to {backup_path.name}\",\n        \"backup_file\": str(backup_path)\n    }", "mimetype": "text/plain", "start_char_idx": 4578, "end_char_idx": 7288, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3d949099-99e4-40d5-9993-b40571a91910": {"__data__": {"id_": "3d949099-99e4-40d5-9993-b40571a91910", "embedding": null, "metadata": {"file_path": "/app/routes/admin_routes.py", "file_name": "admin_routes.py", "file_type": "text/x-python", "file_size": 750, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "51d3239f-b8a4-47d4-bf6a-60311009920a", "node_type": "4", "metadata": {"file_path": "/app/routes/admin_routes.py", "file_name": "admin_routes.py", "file_type": "text/x-python", "file_size": 750, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "a97cd546e09ccbfb53fd2bbd316d7612a22eb697b308401e5569f42fd5cc1e35", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: routes/admin_routes.py\n# Purpose: Add manual trigger to generate auto global context from /context/*.md\n\nfrom fastapi import APIRouter, Depends\nfrom fastapi.responses import JSONResponse\nimport subprocess\nimport os\n\nrouter = APIRouter(prefix=\"/admin\", tags=[\"admin\"])\n\n@router.post(\"/generate_auto_context\")\ndef generate_auto_context():\n    try:\n        result = subprocess.run(\n            [\"python\", \"scripts/generate_global_context.auto.py\"],\n            capture_output=True, text=True, check=True\n        )\n        return JSONResponse({\"status\": \"success\", \"output\": result.stdout})\n    except subprocess.CalledProcessError as e:\n        return JSONResponse(\n            {\"status\": \"error\", \"detail\": e.stderr}, status_code=500\n        )", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 749, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "792dbdcd-b20b-463b-9d84-f672bf7de6b0": {"__data__": {"id_": "792dbdcd-b20b-463b-9d84-f672bf7de6b0", "embedding": null, "metadata": {"file_path": "/app/routes/ask.py", "file_name": "ask.py", "file_type": "text/x-python", "file_size": 7881, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "95eae29a-cc96-4b4c-8e6e-30b4c6a4ab5d", "node_type": "4", "metadata": {"file_path": "/app/routes/ask.py", "file_name": "ask.py", "file_type": "text/x-python", "file_size": 7881, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "382afc9178451e5a3c1ecb1ccce87fec6d13cd390c1d8389ee98090a55ab3dc2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "af50a720-637e-4f2a-af24-086c1d19e15b", "node_type": "1", "metadata": {}, "hash": "f42b406bb8f9056957d8e25e2f6e2f3ebbb898c8e31bd3089b0eaaf35550d42a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: routes/ask.py\r\n# Directory: routes/\r\n# Purpose: Unified API routes for /ask endpoints \u2014 user entry point to Relay agents\r\n#          Delegates all query logic to MCP (run_mcp), handling agent/critic orchestration.\r\n#          Handles streaming for both Codex and Echo (primary/fallback) agents.\r\n# Updated: 2025-07-02\r\n\r\nimport traceback\r\nfrom fastapi import APIRouter, Query, Request, Header, HTTPException\r\nfrom fastapi.responses import StreamingResponse\r\nfrom typing import Optional\r\n\r\nfrom agents.mcp_agent import run_mcp\r\nfrom agents.codex_agent import stream as codex_stream\r\nfrom agents.echo_agent import stream as echo_stream\r\nfrom utils.openai_client import create_openai_client\r\nfrom openai import OpenAIError\r\n\r\nrouter = APIRouter(prefix=\"/ask\", tags=[\"ask\"])\r\n\r\n# Streaming map for roles that support it\r\nSTREAM_ROUTING_TABLE = {\r\n    \"codex\": codex_stream,\r\n    \"echo\": echo_stream,\r\n    # Add more streaming agents here as needed in the future\r\n}\r\n\r\n# === GET /ask ==================================================================\r\n@router.get(\"\")\r\nasync def ask_get(\r\n    request: Request,\r\n    question: str = Query(..., description=\"User's natural language question\"),\r\n    x_user_id: Optional[str] = Header(None, alias=\"X-User-Id\"),\r\n    debug: Optional[bool] = Query(False, description=\"Return debug/context info\"),\r\n    role: Optional[str] = Query(\"planner\", description=\"Which agent role to use (planner, echo, codex, etc)\"),\r\n    files: Optional[str] = Query(None, description=\"Comma-separated file list for context\"),\r\n    topics: Optional[str] = Query(None, description=\"Comma-separated topics for context\")\r\n):\r\n    \"\"\"\r\n    GET version of /ask, mostly for quick dev/testing.\r\n    Routes to MCP with appropriate agent role.\r\n    Echo is always available as both primary and fallback agent.\r\n    \"\"\"\r\n    user_id = x_user_id or \"anonymous\"\r\n    file_list = [f.strip() for f in files.split(\",\")] if files else []\r\n    topic_list = [t.strip() for t in topics.split(\",\")] if topics else []\r\n\r\n    if not question:\r\n        raise HTTPException(status_code=422, detail=\"Missing 'question' parameter.\")\r\n\r\n    try:\r\n        return await run_mcp(\r\n            query=question,\r\n            files=file_list,\r\n            topics=topic_list,\r\n            role=role,\r\n            user_id=user_id,\r\n            debug=debug\r\n        )\r\n    except Exception as e:\r\n        traceback.print_exc()\r\n        raise HTTPException(status_code=500, detail=str(e))\r\n\r\n# === POST /ask =================================================================\r\n@router.post(\"\")\r\nasync def ask_post(\r\n    request: Request,\r\n    payload: dict,\r\n    x_user_id: Optional[str] = Header(None, alias=\"X-User-Id\"),\r\n    debug: Optional[bool] = Query(False),\r\n):\r\n    \"\"\"\r\n    Main POST endpoint for /ask \u2014 entrypoint for planner, codex, echo, or other agents.\r\n    Routes all queries to MCP for context injection, agent routing, and critics.\r\n    Echo is always available as both primary and fallback agent.\r\n    \"\"\"\r\n    user_id = x_user_id or \"anonymous\"\r\n    question = payload.get(\"question\", \"\")\r\n    context = payload.get(\"context\", \"\")\r\n    files = payload.get(\"files\", [])\r\n    topics = payload.get(\"topics\", [])\r\n    role = payload.get(\"role\", \"planner\")\r\n\r\n    if not question:\r\n        raise HTTPException(status_code=422, detail=\"Missing 'question' in request payload.\")\r\n\r\n    try:\r\n        result = await run_mcp(\r\n            query=question,\r\n            files=files,\r\n            topics=topics,\r\n            role=role,\r\n            user_id=user_id,\r\n            debug=debug\r\n        )\r\n        return result\r\n    except Exception as e:\r\n        traceback.print_exc()\r\n        raise HTTPException(status_code=500, detail=str(e))\r\n\r\n\r\n# === POST /ask/stream ==========================================================\r\n@router.post(\"/stream\")\r\nasync def ask_stream(\r\n    request: Request,\r\n    payload: dict,\r\n    x_user_id: Optional[str] = Header(None, alias=\"X-User-Id\"),\r\n):\r\n    \"\"\"\r\n    Streaming endpoint for planner/meta/explicit agent roles via MCP routing.\r\n    If the routed agent supports streaming, streams the response.\r\n    Fallbacks to Echo stream if the routed agent doesn't support streaming.\r\n    \"\"\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4222, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "af50a720-637e-4f2a-af24-086c1d19e15b": {"__data__": {"id_": "af50a720-637e-4f2a-af24-086c1d19e15b", "embedding": null, "metadata": {"file_path": "/app/routes/ask.py", "file_name": "ask.py", "file_type": "text/x-python", "file_size": 7881, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "95eae29a-cc96-4b4c-8e6e-30b4c6a4ab5d", "node_type": "4", "metadata": {"file_path": "/app/routes/ask.py", "file_name": "ask.py", "file_type": "text/x-python", "file_size": 7881, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "382afc9178451e5a3c1ecb1ccce87fec6d13cd390c1d8389ee98090a55ab3dc2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "792dbdcd-b20b-463b-9d84-f672bf7de6b0", "node_type": "1", "metadata": {"file_path": "/app/routes/ask.py", "file_name": "ask.py", "file_type": "text/x-python", "file_size": 7881, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "8d5202dbfb8671bdcffb2c55ce8cff77a082e7e8fa8b97ea344c0938d39227d6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "try:\r\n        result = await run_mcp(\r\n            query=question,\r\n            files=files,\r\n            topics=topics,\r\n            role=role,\r\n            user_id=user_id,\r\n            debug=debug\r\n        )\r\n        return result\r\n    except Exception as e:\r\n        traceback.print_exc()\r\n        raise HTTPException(status_code=500, detail=str(e))\r\n\r\n\r\n# === POST /ask/stream ==========================================================\r\n@router.post(\"/stream\")\r\nasync def ask_stream(\r\n    request: Request,\r\n    payload: dict,\r\n    x_user_id: Optional[str] = Header(None, alias=\"X-User-Id\"),\r\n):\r\n    \"\"\"\r\n    Streaming endpoint for planner/meta/explicit agent roles via MCP routing.\r\n    If the routed agent supports streaming, streams the response.\r\n    Fallbacks to Echo stream if the routed agent doesn't support streaming.\r\n    \"\"\"\r\n    user_id = x_user_id or \"anonymous\"\r\n    question = payload.get(\"question\", \"\")\r\n    context = payload.get(\"context\", \"\")\r\n    files = payload.get(\"files\", [])\r\n    topics = payload.get(\"topics\", [])\r\n    role = payload.get(\"role\", \"planner\")\r\n\r\n    if not question:\r\n        raise HTTPException(status_code=422, detail=\"Missing 'question' in request payload.\")\r\n\r\n    try:\r\n        # Get plan and route via MCP (to know the agent/role to stream)\r\n        mcp_result = await run_mcp(\r\n            query=question,\r\n            files=files,\r\n            topics=topics,\r\n            role=role,\r\n            user_id=user_id,\r\n            debug=False\r\n        )\r\n        plan = mcp_result.get(\"plan\", {})\r\n        used_route = plan.get(\"meta_override\") or plan.get(\"route\") or role\r\n\r\n        stream_fn = STREAM_ROUTING_TABLE.get(used_route, echo_stream)\r\n        return StreamingResponse(\r\n            stream_fn(question, context, user_id),\r\n            media_type=\"text/plain\"\r\n        )\r\n    except Exception as e:\r\n        traceback.print_exc()\r\n        raise HTTPException(status_code=500, detail=str(e))\r\n\r\n\r\n# === POST /ask/codex_stream ===================================================\r\n@router.post(\"/codex_stream\")\r\nasync def ask_codex_stream(\r\n    request: Request,\r\n    payload: dict,\r\n    x_user_id: Optional[str] = Header(None, alias=\"X-User-Id\")\r\n):\r\n    \"\"\"\r\n    Streaming endpoint for Codex/code edits. Streams text output directly.\r\n    \"\"\"\r\n    user_id = x_user_id or \"anonymous\"\r\n    question = payload.get(\"question\", \"\")\r\n    context = payload.get(\"context\", \"\")\r\n\r\n    if not question or not context:\r\n        raise HTTPException(status_code=422, detail=\"Missing 'question' or 'context' in request.\")\r\n\r\n    try:\r\n        return StreamingResponse(codex_stream(question, context, user_id), media_type=\"text/plain\")\r\n    except Exception as e:\r\n        traceback.print_exc()\r\n        raise HTTPException(status_code=500, detail=str(e))\r\n\r\n\r\n# === POST /ask/echo_stream ====================================================\r\n@router.post(\"/echo_stream\")\r\nasync def ask_echo_stream(\r\n    request: Request,\r\n    payload: dict,\r\n    x_user_id: Optional[str] = Header(None, alias=\"X-User-Id\"),\r\n):\r\n    \"\"\"\r\n    Streaming endpoint for Echo (LLM chat) responses.\r\n    \"\"\"\r\n    user_id = x_user_id or \"anonymous\"\r\n    question = payload.get(\"question\", \"\")\r\n    context = payload.get(\"context\", \"\")\r\n\r\n    if not question:\r\n        raise HTTPException(status_code=422, detail=\"Missing 'question' in request.\")\r\n\r\n    try:\r\n        return StreamingResponse(\r\n            echo_stream(question, context, user_id),\r\n            media_type=\"text/plain\"\r\n        )\r\n    except Exception as e:\r\n        traceback.print_exc()\r\n        raise HTTPException(status_code=500, detail=str(e))\r\n\r\n\r\n# === GET /ask/test_openai ======================================================\r\n@router.get(\"/test_openai\")\r\nasync def test_openai():\r\n    \"\"\"\r\n    Quick endpoint to verify OpenAI API connectivity and model health.\r\n    \"\"\"\r\n    try:\r\n        client = create_openai_client()\r\n        response = await client.chat.completions.create(\r\n            model=\"gpt-4o\",\r\n            messages=[\r\n                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\r\n                {\"role\": \"user\", \"content\": \"Ping test\"}\r\n            ]\r\n        )\r\n        return { \"response\": response.choices[0].message.content }\r\n    except OpenAIError as e:\r\n        raise HTTPException(status_code=502, detail=str(e))\r\n    except Exception as e:\r\n        traceback.print_exc()\r\n        raise HTTPException(status_code=500, detail=f\"Unexpected error: {str(e)}\")", "mimetype": "text/plain", "start_char_idx": 3381, "end_char_idx": 7875, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1fe50337-9315-46f0-a46a-3f31e2d56b28": {"__data__": {"id_": "1fe50337-9315-46f0-a46a-3f31e2d56b28", "embedding": null, "metadata": {"file_path": "/app/routes/codex.py", "file_name": "codex.py", "file_type": "text/x-python", "file_size": 1956, "creation_date": "2025-06-28", "last_modified_date": "2025-06-28", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7b1ec6a5-a75b-47ec-9e66-f73a87b0083e", "node_type": "4", "metadata": {"file_path": "/app/routes/codex.py", "file_name": "codex.py", "file_type": "text/x-python", "file_size": 1956, "creation_date": "2025-06-28", "last_modified_date": "2025-06-28", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "45fe82f985a5507fbfada618abaa7ce71b6db1f9926b740f32bc6064de5b49a3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: routes/codex.py\n# Purpose: CodexAgent backend endpoints (e.g., patch application, preview)\n\nimport os\nfrom fastapi import APIRouter, HTTPException, Request\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel\nfrom utils.patch_utils import validate_patch_format\nfrom core.logging import log_event\n\nrouter = APIRouter(prefix=\"/codex\", tags=[\"codex\"])\n\nclass PatchRequest(BaseModel):\n    target_file: str\n    patch: str\n    reason: str\n\n@router.post(\"/apply_patch\")\nasync def apply_patch(payload: PatchRequest, request: Request):\n    \"\"\"\n    Apply a code patch directly to the specified file on disk.\n    \"\"\"\n    if not validate_patch_format({\"type\": \"patch\", **payload.dict()}):\n        raise HTTPException(status_code=422, detail=\"Invalid patch format.\")\n\n    try:\n        file_path = os.path.abspath(payload.target_file)\n\n        # Optional: Prevent writing outside project root\n        project_root = os.path.abspath(os.getcwd())\n        if not file_path.startswith(project_root):\n            raise HTTPException(status_code=400, detail=\"Refused to write outside project scope.\")\n\n        # Optional: Ensure file exists (comment out if you want to allow creation)\n        if not os.path.exists(file_path):\n            raise HTTPException(status_code=404, detail=f\"Target file not found: {payload.target_file}\")\n\n        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(payload.patch)\n\n    except Exception as e:\n        log_event(\"codex_patch_error\", {\n            \"file\": payload.target_file,\n            \"error\": str(e)\n        })\n        raise HTTPException(status_code=500, detail=f\"Failed to apply patch: {e}\")\n\n    log_event(\"codex_patch_applied\", {\n        \"file\": payload.target_file,\n        \"user\": request.headers.get(\"X-User-Id\", \"anon\")\n    })\n    return JSONResponse({\n        \"status\": \"success\",\n        \"file\": payload.target_file,\n        \"message\": \"Patch written successfully.\"\n    })", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1955, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "93765477-4e06-4799-af5e-f6de66fe639a": {"__data__": {"id_": "93765477-4e06-4799-af5e-f6de66fe639a", "embedding": null, "metadata": {"file_path": "/app/routes/context.py", "file_name": "context.py", "file_type": "text/x-python", "file_size": 4064, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c93701a2-a156-450e-a8d1-92e39416a595", "node_type": "4", "metadata": {"file_path": "/app/routes/context.py", "file_name": "context.py", "file_type": "text/x-python", "file_size": 4064, "creation_date": "2025-07-03", "last_modified_date": "2025-07-03", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "f1f960614145b2efc38ff904be63b07906936b936e05172b32fc018cc037d737", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: routes/context.py\n# Purpose: Robust API endpoints for updating and syncing global context and project summaries,\n#          with full markdown safety and error handling for downstream context injection.\n\nfrom fastapi import APIRouter, HTTPException\nfrom services.logs import get_recent_logs, log_and_refresh\nfrom services.google_docs_sync import sync_google_docs\nfrom openai import OpenAI\nfrom pathlib import Path\nimport os\nimport traceback\n\nrouter = APIRouter(prefix=\"/context\", tags=[\"context\"])\n\n# Paths for generated context files\nRELAY_CONTEXT_PATH = Path(\"docs/generated/relay_context.md\")\nGLOBAL_CONTEXT_PATH = Path(\"docs/generated/global_context.md\")\nRELAY_CONTEXT_PATH.parent.mkdir(parents=True, exist_ok=True)\n\ndef safe_write_markdown(path: Path, content: str, header: str = None):\n    \"\"\"Write markdown safely, fallback to a minimal file if an error occurs.\"\"\"\n    try:\n        with open(path, \"w\", encoding=\"utf-8\") as f:\n            if header:\n                f.write(f\"# {header}\\n\\n\")\n            f.write(content.strip() + \"\\n\")\n    except Exception as e:\n        print(f\"Failed to write {path}: {e}\")\n        # Ensure at least an empty file exists\n        try:\n            path.write_text(\"# (empty)\\n\", encoding=\"utf-8\")\n        except Exception:\n            pass\n\ndef ensure_stub_file(path: Path, stub: str = \"# (empty)\\n\"):\n    \"\"\"Ensure a minimal stub markdown file exists.\"\"\"\n    if not path.exists():\n        try:\n            path.write_text(stub, encoding=\"utf-8\")\n        except Exception as e:\n            print(f\"Failed to create stub {path}: {e}\")\n\n# --- Endpoint: Update relay_context.md from logs ---\n@router.post(\"/update\")\ndef update_context_summary():\n    \"\"\"Summarize recent logs to relay_context.md (markdown-safe, robust to errors).\"\"\"\n    ensure_stub_file(RELAY_CONTEXT_PATH, \"# Relay Context (not yet summarized)\\n\")\n    try:\n        logs = get_recent_logs(100)\n        if not logs:\n            safe_write_markdown(RELAY_CONTEXT_PATH, \"No logs to summarize.\", \"Relay Context (auto-generated)\")\n            return {\"status\": \"no logs to summarize\"}\n\n        text = \"\\n\".join(f\"[{l['source']}] {l['message']}\" for l in logs)\n\n        client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n        response = client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=[\n                {\"role\": \"system\", \"content\": \"You are a system summarizer for a command center log.\"},\n                {\"role\": \"user\", \"content\": f\"Summarize the following session log:\\n\\n{text}\"}\n            ]\n        )\n\n        summary = response.choices[0].message.content.strip()\n        safe_write_markdown(RELAY_CONTEXT_PATH, summary, \"Relay Context (auto-generated)\")\n        log_and_refresh(\"system\", \"Updated relay_context.md from session logs.\")\n        return {\"status\": \"ok\", \"summary\": summary}\n\n    except Exception as e:\n        # Log the traceback and return a safe fallback\n        print(f\"Exception in update_context_summary: {e}\\n{traceback.format_exc()}\")\n        safe_write_markdown(RELAY_CONTEXT_PATH, f\"Error updating summary: {e}\", \"Relay Context (auto-generated)\")\n        raise HTTPException(status_code=500, detail=f\"Failed to update context: {e}\")\n\n# --- Sync Google Docs and ensure stub context files ---\n@router.post(\"/sync_docs\")\ndef sync_docs_and_update():\n    \"\"\"Sync Google Docs and ensure global context markdown is safe.\"\"\"\n    ensure_stub_file(GLOBAL_CONTEXT_PATH, \"# Global Project Context (not yet generated)\\n\")\n    try:\n        synced = sync_google_docs()\n        log_and_refresh(\"system\", f\"Synced {len(synced)} docs from Google Drive into /docs/imported\")\n        return {\"status\": \"ok\", \"synced_docs\": synced}\n    except Exception as e:\n        print(f\"Exception in sync_docs_and_update: {e}\\n{traceback.format_exc()}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n# Deprecated sync route for compatibility with /docs/sync_google\n@router.post(\"/sync_google\")\ndef legacy_sync_google():\n    \"\"\"Backward-compatible alias for sync_docs.\"\"\"\n    return sync_docs_and_update()", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4063, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4e860305-eff2-4fa6-a0f4-a44c64d4eb2d": {"__data__": {"id_": "4e860305-eff2-4fa6-a0f4-a44c64d4eb2d", "embedding": null, "metadata": {"file_path": "/app/routes/control.py", "file_name": "control.py", "file_type": "text/x-python", "file_size": 7803, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "09ec149a-3e21-409a-8651-57a52d3530ee", "node_type": "4", "metadata": {"file_path": "/app/routes/control.py", "file_name": "control.py", "file_type": "text/x-python", "file_size": 7803, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "300b84ad937a6eeb7cfffd6396219f5d12d5b28155c33c0886fb298debe9d825", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b7f36b73-9f56-40ea-8f6d-f324d8d19565", "node_type": "1", "metadata": {}, "hash": "221452af402e7c6e1bf4f5fbd75e5bb46dad8f63579bd13bf0e6130e81e356be", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: routes/control.py\r\n# Directory: routes/\r\n# Purpose: Relay Action Queue & Audit API\r\n# - Queue, approve, deny, and execute agent-proposed actions\r\n# - Maintains audit log and Gmail notifications\r\n# - CORS-safe, with strong error handling and API key auth\r\n\r\nimport os, json\r\nfrom uuid import uuid4\r\nfrom pathlib import Path\r\nfrom datetime import datetime\r\nfrom fastapi import APIRouter, Depends, Header, HTTPException, Body, Request\r\n\r\nfrom services import gmail\r\nfrom agents import codex_agent, docs_agent, echo_agent\r\nfrom agents.control_agent import control_agent\r\n\r\nrouter = APIRouter(prefix=\"/control\", tags=[\"control\"])\r\n\r\n# === Auth Middleware ===\r\ndef auth(key: str = Header(None, alias=\"X-API-Key\")):\r\n    expected = os.getenv(\"API_KEY\")\r\n    if not key or key != expected:\r\n        raise HTTPException(status_code=401, detail=\"Invalid API key\")\r\n    return \"admin\"\r\n\r\n# === File paths ===\r\nACTIONS_PATH = Path(__file__).resolve().parents[1] / \"data\" / \"pending_actions.json\"\r\nLOG_PATH = Path(__file__).resolve().parents[1] / \"logs\" / \"actions.log\"\r\nACTIONS_PATH.parent.mkdir(parents=True, exist_ok=True)\r\nLOG_PATH.parent.mkdir(parents=True, exist_ok=True)\r\nif not ACTIONS_PATH.exists():\r\n    ACTIONS_PATH.write_text(\"[]\")\r\n\r\n# === Utils ===\r\ndef load_actions():\r\n    return json.loads(ACTIONS_PATH.read_text())\r\n\r\ndef save_actions(actions):\r\n    ACTIONS_PATH.write_text(json.dumps(actions, indent=2))\r\n\r\ndef append_log(entry: dict):\r\n    with LOG_PATH.open(\"a\", encoding=\"utf-8\") as f:\r\n        f.write(json.dumps(entry) + \"\\n\")\r\n\r\ndef update_action_history(action, status, user, comment=\"\"):\r\n    action.setdefault(\"history\", []).append({\r\n        \"timestamp\": datetime.utcnow().isoformat(),\r\n        \"status\": status,\r\n        \"user\": user,\r\n        \"comment\": comment\r\n    })\r\n\r\n# === Agent Dispatch Map ===\r\nAGENT_DISPATCH = {\r\n    \"codex\": codex_agent.handle,\r\n    \"control\": control_agent.run,\r\n    \"docs\": docs_agent.analyze,\r\n    \"echo\": echo_agent.run,\r\n}\r\n\r\n# === /queue_action ===\r\n@router.post(\"/queue_action\")\r\ndef queue_action(data: dict = Body(...), user=Depends(auth)):\r\n    action_id = str(uuid4())\r\n    queued = {\r\n        \"id\": action_id,\r\n        \"timestamp\": datetime.utcnow().isoformat(),\r\n        \"status\": \"pending\",\r\n        \"action\": data,\r\n        \"history\": [{\r\n            \"timestamp\": datetime.utcnow().isoformat(),\r\n            \"status\": \"pending\",\r\n            \"user\": user,\r\n            \"comment\": data.get(\"rationale\", \"\")\r\n        }]\r\n    }\r\n    actions = load_actions()\r\n    actions.append(queued)\r\n    save_actions(actions)\r\n    return {\"status\": \"queued\", \"id\": action_id}\r\n\r\n# === /list_queue ===\r\n@router.get(\"/list_queue\")\r\ndef list_queue(user=Depends(auth)):\r\n    try:\r\n        return {\"actions\": load_actions()}\r\n    except Exception as e:\r\n        raise HTTPException(500, f\"Failed to load queue: {e}\")\r\n\r\n# === /approve_action ===\r\n@router.post(\"/approve_action\")\r\nasync def approve_action(data: dict = Body(...), user=Depends(auth)):\r\n    action_id = data.get(\"id\")\r\n    comment = data.get(\"comment\", \"\")\r\n    if not action_id:\r\n        raise HTTPException(400, \"Missing action ID\")\r\n\r\n    actions = load_actions()\r\n    updated = []\r\n    approved = None\r\n\r\n    for a in actions:\r\n        if a[\"id\"] == action_id and a[\"status\"] == \"pending\":\r\n            approved = a\r\n            a[\"status\"] = \"approved\"\r\n            a[\"approved_at\"] = datetime.utcnow().isoformat()\r\n            update_action_history(a, \"approved\", user, comment)\r\n        updated.append(a)\r\n\r\n    if not approved:\r\n        raise HTTPException(404, \"No matching pending action found\")\r\n\r\n    save_actions(updated)\r\n    action_data = approved[\"action\"]\r\n\r\n    route = action_data.get(\"type\")\r\n    handler = AGENT_DISPATCH.get(route)\r\n\r\n    if handler:\r\n        result = await handler(\n            query=action_data.get(\"query\", \"\"),\n            context=action_data.get(\"context\", {}),", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3915, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b7f36b73-9f56-40ea-8f6d-f324d8d19565": {"__data__": {"id_": "b7f36b73-9f56-40ea-8f6d-f324d8d19565", "embedding": null, "metadata": {"file_path": "/app/routes/control.py", "file_name": "control.py", "file_type": "text/x-python", "file_size": 7803, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "09ec149a-3e21-409a-8651-57a52d3530ee", "node_type": "4", "metadata": {"file_path": "/app/routes/control.py", "file_name": "control.py", "file_type": "text/x-python", "file_size": 7803, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "300b84ad937a6eeb7cfffd6396219f5d12d5b28155c33c0886fb298debe9d825", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4e860305-eff2-4fa6-a0f4-a44c64d4eb2d", "node_type": "1", "metadata": {"file_path": "/app/routes/control.py", "file_name": "control.py", "file_type": "text/x-python", "file_size": 7803, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "902f6fb961ca6cec6f99215327ea4f89ee1bd49cab4ff097d67b966e06ec1ad1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0e26de10-885c-4310-8460-3a23312ec452", "node_type": "1", "metadata": {}, "hash": "51e73c896b6eb2134e79b853ef27c947b548e57d8d23832f6d24438669a8edda", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "get(\"comment\", \"\")\r\n    if not action_id:\r\n        raise HTTPException(400, \"Missing action ID\")\r\n\r\n    actions = load_actions()\r\n    updated = []\r\n    approved = None\r\n\r\n    for a in actions:\r\n        if a[\"id\"] == action_id and a[\"status\"] == \"pending\":\r\n            approved = a\r\n            a[\"status\"] = \"approved\"\r\n            a[\"approved_at\"] = datetime.utcnow().isoformat()\r\n            update_action_history(a, \"approved\", user, comment)\r\n        updated.append(a)\r\n\r\n    if not approved:\r\n        raise HTTPException(404, \"No matching pending action found\")\r\n\r\n    save_actions(updated)\r\n    action_data = approved[\"action\"]\r\n\r\n    route = action_data.get(\"type\")\r\n    handler = AGENT_DISPATCH.get(route)\r\n\r\n    if handler:\r\n        result = await handler(\n            query=action_data.get(\"query\", \"\"),\n            context=action_data.get(\"context\", {}),\n            user_id=user\n        )\n        append_log({\r\n            \"id\": action_id,\r\n            \"type\": route,\r\n            \"timestamp\": datetime.utcnow().isoformat(),\r\n            \"status\": \"executed\",\r\n            \"result\": result,\r\n            \"user\": user,\r\n            \"comment\": comment\r\n        })\r\n        return result\r\n\r\n    # Optional: file write fallback\r\n    if action_data.get(\"type\") == \"write_file\":\r\n        result = write_file(action_data, user=user)\r\n        append_log({\r\n            \"id\": action_id,\r\n            \"type\": \"write_file\",\r\n            \"path\": action_data.get(\"path\"),\r\n            \"timestamp\": datetime.utcnow().isoformat(),\r\n            \"status\": \"executed\",\r\n            \"result\": result,\r\n            \"user\": user,\r\n            \"comment\": comment\r\n        })\r\n        return result\r\n\r\n    append_log({\r\n        \"id\": action_id,\r\n        \"type\": action_data.get(\"type\"),\r\n        \"timestamp\": datetime.utcnow().isoformat(),\r\n        \"status\": \"approved\",\r\n        \"user\": user,\r\n        \"comment\": comment\r\n    })\r\n\r\n    return {\"status\": \"approved\"}\r\n\r\n# === /deny_action ===\r\n@router.post(\"/deny_action\")\r\ndef deny_action(data: dict = Body(...), user=Depends(auth)):\r\n    action_id = data.get(\"id\")\r\n    comment = data.get(\"comment\", \"\")\r\n    if not action_id:\r\n        raise HTTPException(400, \"Missing action ID\")\r\n\r\n    actions = load_actions()\r\n    updated = []\r\n    denied = None\r\n\r\n    for a in actions:\r\n        if a[\"id\"] == action_id and a[\"status\"] == \"pending\":\r\n            denied = a\r\n            a[\"status\"] = \"denied\"\r\n            a[\"denied_at\"] = datetime.utcnow().isoformat()\r\n            update_action_history(a, \"denied\", user, comment)\r\n        updated.append(a)\r\n\r\n    if not denied:\r\n        raise HTTPException(404, \"No matching pending action found\")\r\n\r\n    save_actions(updated)\r\n    append_log({\r\n        \"id\": action_id,\r\n        \"type\": denied[\"action\"].get(\"type\"),\r\n        \"timestamp\": datetime.utcnow().isoformat(),\r\n        \"status\": \"denied\",\r\n        \"user\": user,\r\n        \"comment\": comment\r\n    })\r\n    return {\"status\": \"denied\"}\r\n\r\n# === /list_log ===\r\n@router.get(\"/list_log\")\r\ndef list_log(user=Depends(auth)):\r\n    try:\r\n        if not LOG_PATH.exists():\r\n            return {\"log\": []}\r\n        with LOG_PATH.open(\"r\", encoding=\"utf-8\") as f:\r\n            lines = f.readlines()\r\n        return {\"log\": [json.loads(line) for line in lines if line.strip()]}\r\n    except Exception as e:\r\n        raise HTTPException(500, f\"Failed to read log: {e}\")\r\n\r\n# === /write_file ===\r\n@router.post(\"/write_file\")\r\ndef write_file(data: dict = Body(...), user=Depends(auth)):\r\n    path = data.get(\"path\")\r\n    content = data.get(\"content\")\r\n    if not path or not content:\r\n        raise HTTPException(400, \"Missing path or content\")\r\n    base = Path(__file__).resolve().parents[1]\r\n    full_path = base / path\r\n    full_path.parent.mkdir(parents=True, exist_ok=True)\r\n    try:\r\n        full_path.write_text(content)\r\n        return {\r\n            \"status\": \"success\",\r\n            \"path\": str(full_path.relative_to(base)),", "mimetype": "text/plain", "start_char_idx": 3049, "end_char_idx": 7009, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0e26de10-885c-4310-8460-3a23312ec452": {"__data__": {"id_": "0e26de10-885c-4310-8460-3a23312ec452", "embedding": null, "metadata": {"file_path": "/app/routes/control.py", "file_name": "control.py", "file_type": "text/x-python", "file_size": 7803, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "09ec149a-3e21-409a-8651-57a52d3530ee", "node_type": "4", "metadata": {"file_path": "/app/routes/control.py", "file_name": "control.py", "file_type": "text/x-python", "file_size": 7803, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "300b84ad937a6eeb7cfffd6396219f5d12d5b28155c33c0886fb298debe9d825", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b7f36b73-9f56-40ea-8f6d-f324d8d19565", "node_type": "1", "metadata": {"file_path": "/app/routes/control.py", "file_name": "control.py", "file_type": "text/x-python", "file_size": 7803, "creation_date": "2025-07-02", "last_modified_date": "2025-07-02", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "6b8a503ebe88200ad02c1b081a67479c1f780586ca880ff9d59e49c5ae5e026b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "readlines()\r\n        return {\"log\": [json.loads(line) for line in lines if line.strip()]}\r\n    except Exception as e:\r\n        raise HTTPException(500, f\"Failed to read log: {e}\")\r\n\r\n# === /write_file ===\r\n@router.post(\"/write_file\")\r\ndef write_file(data: dict = Body(...), user=Depends(auth)):\r\n    path = data.get(\"path\")\r\n    content = data.get(\"content\")\r\n    if not path or not content:\r\n        raise HTTPException(400, \"Missing path or content\")\r\n    base = Path(__file__).resolve().parents[1]\r\n    full_path = base / path\r\n    full_path.parent.mkdir(parents=True, exist_ok=True)\r\n    try:\r\n        full_path.write_text(content)\r\n        return {\r\n            \"status\": \"success\",\r\n            \"path\": str(full_path.relative_to(base)),\r\n            \"size\": len(content)\r\n        }\r\n    except Exception as e:\r\n        raise HTTPException(500, f\"Failed to write file: {e}\")\r\n\r\n# === /test (ControlAgent direct test) ===\r\n@router.post(\"/test\")\r\nasync def control_test(request: Request, user=Depends(auth)):\r\n    payload = await request.json()\r\n    query = payload.get(\"query\", \"\")\r\n    context = payload.get(\"context\", {})\r\n\r\n    result = await control_agent.run(query=query, context=context, user_id=user)\r\n    append_log({\r\n        \"id\": f\"manual-{datetime.utcnow().isoformat()}\",\r\n        \"type\": \"control_test\",\r\n        \"timestamp\": datetime.utcnow().isoformat(),\r\n        \"status\": \"executed\",\r\n        \"user\": user,\r\n        \"query\": query,\r\n        \"context\": context,\r\n        \"result\": result\r\n    })\r\n    return result", "mimetype": "text/plain", "start_char_idx": 6267, "end_char_idx": 7801, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "042a2091-7b01-404a-bb08-dbc24b7c8dbe": {"__data__": {"id_": "042a2091-7b01-404a-bb08-dbc24b7c8dbe", "embedding": null, "metadata": {"file_path": "/app/routes/debug.py", "file_name": "debug.py", "file_type": "text/x-python", "file_size": 342, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "60b5ba83-0e9a-4e8d-8502-53cdc5db4df4", "node_type": "4", "metadata": {"file_path": "/app/routes/debug.py", "file_name": "debug.py", "file_type": "text/x-python", "file_size": 342, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "be006be57b9a77192892dc50729fdd01e0aac0f79060dbd9df4ab8267356f5ad", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: routes/debug.py\nfrom fastapi import APIRouter\nimport os\n\nrouter = APIRouter()\n\n@router.get(\"/debug/env\")\ndef debug_env():\n    val = os.getenv(\"GOOGLE_CREDS_JSON\")\n    return {\n        \"GOOGLE_CREDS_JSON present\": bool(val),\n        \"length\": len(val) if val else 0,\n        \"starts_with\": val[:30] + \"...\" if val else \"MISSING\"\n    }", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 341, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ce3f04da-e475-4100-9ea5-63513b6c945a": {"__data__": {"id_": "ce3f04da-e475-4100-9ea5-63513b6c945a", "embedding": null, "metadata": {"file_path": "/app/routes/docs.py", "file_name": "docs.py", "file_type": "text/x-python", "file_size": 8487, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b0cbb453-9d7f-48aa-a87c-3b71bb8db6b8", "node_type": "4", "metadata": {"file_path": "/app/routes/docs.py", "file_name": "docs.py", "file_type": "text/x-python", "file_size": 8487, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "2ef58a6a4655ba2c2e9b558bee0cef0e55af28be8ede572ce957a476da7872ef", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e6c6648a-fd25-492a-9231-27fd07ee7467", "node_type": "1", "metadata": {}, "hash": "04170c25233bea69a272243d4bdc426d56d8f61ec6eae028a9e3021fd664b012", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# File: docs.py\n# Directory: routes/\n# Purpose : Secure API routes for listing, viewing, syncing, promoting,\n#           pruning, and prioritizing tiered Markdown documentation.\n# Notes   :\n#   \u2022 API\u2011key (or future SSO) required for every endpoint.\n#   \u2022 Path\u2011traversal safe: requested file must resolve inside project_root/docs.\n#   \u2022 Adds /mark_priority to manually set doc tier or pin for context.\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nfrom __future__ import annotations\n\nimport os\nimport shutil\nfrom pathlib import Path\nfrom typing import List\n\nfrom fastapi import APIRouter, Depends, HTTPException, Query, Request\nfrom fastapi.responses import JSONResponse\n\nfrom services.google_docs_sync import sync_google_docs\nfrom services import kb\nfrom services.context_engine import ContextEngine\nfrom services.docs_utils import (\n    extract_doc_id,\n    build_doc_registry,\n    choose_canonical_path,\n    write_doc_metadata,\n)\n\n# \u2500\u2500\u2500 Router Setup \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nrouter = APIRouter(prefix=\"/docs\", tags=[\"docs\"])\n\n# \u2500\u2500\u2500 Auth Stub (replace with real auth) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef require_api_key():\n    return True  # TODO: Replace with real API key or OAuth validation\n\n# \u2500\u2500\u2500 Constants \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nPROJECT_ROOT = Path(__file__).resolve().parents[1]\nBASE_DIR: Path = PROJECT_ROOT / \"docs\"\nCATEGORIES = (\"imported\", \"generated\")\n\ndef _safe_resolve(path: Path) -> Path:\n    resolved = path.resolve()\n    resolved.relative_to(BASE_DIR)\n    return resolved\n\n# \u2500\u2500\u2500 List docs with metadata \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n@router.get(\"/list\", dependencies=[Depends(require_api_key)])\nasync def list_docs(\n    category: str = Query(\"all\", pattern=\"^(all|imported|generated)$\"),\n    limit: int = Query(100, ge=1, le=500),\n):\n    cats = CATEGORIES if category == \"all\" else (category,)\n    results: List[dict] = []\n\n    for sub in cats:\n        for f in (BASE_DIR / sub).rglob(\"*.md\"):\n            if len(results) >= limit:\n                break\n            try:\n                doc_id = extract_doc_id(f)\n                results.append({\n                    \"path\": str(f.relative_to(BASE_DIR)),\n                    \"doc_id\": doc_id,\n                    \"tier\": sub,\n                    \"source\": \"google\" if \"imported\" in str(f) else \"local\",\n                    \"last_modified\": f.stat().st_mtime,\n                })\n            except Exception:\n                continue\n\n    return {\"files\": results}\n\n# \u2500\u2500\u2500 View raw markdown \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n@router.get(\"/view\", dependencies=[Depends(require_api_key)])\nasync def view_doc(path: str):\n    try:\n        doc_path = _safe_resolve(BASE_DIR / path)\n        if not doc_path.exists():\n            raise HTTPException(status_code=404, detail=\"Doc not found\")\n        return {\"content\": doc_path.read_text()}\n    except ValueError:\n        raise HTTPException(status_code=400, detail=\"Invalid path\")\n    except Exception:\n        raise HTTPException(status_code=500, detail=\"Internal error\")\n\n# \u2500\u2500\u2500 Google Docs Sync \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n@router.post(\"/sync\", dependencies=[Depends(require_api_key)])\nasync def sync_docs():\n    try:\n        saved_files = sync_google_docs()\n        kb.api_reindex()\n        ContextEngine.clear_cache()\n        return {\"synced_docs\": saved_files}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n# \u2500\u2500\u2500 Manual Reindex \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n@router.post(\"/refresh_kb\", dependencies=[Depends(require_api_key)])\nasync def refresh_kb():\n    try:\n        result = kb.api_reindex()\n        ContextEngine.clear_cache()\n        return result\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@router.post(\"/full_sync\", dependencies=[Depends(require_api_key)])\nasync def full_sync():\n    try:\n        files = sync_google_docs()\n        index_info = kb.api_reindex()\n        ContextEngine.clear_cache()\n        return {\"synced_docs\": files,", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4222, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e6c6648a-fd25-492a-9231-27fd07ee7467": {"__data__": {"id_": "e6c6648a-fd25-492a-9231-27fd07ee7467", "embedding": null, "metadata": {"file_path": "/app/routes/docs.py", "file_name": "docs.py", "file_type": "text/x-python", "file_size": 8487, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b0cbb453-9d7f-48aa-a87c-3b71bb8db6b8", "node_type": "4", "metadata": {"file_path": "/app/routes/docs.py", "file_name": "docs.py", "file_type": "text/x-python", "file_size": 8487, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "2ef58a6a4655ba2c2e9b558bee0cef0e55af28be8ede572ce957a476da7872ef", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ce3f04da-e475-4100-9ea5-63513b6c945a", "node_type": "1", "metadata": {"file_path": "/app/routes/docs.py", "file_name": "docs.py", "file_type": "text/x-python", "file_size": 8487, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "7502c0baaebc29e765c1528e17f6c468a4a421a3fcb96f4fcfeaf6289b0e4b6a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "api_reindex()\n        ContextEngine.clear_cache()\n        return {\"synced_docs\": saved_files}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n# \u2500\u2500\u2500 Manual Reindex \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n@router.post(\"/refresh_kb\", dependencies=[Depends(require_api_key)])\nasync def refresh_kb():\n    try:\n        result = kb.api_reindex()\n        ContextEngine.clear_cache()\n        return result\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@router.post(\"/full_sync\", dependencies=[Depends(require_api_key)])\nasync def full_sync():\n    try:\n        files = sync_google_docs()\n        index_info = kb.api_reindex()\n        ContextEngine.clear_cache()\n        return {\"synced_docs\": files, \"kb\": index_info}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n# \u2500\u2500\u2500 Promote to canonical \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n@router.post(\"/promote\", dependencies=[Depends(require_api_key)])\nasync def promote_doc(request: Request):\n    data = await request.json()\n    path = data.get(\"path\")\n    if not path:\n        raise HTTPException(status_code=400, detail=\"Missing path\")\n\n    full_path = _safe_resolve(BASE_DIR / path)\n    if not full_path.exists():\n        raise HTTPException(status_code=404, detail=\"File not found\")\n\n    doc_id = extract_doc_id(full_path)\n    target_path = BASE_DIR / f\"{doc_id}.md\"\n\n    try:\n        shutil.copy(full_path, target_path)\n        kb.api_reindex()\n        ContextEngine.clear_cache()\n        return {\"promoted\": str(target_path.relative_to(BASE_DIR))}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Promote failed: {e}\")\n\n# \u2500\u2500\u2500 Prune Duplicates \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n@router.post(\"/prune_duplicates\", dependencies=[Depends(require_api_key)])\nasync def prune_duplicates():\n    removed = []\n    try:\n        registry = build_doc_registry()\n        for doc_id, versions in registry.items():\n            if len(versions) <= 1:\n                continue\n            keep = choose_canonical_path(versions)\n            for path in versions:\n                if path != keep:\n                    try:\n                        os.remove(path)\n                        removed.append(str(path.relative_to(BASE_DIR)))\n                    except Exception as e:\n                        print(f\"\u26a0\ufe0f Failed to remove {path}: {e}\")\n        kb.api_reindex()\n        ContextEngine.clear_cache()\n        return {\"removed\": removed}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Prune failed: {e}\")\n\n# \u2500\u2500\u2500 Mark Priority / Tier \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n@router.post(\"/mark_priority\", dependencies=[Depends(require_api_key)])\nasync def mark_priority(request: Request):\n    \"\"\"\n    Set or update a doc's metadata: tier, pinned flag, or doc_id.\n    \"\"\"\n    data = await request.json()\n    path = data.get(\"path\")\n    tier = data.get(\"tier\")\n    pinned = data.get(\"pinned\")\n\n    if not path:\n        raise HTTPException(status_code=400, detail=\"Missing path\")\n\n    full_path = _safe_resolve(BASE_DIR / path)\n    if not full_path.exists():\n        raise HTTPException(status_code=404, detail=\"File not found\")\n\n    try:\n        write_doc_metadata(full_path, {\"tier\": tier, \"pinned\": pinned})\n        kb.api_reindex()\n        ContextEngine.clear_cache()\n        return {\"updated\": str(full_path.relative_to(BASE_DIR)), \"tier\": tier, \"pinned\": pinned}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Metadata update failed: {e}\")", "mimetype": "text/plain", "start_char_idx": 3435, "end_char_idx": 7078, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e3756285-316d-4169-af73-7cf91b109b87": {"__data__": {"id_": "e3756285-316d-4169-af73-7cf91b109b87", "embedding": null, "metadata": {"file_path": "/app/routes/embeddings.py", "file_name": "embeddings.py", "file_type": "text/x-python", "file_size": 1611, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a9af4860-3709-4426-98e6-a13c1e1d66cd", "node_type": "4", "metadata": {"file_path": "/app/routes/embeddings.py", "file_name": "embeddings.py", "file_type": "text/x-python", "file_size": 1611, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "ae5bf40ea6b7b300c50395334dec0685ee583037c4bb7d3f8cb68a012545f250", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# routes/embeddings.py\n\n\"\"\"\nEmbeddings Debug & Maintenance API for Relay\n---------------------------------------------\n- /embeddings/status : Check if embedding index exists, get stats\n- /embeddings/rebuild : (POST) Trigger rebuild of the embedding index\n\"\"\"\n\nfrom fastapi import APIRouter, Response, status\nfrom fastapi.responses import JSONResponse\nfrom services import embeddings\nimport os\nfrom pathlib import Path\nimport time\n\nrouter = APIRouter()\n\nEMBED_INDEX = embeddings.EMBED_INDEX\n\n@router.get(\"/embeddings/status\")\ndef embeddings_status():\n    \"\"\"\n    Returns basic info about the current embedding index.\n    \"\"\"\n    info = {\n        \"exists\": False,\n        \"num_files\": None,\n        \"last_modified\": None\n    }\n    if os.path.exists(EMBED_INDEX):\n        stat = os.stat(EMBED_INDEX)\n        info[\"exists\"] = True\n        info[\"last_modified\"] = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(stat.st_mtime))\n        try:\n            # Try to get number of files in index\n            import pickle\n            with open(EMBED_INDEX, \"rb\") as f:\n                idx = pickle.load(f)\n            info[\"num_files\"] = len(idx)\n        except Exception as e:\n            info[\"num_files\"] = f\"Error: {e}\"\n    return JSONResponse(info)\n\n@router.post(\"/embeddings/rebuild\")\ndef embeddings_rebuild():\n    \"\"\"\n    Triggers a rebuild of the embedding index.\n    \"\"\"\n    try:\n        embeddings.build_index()\n        return JSONResponse({\"status\": \"ok\", \"message\": \"Embedding index rebuilt.\"})\n    except Exception as e:\n        return JSONResponse({\"status\": \"error\", \"message\": str(e)}, status_code=500)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1610, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "24b9cb94-0312-42a8-99c1-116027148a56": {"__data__": {"id_": "24b9cb94-0312-42a8-99c1-116027148a56", "embedding": null, "metadata": {"file_path": "/app/routes/index.py", "file_name": "index.py", "file_type": "text/x-python", "file_size": 1283, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "61259ec3-cd95-4e4d-b215-b73e25366f15", "node_type": "4", "metadata": {"file_path": "/app/routes/index.py", "file_name": "index.py", "file_type": "text/x-python", "file_size": 1283, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "77e59bd35d6da85d8facc8386e6c1acad728c0f5b35a5b595bc0f4745526ac60", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: routes/index.py\n# Directory: routes/\n# Purpose: FastAPI endpoint to trigger code/doc indexing\u2014secured with API Key, dev/staging only.\n\nfrom fastapi import APIRouter, Depends, HTTPException, Header\nimport os\nfrom services.indexer import index_directories\nfrom datetime import datetime\nfrom pathlib import Path\n\nrouter = APIRouter(prefix=\"/ops\", tags=[\"ops\"])\n\n# -- Security: Require X-API-Key header for indexing --\ndef require_api_key(x_api_key: str = Header(..., alias=\"X-API-Key\")):\n    api_key = os.environ.get(\"API_KEY\")\n    if not api_key or x_api_key != api_key:\n        raise HTTPException(status_code=403, detail=\"Invalid or missing API key.\")\n\n# -- Optional: Simple audit log to /data/ops_events.log --\nAUDIT_LOG = Path(os.environ.get(\"AUDIT_LOG\", \"/app/data/ops_events.log\"))\n\ndef log_event(msg: str):\n    now = datetime.utcnow().isoformat()\n    with AUDIT_LOG.open(\"a\", encoding=\"utf-8\") as f:\n        f.write(f\"{now} | {msg}\\n\")\n\n@router.post(\"/index\")\nasync def trigger_index(api_key: str = Depends(require_api_key), user: str = \"ops\"):\n    \"\"\"\n    Secured endpoint to start indexing codebase and docs (requires X-API-Key).\n    \"\"\"\n    log_event(f\"[TRIGGER_INDEX] by {user}\")\n    index_directories()\n    return {\"status\": \"ok\", \"message\": \"Indexing started!\"}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1280, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "83fc7e65-a33b-4a96-8a97-24433ce0cd12": {"__data__": {"id_": "83fc7e65-a33b-4a96-8a97-24433ce0cd12", "embedding": null, "metadata": {"file_path": "/app/routes/kb.py", "file_name": "kb.py", "file_type": "text/x-python", "file_size": 3005, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "bfd9ac9a-cc40-43ea-a592-12dcac061a38", "node_type": "4", "metadata": {"file_path": "/app/routes/kb.py", "file_name": "kb.py", "file_type": "text/x-python", "file_size": 3005, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "d3e4a99b9c0e8901f1fd3eee9fdca4573eb1756e86420cbb34a727659b1109e4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# routes/kb.py\n# Directory: routes/\n# Purpose: API routes for knowledge base (KB) semantic search, summary, and admin endpoints.\n# Security: All admin/debug endpoints require X-API-Key header, which must match API_KEY in environment.\n# Stack: FastAPI, LlamaIndex/OpenAI (via services.kb), User-aware\n\nfrom fastapi import APIRouter, HTTPException, Header, Depends, Query\nfrom pydantic import BaseModel\nfrom typing import Optional\nfrom services import kb\nimport os\n\n# === Security Dependency: Require X-API-Key header for all admin ops ===\ndef require_api_key(x_api_key: str = Header(..., alias=\"X-API-Key\")):\n    api_key = os.environ.get(\"API_KEY\")\n    if not api_key or x_api_key != api_key:\n        raise HTTPException(status_code=403, detail=\"Invalid or missing API key.\")\n\nrouter = APIRouter(prefix=\"/kb\", tags=[\"knowledge-base\"])\n\nclass SearchQuery(BaseModel):\n    query: str\n    k: int = 4\n    search_type: Optional[str] = \"all\"  # \"code\", \"doc\", or \"all\"\n\n@router.post(\"/search\")\nasync def search_kb(\n    q: SearchQuery,\n    x_user_id: Optional[str] = Header(None, alias=\"X-User-Id\")\n):\n    \"\"\"\n    Search the knowledge base (semantic vector index) for relevant snippets.\n    Optional X-User-Id header for user-aware results.\n    `search_type`: 'code', 'doc', or 'all'.\n    \"\"\"\n    user_id = x_user_id or \"anonymous\"\n    try:\n        results = kb.api_search(\n            query=q.query,\n            k=q.k,\n            search_type=q.search_type or \"all\"\n        )\n        return {\"results\": results}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"KB search failed: {e}\")\n\n@router.get(\"/search\")\nasync def search_kb_get(\n    query: str,\n    k: int = 4,\n    search_type: Optional[str] = \"all\",\n    x_user_id: Optional[str] = Header(None, alias=\"X-User-Id\")\n):\n    \"\"\"\n    GET variant of KB search for easy testing.\n    \"\"\"\n    user_id = x_user_id or \"anonymous\"\n    try:\n        results = kb.api_search(\n            query=query,\n            k=k,\n            search_type=search_type or \"all\"\n        )\n        return {\"results\": results}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"KB search failed: {e}\")\n\n@router.get(\"/summary\")\nasync def get_summary(\n    x_user_id: Optional[str] = Header(None, alias=\"X-User-Id\")\n):\n    \"\"\"\n    Fetch recent context summary for a given user, or fallback to generic summary.\n    \"\"\"\n    user_id = x_user_id or \"anonymous\"\n    try:\n        summary = kb.get_recent_summaries(user_id)\n        return {\"summary\": summary}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"KB summary fetch failed: {e}\")\n\n@router.post(\"/reindex\")\nasync def reindex_kb(\n    api_key: str = Depends(require_api_key)\n):\n    \"\"\"\n    Trigger a rebuild of the KB index (admin/debug only).\n    Requires X-API-Key header.\n    \"\"\"\n    try:\n        resp = kb.api_reindex()\n        return resp\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"KB reindex failed: {e}\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3004, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fa4799e7-d420-4148-afaf-ef6211988516": {"__data__": {"id_": "fa4799e7-d420-4148-afaf-ef6211988516", "embedding": null, "metadata": {"file_path": "/app/routes/logs_sessions.py", "file_name": "logs_sessions.py", "file_type": "text/x-python", "file_size": 774, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "888173d7-1fb9-404d-9f59-bea71addb73a", "node_type": "4", "metadata": {"file_path": "/app/routes/logs_sessions.py", "file_name": "logs_sessions.py", "file_type": "text/x-python", "file_size": 774, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "b4d10905ed051dbab4a441631a2782cf8909529c78cb1f5df851550af375d6bf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: routes/logs_sessions.py\n# Directory: routes/\n# Purpose: API route for listing user session memory logs from /logs/sessions/*.jsonl\n\nfrom fastapi import APIRouter, Request\nfrom pathlib import Path\nimport json\n\nrouter = APIRouter(prefix=\"/logs/sessions\", tags=[\"logs\", \"memory\"])\n\nSESSION_LOG_DIR = Path(\"./logs/sessions\")\n\n@router.get(\"/all\")\ndef list_all_sessions():\n    entries = []\n    for path in SESSION_LOG_DIR.glob(\"*.jsonl\"):\n        with open(path) as f:\n            for line in f:\n                try:\n                    parsed = json.loads(line)\n                    entries.append(parsed)\n                except json.JSONDecodeError:\n                    continue\n    return {\"entries\": sorted(entries, key=lambda x: x.get(\"timestamp\", \"\"), reverse=True)}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 773, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "facb9b5c-ee05-4853-b307-0d111ec63245": {"__data__": {"id_": "facb9b5c-ee05-4853-b307-0d111ec63245", "embedding": null, "metadata": {"file_path": "/app/routes/mcp.py", "file_name": "mcp.py", "file_type": "text/x-python", "file_size": 2007, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3d3248c5-f501-4acb-8c53-1f291fb9328c", "node_type": "4", "metadata": {"file_path": "/app/routes/mcp.py", "file_name": "mcp.py", "file_type": "text/x-python", "file_size": 2007, "creation_date": "2025-06-30", "last_modified_date": "2025-06-30", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "75a34f5b0c770124325a02d536a6f3a87a6ec4914eb62bf1dbf2d103d151d9c2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# File: routes/mcp.py\n# Directory: routes/\n# Purpose: API route for direct access to MCP handler (run_mcp) for testing, automation, or admin use\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nfrom fastapi import APIRouter, HTTPException, Request, Header\nfrom typing import Optional\nfrom agents.mcp_agent import run_mcp\n\nrouter = APIRouter(prefix=\"/mcp\", tags=[\"mcp\"])\n\n@router.post(\"/run\")\nasync def mcp_run(\n    request: Request,\n    x_user_id: Optional[str] = Header(None, alias=\"X-User-Id\")\n):\n    \"\"\"\n    Direct endpoint for invoking the MCP agent orchestrator (run_mcp).\n    Accepts flexible input for query/prompt, plus optional files, topics, role, debug.\n    \"\"\"\n    data = await request.json()\n    # Accept a variety of possible input keys for maximum compatibility.\n    query = data.get(\"query\") or data.get(\"question\") or data.get(\"prompt\")\n    if not query:\n        raise HTTPException(status_code=422, detail=\"Missing 'query' in payload\")\n\n    # Use .get() with default empty list to prevent passing None if omitted.\n    files = data.get(\"files\", [])\n    topics = data.get(\"topics\", [])\n    role = data.get(\"role\", \"planner\")\n    debug = data.get(\"debug\", False)\n    user_id = x_user_id or \"anonymous\"\n\n    try:\n        return await run_mcp(\n            query=query,\n            files=files,\n            topics=topics,\n            role=role,\n            user_id=user_id,\n            debug=debug,\n        )\n    except Exception as e:\n        # Optionally add traceback.print_exc() for debug\n        raise HTTPException(status_code=500, detail=f\"MCP error: {str(e)}\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1694, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0300e3bc-6d7e-406e-a6bd-fb265f1f521f": {"__data__": {"id_": "0300e3bc-6d7e-406e-a6bd-fb265f1f521f", "embedding": null, "metadata": {"file_path": "/app/routes/oauth.py", "file_name": "oauth.py", "file_type": "text/x-python", "file_size": 4788, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a4024c57-c722-4f9b-8eda-17ce04be1d15", "node_type": "4", "metadata": {"file_path": "/app/routes/oauth.py", "file_name": "oauth.py", "file_type": "text/x-python", "file_size": 4788, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "33a093e0f2ee4942134cc366bf1d5f4bc9f146798971aed2fe6839e27bbed2a7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4315ed6f-6d93-4f56-bfd0-432b1ed6e8ca", "node_type": "1", "metadata": {}, "hash": "e4287cf2a1d5980944d5eac49002e55bb2ed99441820b1eb409710ccf2da811a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: routes/oauth.py\n# Directory: /routes\n# Purpose: Provide Google OAuth endpoints for both development (Codespaces) and production.\n# Supports dynamic and environment-overridden redirect URIs, robust logging, and token persistence.\n\nimport os\nimport base64\nfrom pathlib import Path\nfrom fastapi import APIRouter, Request, HTTPException\nfrom fastapi.responses import RedirectResponse\nfrom google_auth_oauthlib.flow import Flow, InstalledAppFlow\n\nrouter = APIRouter()\n\n# === OAuth Configuration ===\nSCOPES = [\n    \"https://www.googleapis.com/auth/drive.readonly\",\n    \"https://www.googleapis.com/auth/documents.readonly\",\n]\nCREDENTIALS_PATH = Path(\"/tmp/credentials.json\")\nTOKEN_PATH = Path(\"frontend/sync/token.json\")\n# Default post-auth landing page (relative path)\nDEFAULT_POST_REDIRECT = \"/status/summary\"\n# Optional overrides (full URIs)\nOVERRIDE_REDIRECT_URI = os.getenv(\"OAUTH_REDIRECT_URI\")\nOVERRIDE_POST_REDIRECT = os.getenv(\"POST_AUTH_REDIRECT_URI\")\n\n@router.get(\"/google/auth\")\nasync def start_oauth(request: Request):\n    \"\"\"\n    Initiates the OAuth flow:\n    1. Ensure client secrets in /tmp/credentials.json from GOOGLE_CREDS_JSON.\n    2. Determine redirect URI (override or based on request.base_url).\n    3. Redirect browser to Google consent screen.\n    \"\"\"\n    # 1. Write client secrets if missing\n    if not CREDENTIALS_PATH.exists():\n        raw = os.getenv(\"GOOGLE_CREDS_JSON\")\n        if not raw:\n            raise HTTPException(500, detail=\"Missing GOOGLE_CREDS_JSON environment variable.\")\n        try:\n            creds_json = base64.b64decode(raw).decode()\n            CREDENTIALS_PATH.write_text(creds_json)\n            print(f\"\u2705 Wrote client secrets to {CREDENTIALS_PATH}\")\n        except Exception as e:\n            raise HTTPException(500, detail=f\"Error decoding GOOGLE_CREDS_JSON: {e}\")\n\n    # 2. Determine redirect URI\n    if OVERRIDE_REDIRECT_URI:\n        redirect_uri = OVERRIDE_REDIRECT_URI\n        print(f\"\ud83d\udd27 Using override redirect URI: {redirect_uri}\")\n    else:\n        base = str(request.base_url).rstrip(\"/\")\n        redirect_uri = f\"{base}/google/callback\"\n        print(f\"\ud83d\udd27 Using dynamic redirect URI: {redirect_uri}\")\n\n    # 3. Create flow and authorization URL\n    flow = Flow.from_client_secrets_file(\n        str(CREDENTIALS_PATH),\n        scopes=SCOPES,\n        redirect_uri=redirect_uri,\n    )\n    auth_url, state = flow.authorization_url(\n        access_type=\"offline\",\n        include_granted_scopes=\"true\",\n        prompt=\"consent\"\n    )\n    print(f\"\ud83c\udf10 Redirecting to Google consent: {auth_url}\")\n    return RedirectResponse(auth_url)\n\n@router.get(\"/google/callback\")\nasync def oauth_callback(request: Request, code: str = None, state: str = None):\n    \"\"\"\n    Handles the OAuth callback:\n    1. Validate 'code'.\n    2. Exchange code for credentials using redirect URI.\n    3. Persist token.json.\n    4. Redirect to post-auth landing (relative path).\n    \"\"\"\n    if not code:\n        raise HTTPException(400, detail=\"Missing authorization code in callback.\")\n\n    if not CREDENTIALS_PATH.exists():\n        raise HTTPException(500, detail=\"Client secrets not found.\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3120, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4315ed6f-6d93-4f56-bfd0-432b1ed6e8ca": {"__data__": {"id_": "4315ed6f-6d93-4f56-bfd0-432b1ed6e8ca", "embedding": null, "metadata": {"file_path": "/app/routes/oauth.py", "file_name": "oauth.py", "file_type": "text/x-python", "file_size": 4788, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a4024c57-c722-4f9b-8eda-17ce04be1d15", "node_type": "4", "metadata": {"file_path": "/app/routes/oauth.py", "file_name": "oauth.py", "file_type": "text/x-python", "file_size": 4788, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "33a093e0f2ee4942134cc366bf1d5f4bc9f146798971aed2fe6839e27bbed2a7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0300e3bc-6d7e-406e-a6bd-fb265f1f521f", "node_type": "1", "metadata": {"file_path": "/app/routes/oauth.py", "file_name": "oauth.py", "file_type": "text/x-python", "file_size": 4788, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "c20dbb1b7892948fd26e826ab59e7d4fedfc9c51b11ca57cc751d10ca8f550d8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Validate 'code'.\n    2. Exchange code for credentials using redirect URI.\n    3. Persist token.json.\n    4. Redirect to post-auth landing (relative path).\n    \"\"\"\n    if not code:\n        raise HTTPException(400, detail=\"Missing authorization code in callback.\")\n\n    if not CREDENTIALS_PATH.exists():\n        raise HTTPException(500, detail=\"Client secrets not found.\")\n\n    # Determine redirect URI for token exchange\n    if OVERRIDE_REDIRECT_URI:\n        redirect_uri = OVERRIDE_REDIRECT_URI\n        print(f\"\ud83d\udd27 Exchanging token with override redirect URI: {redirect_uri}\")\n    else:\n        base = str(request.base_url).rstrip(\"/\")\n        redirect_uri = f\"{base}/google/callback\"\n        print(f\"\ud83d\udd27 Exchanging token with dynamic redirect URI: {redirect_uri}\")\n\n    # Exchange code for credentials\n    try:\n        flow = InstalledAppFlow.from_client_secrets_file(\n            str(CREDENTIALS_PATH),\n            scopes=SCOPES,\n            redirect_uri=redirect_uri,\n        )\n        flow.fetch_token(code=code)\n        creds = flow.credentials\n        print(f\"\u2705 Obtained credentials (expires: {creds.expiry})\")\n    except Exception as e:\n        print(f\"\u274c Token exchange failed: {e}\")\n        raise HTTPException(500, detail=f\"Token exchange failed: {e}\")\n\n    # Persist token.json\n    try:\n        TOKEN_PATH.parent.mkdir(parents=True, exist_ok=True)\n        TOKEN_PATH.write_text(creds.to_json())\n        print(f\"\u2705 Saved token.json to {TOKEN_PATH}\")\n    except Exception as e:\n        print(f\"\u274c Could not save token.json: {e}\")\n        raise HTTPException(500, detail=f\"Could not write token.json: {e}\")\n\n    # Redirect to post-auth page (use relative path to avoid port issues)\n    if OVERRIDE_POST_REDIRECT:\n        post_redirect = OVERRIDE_POST_REDIRECT\n        print(f\"\ud83d\udd04 Redirecting to override post-auth: {post_redirect}\")\n    else:\n        post_redirect = DEFAULT_POST_REDIRECT\n        print(f\"\ud83d\udd04 Redirecting to relative post-auth path: {post_redirect}\")\n    return RedirectResponse(post_redirect)", "mimetype": "text/plain", "start_char_idx": 2750, "end_char_idx": 4756, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "13f0c1d0-d581-48eb-85b5-04c291fad720": {"__data__": {"id_": "13f0c1d0-d581-48eb-85b5-04c291fad720", "embedding": null, "metadata": {"file_path": "/app/routes/search.py", "file_name": "search.py", "file_type": "text/x-python", "file_size": 2750, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f72281f2-9b23-49b2-b048-17227125f7e0", "node_type": "4", "metadata": {"file_path": "/app/routes/search.py", "file_name": "search.py", "file_type": "text/x-python", "file_size": 2750, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "36e49c7fcd560cc1bfea9a46dff88d2f8ff4cc3fbbcb4c44f11a796dad22314e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: search.py\n# Directory: routes/\n# Purpose: Secure semantic KB search endpoint (GET /kb/search)\n# Notes:\n#   \u2022 Accepts canonical `query` param (alias `q` for legacy clients).\n#   \u2022 CORS\u2011safe: OPTIONS pre\u2011flight bypasses API\u2011key auth.\n#   \u2022 Casts similarity to `float` so FastAPI JSON serialisation never 500s.\n#   \u2022 Returns plain list consumed by SearchPanel.\n# Last Updated: 2025\u201106\u201113\n\nfrom __future__ import annotations\n\nimport os\nimport logging\nfrom typing import List, Optional\n\nfrom fastapi import APIRouter, Depends, HTTPException, Query, Request\n\nfrom services import kb\n\nlogger = logging.getLogger(__name__)\nrouter = APIRouter(prefix=\"/kb\", tags=[\"kb-search\"])\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# Auth helper\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n\ndef require_api_key(request: Request) -> None:\n    \"\"\"Simple header check. OPTIONS (CORS pre-flight) bypasses auth.\"\"\"\n    if request.method == \"OPTIONS\":\n        return  # allow browser pre-flight\n\n    if request.headers.get(\"x-api-key\") != os.getenv(\"API_KEY\"):\n        raise HTTPException(status_code=401, detail=\"Invalid API key\")\n\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# Routes\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n\n@router.get(\n    \"/search\",\n    dependencies=[Depends(require_api_key)],\n    summary=\"Semantic KB search\",\n)\ndef search(\n    query: Optional[str] = Query(None, alias=\"query\", description=\"Search string\"),\n    q: Optional[str] = Query(None, description=\"Legacy alias for query\"),\n    k: int = Query(5, ge=1, le=20, description=\"Top\u2011K results\"),\n) -> List[dict]:\n    \"\"\"Proxy to `services.kb.api_search`. Returns a JSON\u2011serialisable list.\"\"\"\n    term = (query or q or \"\").strip()\n    if not term:\n        raise HTTPException(status_code=400, detail=\"Missing query parameter\")\n\n    try:\n        raw = kb.api_search(term, k=k)\n        safe = [\n            {\n                \"path\": r[\"path\"],\n                \"title\": r[\"title\"],\n                \"snippet\": r[\"snippet\"],\n                \"updated\": r[\"updated\"],\n                \"similarity\": float(r[\"similarity\"]),\n            }\n            for r in raw\n        ]\n        return safe\n    except Exception as exc:\n        logger.exception(\"KB search failed for %r\", term)\n        raise HTTPException(status_code=500, detail=\"KB backend error\") from exc", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2343, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b240fd01-4306-48b1-bf59-0a7139afdea9": {"__data__": {"id_": "b240fd01-4306-48b1-bf59-0a7139afdea9", "embedding": null, "metadata": {"file_path": "/app/routes/status.py", "file_name": "status.py", "file_type": "text/x-python", "file_size": 3986, "creation_date": "2025-06-29", "last_modified_date": "2025-06-29", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0bb7f586-e48e-49ba-a87e-f970df9d294f", "node_type": "4", "metadata": {"file_path": "/app/routes/status.py", "file_name": "status.py", "file_type": "text/x-python", "file_size": 3986, "creation_date": "2025-06-29", "last_modified_date": "2025-06-29", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "5f67991ed1fc8aea42bf2f34d557b96ee9e9b2c2812b9c37bf1731666a3cff92", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: routes/status.py\r\n# Directory: routes/\r\n# Purpose: Health, environment, version, and context awareness endpoints for Relay service.\r\n# Security: Public (no auth; consider protecting `/env` or `/summary` in production).\r\n\r\nfrom fastapi import APIRouter\r\nfrom pathlib import Path\r\nimport os\r\nfrom subprocess import check_output, CalledProcessError\r\nfrom datetime import datetime\r\n\r\nrouter = APIRouter(prefix=\"/status\", tags=[\"status\"])\r\n\r\n@router.get(\"/paths\")\r\ndef get_status_paths():\r\n    \"\"\"\r\n    Returns existence of major source code/data directories for debugging.\r\n    \"\"\"\r\n    env_root = os.getenv(\"RELAY_PROJECT_ROOT\")\r\n    base = Path(env_root).resolve() if env_root else Path.cwd()\r\n\r\n    roots = [\r\n        \"services\",\r\n        \"frontend/src/app\",\r\n        \"frontend/src/components\",\r\n        \"routes\",\r\n        \".\"\r\n    ]\r\n\r\n    visible = {}\r\n    for r in roots:\r\n        path = base / r\r\n        visible[r] = path.exists()\r\n\r\n    return {\r\n        \"base_path\": str(base),\r\n        \"resolved_paths\": visible\r\n    }\r\n\r\n@router.get(\"/env\")\r\ndef get_env_status():\r\n    \"\"\"\r\n    Returns selected environment variable statuses (partially masked for safety).\r\n    \"\"\"\r\n    keys = [\"OPENAI_API_KEY\", \"API_KEY\", \"RELAY_PROJECT_ROOT\", \"RAILWAY_URL\"]\r\n    values = {\r\n        k: os.getenv(k)[:5] + \"...\" if os.getenv(k) else None\r\n        for k in keys\r\n    }\r\n    return values\r\n\r\n@router.get(\"/version\")\r\ndef get_version():\r\n    \"\"\"\r\n    Returns current Git commit short hash.\r\n    \"\"\"\r\nfrom subprocess import check_output, CalledProcessError, DEVNULL\r\n\r\n@router.get(\"/version\")\r\ndef get_version():\r\n    \"\"\"\r\n    Returns current Git commit short hash.\r\n    \"\"\"\r\n    try:\r\n        commit = check_output([\"git\", \"rev-parse\", \"--short\", \"HEAD\"], stderr=DEVNULL).decode().strip()\r\n    except Exception:\r\n        commit = \"unknown\"\r\n    return {\"git_commit\": commit}\r\n\r\n\r\n@router.get(\"/summary\")\r\ndef get_summary():\r\n    \"\"\"\r\n    Returns a bundle of status: paths, env, and version.\r\n    \"\"\"\r\n    return {\r\n        \"paths\": get_status_paths(),\r\n        \"env\": get_env_status(),\r\n        \"version\": get_version()\r\n    }\r\n\r\ndef list_context_inventory(\r\n    base: Path, \r\n    roots = [\"docs\", \"context\"], \r\n    exts = [\".md\", \".txt\"]\r\n):\r\n    \"\"\"\r\n    Helper: Returns a list of context file metadata from all roots.\r\n    \"\"\"\r\n    inventory = []\r\n    for root in roots:\r\n        folder = base / root\r\n        if not folder.exists():\r\n            continue\r\n        for f in folder.rglob(\"*\"):\r\n            if f.is_file() and f.suffix in exts:\r\n                inventory.append({\r\n                    \"path\": str(f.relative_to(base)),\r\n                    \"size_bytes\": f.stat().st_size,\r\n                    \"last_modified\": datetime.utcfromtimestamp(f.stat().st_mtime).isoformat() + \"Z\"\r\n                })\r\n    return inventory\r\n\r\n@router.get(\"/context\")\r\ndef get_context_status():\r\n    \"\"\"\r\n    Returns details about all global context and overlays:\r\n    - All context files with metadata (from /docs, /context)\r\n    - Which global_context (manual or auto) is active\r\n    - Last updated timestamps\r\n    \"\"\"\r\n    env_root = os.getenv(\"RELAY_PROJECT_ROOT\")\r\n    base = Path(env_root).resolve() if env_root else Path.cwd()\r\n    global_manual = base / \"docs/generated/global_context.md\"\r\n    global_auto = base / \"docs/generated/global_context.auto.md\"\r\n\r\n    def fmt_time(path):\r\n        return datetime.utcfromtimestamp(path.stat().st_mtime).isoformat() + \"Z\" if path.exists() else \"missing\"\r\n\r\n    files = list_context_inventory(base)\r\n    files_sorted = sorted(files, key=lambda x: x[\"path\"])\r\n\r\n    return {\r\n        \"context_files\": files_sorted,\r\n        \"global_context_used\": \"manual\" if global_manual.exists() else \"auto\" if global_auto.exists() else \"none\",\r\n        \"global_context_manual_last_updated\": fmt_time(global_manual),\r\n        \"global_context_auto_last_updated\": fmt_time(global_auto),\r\n        \"file_count\": len(files_sorted),\r\n        \"root\": str(base)\r\n    }", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3984, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d4b8ec1d-afcc-4a0f-b3cb-a663c9ba07f3": {"__data__": {"id_": "d4b8ec1d-afcc-4a0f-b3cb-a663c9ba07f3", "embedding": null, "metadata": {"file_path": "/app/routes/status_code.py", "file_name": "status_code.py", "file_type": "text/x-python", "file_size": 1548, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a6af3722-6c3b-441d-ac6c-75944529afe7", "node_type": "4", "metadata": {"file_path": "/app/routes/status_code.py", "file_name": "status_code.py", "file_type": "text/x-python", "file_size": 1548, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "e38d8e710998fe04d083000a3e353668c03ffb6003b33dc8fa93d81f144a4137", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# File: routes/status_code.py\n# Purpose: Provide detailed insights into Relay source files, functions, usage, and freshness.\n\nfrom fastapi import APIRouter\nfrom pathlib import Path\nimport os, ast\nfrom datetime import datetime\n\nrouter = APIRouter(prefix=\"/status\", tags=[\"status\"])\n\nCODE_PATHS = [\n    (\"services/context_injector.py\", \"core\"),\n    (\"services/indexer.py\", \"core\"),\n    (\"routes/ask.py\", \"core\"),\n    (\"routes/admin_routes.py\", \"core\"),\n    (\"routes/status.py\", \"support\"),\n    (\"scripts/sync_context_docs.py\", \"support\"),\n    (\"scripts/generate_global_context.auto.py\", \"support\"),\n    (\"main.py\", \"entrypoint\")\n]\n\n# Extract function names from a file using AST\ndef extract_functions(path: Path) -> list:\n    try:\n        tree = ast.parse(path.read_text())\n        return [node.name for node in ast.walk(tree) if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef))]\n    except Exception:\n        return []\n\n@router.get(\"/code\")\ndef get_code_status():\n    results = []\n    for rel_path, tag in CODE_PATHS:\n        path = Path(rel_path)\n        if not path.exists():\n            results.append({\"file\": rel_path, \"status\": \"\u274c Missing\", \"tag\": tag})\n            continue\n\n        functions = extract_functions(path)\n        modified = datetime.utcfromtimestamp(path.stat().st_mtime).isoformat() + \"Z\"\n        results.append({\n            \"file\": rel_path,\n            \"status\": \"\u2705 OK\",\n            \"tag\": tag,\n            \"functions\": functions,\n            \"last_modified\": modified\n        })\n\n    return {\"files\": results}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1543, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0f7496f4-e9cf-46d1-8666-84664a886a79": {"__data__": {"id_": "0f7496f4-e9cf-46d1-8666-84664a886a79", "embedding": null, "metadata": {"file_path": "/app/routes/webhook.py", "file_name": "webhook.py", "file_type": "text/x-python", "file_size": 0, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d885c313-e146-4f85-b967-2c7c5d088fef", "node_type": "4", "metadata": {"file_path": "/app/routes/webhook.py", "file_name": "webhook.py", "file_type": "text/x-python", "file_size": 0, "creation_date": "2025-06-27", "last_modified_date": "2025-06-27", "tier": "code", "document_title": "Global Project Context Overview and Future Plans: Leveraging Next.js, FastAPI, and GPT-4o for AI-Enabled Collaboration and Coordination across Regions and Time Zones"}, "hash": "212386a909a24a68047b7661256c75066b5c116dd54d8baa976259be863e26e7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 0, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"14f65c6d-c5b1-4b1f-b1e4-26258b42f6d7": {"doc_hash": "8c4ce573e08c22c85ffb0d0228adeec3a38ede49fd041cb0430ad4ab694d2dfb", "ref_doc_id": "e5efd9bb-a805-4b5c-a100-d1392d256f8f"}, "91528f11-0ed2-49d3-b5da-1e1b630f8388": {"doc_hash": "c226db5e073ea14db6586b9ef3e56da1aa277e8f9e0061cf9c38831efc63488b", "ref_doc_id": "98bf680b-f373-4726-8a44-1c3164beb546"}, "71fd5e87-f0af-47de-9eaf-e7c746755676": {"doc_hash": "80018d6b5adc2031a22fabc9962bc11bf033a3df1348bb6cdde3b9f1ebc9e4e9", "ref_doc_id": "70d7a252-e285-453b-a42c-c0b6c60ae7a2"}, "df242dce-083a-4c83-bacc-66420b5f4941": {"doc_hash": "dd626fd7ad348221ef8f1ac15a9b619c687ce920c4a94d9fbe4e5333c2543a00", "ref_doc_id": "ede8dcfa-1809-4e28-a83f-ea01166d4f5a"}, "af1348d7-dafe-4b9c-b1c3-741d82c9dc1a": {"doc_hash": "e8a403eda54b47511aaca46e98bd432a645f3841a57a56bdc43ae4c0c53d5fed", "ref_doc_id": "89382837-662b-4520-b66b-a2c9c78eccb5"}, "a45f5cca-c770-48de-944e-21946c4e54c6": {"doc_hash": "93cfc7d52a998a565e8b71fea69a6d8ef2493c4c1c905acc2e21be700e304403", "ref_doc_id": "89382837-662b-4520-b66b-a2c9c78eccb5"}, "735c5632-2eef-4267-9f01-d844c9b3b5b4": {"doc_hash": "acf03ab454b29fff7905fac03510c07f56773975894db94242ea5c125724b298", "ref_doc_id": "0c5bffea-629f-41a4-98aa-62251d0a9904"}, "72c154dd-bd22-44d6-8548-502f450f53b2": {"doc_hash": "1a3cc7ac6a0c27fc32f821ba4a4dc76e7d208d14a5fc18aeecc54ffa05d53edb", "ref_doc_id": "61560e80-1b0c-48b7-837c-d00a6483902c"}, "3b22dafb-6cb3-414f-8e41-9b32debdb0b0": {"doc_hash": "82d88423fdaf45fd4d7a8745b9a03589a930aabc739d508234654af510550503", "ref_doc_id": "61560e80-1b0c-48b7-837c-d00a6483902c"}, "c4f918e2-abb0-4d87-8024-3abdafb9d222": {"doc_hash": "ef198da6c7c4271d7eed0947d81dc0ad2907d1915081f2628ce878f7cb1e59cf", "ref_doc_id": "61560e80-1b0c-48b7-837c-d00a6483902c"}, "6a3302e9-260f-47df-b87f-7b7ba002a0b7": {"doc_hash": "bdec31fd92aa335468936320415a3fd0c6fa4ef46841eb3a768d112bcaf7bab1", "ref_doc_id": "a4fae8b6-ccef-469c-b9fa-81a9ada5221c"}, "0396bf68-47e3-4645-b9ad-86d41ed947ee": {"doc_hash": "c52c02965a0e9dcf601a27d6bf0ff514b13efe1c58aa8c0a182bfcc25cb357a0", "ref_doc_id": "ce8dd2aa-4aca-4a2d-bfd4-ecd95dd6534b"}, "d7aee2c7-6a7a-49b1-8bad-90a31384ed21": {"doc_hash": "014834f1547ac0e89a5a2ec2825dcc0e9c25c228ed0e789e7bd2b219d49affe0", "ref_doc_id": "1afc5ca0-4c7b-480a-9dd2-51727be5e050"}, "0214fbe3-c1ac-4690-a528-7a5d9e10594f": {"doc_hash": "968c9ac8064174f443350cf95ffa84c0ff24b7f12abf333cdf4795ac243a4688", "ref_doc_id": "7abf54dc-8e4b-4450-a843-80baa48ff48d"}, "266592df-d32c-4574-b809-453b78331782": {"doc_hash": "a03df621db3be30721db470651e26839535faa35a29bbfe5afff58455f905e6e", "ref_doc_id": "538826c7-a4f6-4df5-ae99-73f5e50bb87c"}, "2c111119-5b15-478d-98d1-90b94cb8b263": {"doc_hash": "b1faa73dcc0d1ca7fe84a4eab0d04b8cd3db2003e9096c2a1caecefd9b5d03c0", "ref_doc_id": "3818a848-5c42-489d-a6d2-1d25329bbf48"}, "55f227b3-cf30-4a32-9876-61f7aad6c659": {"doc_hash": "d2e9747eafd44c1648e8a849ff38e00ad939623db5aa3528814b168bebbeb1d7", "ref_doc_id": "30ea6c55-ffa0-44b0-a5e3-618525cc661f"}, "9f8cef8f-3aa5-4a12-b248-851f2ba670a1": {"doc_hash": "2b27a59039f5194dee62e2567955413da063fe1c1889a35b83e9d17070b1a0e8", "ref_doc_id": "0d494dc8-7d07-4c44-801e-d86762f915a2"}, "a21b51f9-d1f2-43f1-8b24-28ecedf723fc": {"doc_hash": "24a008081c36b6c702721c79d85c6350f124f317ab58914238e4985d1d14e35f", "ref_doc_id": "56d5a150-2b90-4300-b501-9725759db856"}, "c19dadd7-258c-4d87-b394-681a39aebac2": {"doc_hash": "813c3fa488e4cde0ea54e0e8f93dec42d879b5f29adc99d75dad857b290736a3", "ref_doc_id": "0307c0df-1e29-4696-8d03-e196b7e67638"}, "86275b3f-d56e-4714-9817-48fcde921c58": {"doc_hash": "95bc91c1a36933a85570416a83bd0a930b03f53e85756286ba45675b5bd53f3f", "ref_doc_id": "43a338b7-920a-4c9a-a700-092e1dfdd77f"}, "21026d6e-054f-4bd7-8039-f58dd0ecc07d": {"doc_hash": "0e217709abbb11afd46ed084ad7c83d43c508e75cc4e67a401d07c03a85a9d2f", "ref_doc_id": "cf0a1220-6211-45fa-924e-e5ad10012b0a"}, "50a43997-5821-404a-8fb7-1f5d9754d2b9": {"doc_hash": "4726cb6a70c71484036c2f2165283b7fd2eb3c4278dab0f0ab8bb80281b18776", "ref_doc_id": "9c13ef1d-7370-4e01-9b40-f1c9ae69a010"}, "1ee72952-cc6b-4f42-935d-1c818f435999": {"doc_hash": "7cd2c5efa5d8a2bb0212d45f6547241c0cd0977636615a4ad03cb355a8b4b30f", "ref_doc_id": "9c13ef1d-7370-4e01-9b40-f1c9ae69a010"}, "b6f8c778-ce5f-4381-875b-56fd57d7d3c6": {"doc_hash": "072f0414dc8a490f9e5a1ae2fee355a7f9972af9d230db918957a2772033957e", "ref_doc_id": "b7b0b669-7e2e-4c36-bb02-b63d4ab74bc1"}, "169d6cd7-1764-4a73-8087-a2489c879090": {"doc_hash": "d4a11bbb2555a645533b2dc5fe27da4e93fa76eedc3bbd72903bf06308d39651", "ref_doc_id": "0f0c8f2d-d9a2-4d17-971f-10b704acebfa"}, "9ff60f9e-9fb9-4443-96b9-ad4d016a0c75": {"doc_hash": "6263f45007c510887dc065341cfc8ba4043653bb10e982d9c317257ea353ac08", "ref_doc_id": "084fd30d-cb52-42a1-96a1-8dfbdf044117"}, "a02055be-f10d-4d4a-ba5f-aaba1cdb9a4d": {"doc_hash": "fdc712e106900995e9296714fc309fad69203935f29afe26efc7d73e19183a21", "ref_doc_id": "79388ba0-f2e0-4d4d-9d06-c0fcfcc9693c"}, "80f9cb49-d9a3-47c4-8bc6-23531d4561de": {"doc_hash": "49a0bfa932a24f10a12e7a1fb90a6f29bbecdd588de97eb438b7dcf4d031579d", "ref_doc_id": "72a7d590-6854-46a3-81dd-1fe3c2a66dd2"}, "168ba6fe-c97e-4277-b311-ef14f3708261": {"doc_hash": "c4d33b20c318f2153138023860cfd3338f33e4c1cb0f034fd9492c9fee4fc507", "ref_doc_id": "bd8404cc-a24b-4070-bfba-aaf44f3b1c25"}, "2b52d66a-71c7-4892-b9c1-e5d6c53acff9": {"doc_hash": "46ef91067ad08971c0621ea4a2c906f520cafa0cd63fd663f650537ddbd5fdad", "ref_doc_id": "b3b15f81-73e1-4060-89ce-b7889cdc75b8"}, "25d92bbf-5613-483c-ba02-fc330476fbad": {"doc_hash": "3e4a4c09fcf8fed446971a8a64626d90aed777e13e4fd043f547f31ea75dc37e", "ref_doc_id": "f8b3b48d-520d-4795-87a7-ad007a31be3d"}, "ffd9b4bc-b29e-4ac7-a5c2-4accf1a8a6d0": {"doc_hash": "1c518d9a27042c02898300a00b841ae319b6ce27ae9c8bda3a8f107fd9348007", "ref_doc_id": "799e5c43-9902-4e43-be76-114a338d915a"}, "1a01ca20-d51c-4323-8003-178197279757": {"doc_hash": "1151f04c58893fb352a3def393bc4cbed80a17358b6d6c660902085bf57524ce", "ref_doc_id": "0d9492d0-368b-4d83-841d-9dbf1f0ec05a"}, "97b597d8-b8c7-4da6-9750-3aae1f481788": {"doc_hash": "e791f138ff31bd3fa5dc584fe1eca180bbef82fcb7a138429da45314c7ac842e", "ref_doc_id": "db5ec47e-45bc-4a07-aed9-aa600aa420e0"}, "83b68592-9154-4fa9-8b24-ddf74037695b": {"doc_hash": "d9ba62b5c10d0d91b338162ffddded8f2787162539afc2b7e4fd6b74ce596183", "ref_doc_id": "ff46f666-a791-4054-b5a3-427bcc10fad8"}, "dfe8c128-0999-4355-9c64-c06cf45cb4b6": {"doc_hash": "d394638e4301c094dae1fff3f859810e2309a396c83ff56bb4bd47e1e56474a2", "ref_doc_id": "ff46f666-a791-4054-b5a3-427bcc10fad8"}, "81b6ddca-d136-40de-8fac-3957ac39b391": {"doc_hash": "b58c447deecc2a6cb1beb13d20b451919f14356fb992f2aa61e576be1db039a4", "ref_doc_id": "ff46f666-a791-4054-b5a3-427bcc10fad8"}, "3218b662-4297-472b-820a-57e402a0495b": {"doc_hash": "8ec0e781fe76fc0b0f777d9f44398f3d8324c78ffa3683dde6489648ed66a1f4", "ref_doc_id": "ff46f666-a791-4054-b5a3-427bcc10fad8"}, "5a0289f4-6019-4bf7-8327-9bb50aebfd55": {"doc_hash": "a490c1030298b899360eb865e0d09667a0e1a5b70199eb5da81ba6df0747fc38", "ref_doc_id": "9d161425-b64a-45c6-a03e-fc42d622814e"}, "df5f57c9-ffa8-4ecc-a2af-ccad2855d00c": {"doc_hash": "35ba8fe7b6384557df5016f1ee9aeaee8f946dcbfedb9fc9a19bcc12106db430", "ref_doc_id": "3eafdc2e-75e9-49c8-8bc3-d517186c369b"}, "675fef89-ecfe-45c4-98e7-fcf80449f3be": {"doc_hash": "67c8ef47904c90acaf8b501c1a7b29ceb2f241cf3108f7eb09ae202543afefee", "ref_doc_id": "d8e830eb-78b8-46ce-b5c5-fdad03186e2a"}, "1a54d072-d80b-4e68-a9f2-0fd5a17c2185": {"doc_hash": "dfac0dbafef689b42bb7ebb845816efd13dfc6eccbaafee09b9001b8f2a510e9", "ref_doc_id": "21bb60dc-2ddc-433f-909a-df6d6cd7fe8b"}, "d833d335-b802-46b7-9b92-565823cf6e3a": {"doc_hash": "c152f4a7cdd466fe35616c757c4d247280cd9ea3b19c4861cb65720486665781", "ref_doc_id": "b96e5856-0579-45a4-bb2d-fe1a6415db66"}, "7151be5b-5504-45ba-8071-ed4658f816f4": {"doc_hash": "39bdb31cad1523e06e75ac0945083df2e26e781d9b2d6cfa8fe6aa6be5dcd5c7", "ref_doc_id": "b96e5856-0579-45a4-bb2d-fe1a6415db66"}, "507c082f-4284-4889-84a4-6cea0ae01d1a": {"doc_hash": "cc0f92652b2c031fe9ff807828dffa3c3d8d3a809ce18aa4a846abdf8bc5545d", "ref_doc_id": "4c35eb16-b549-439c-9138-dcbe2dca99c0"}, "92b71366-6182-4452-9371-72eff4fce54a": {"doc_hash": "db3616ff6b67f0e512e2ff520be8bd78a7dd6b03842ffb5f64508ca9969adb38", "ref_doc_id": "4c35eb16-b549-439c-9138-dcbe2dca99c0"}, "83084774-e814-4af2-9f7c-82382d96fec6": {"doc_hash": "dfe8ff0252c41c7398be26975ca5e780d114f2208c9773d667ed7828d03563f7", "ref_doc_id": "4c35eb16-b549-439c-9138-dcbe2dca99c0"}, "0760576a-0de7-420e-b981-724ffe2446fa": {"doc_hash": "46e38c6771b35019a1b27ab3123b71e6b077e324df71f97609dad89de98cc3e7", "ref_doc_id": "4c35eb16-b549-439c-9138-dcbe2dca99c0"}, "6f388a35-5a14-4ecc-9238-0c22a65d89ab": {"doc_hash": "9f9867598857a881ffd6072106361abe3c7ac851fda5e92e24a06e52ee9d7d2c", "ref_doc_id": "4c35eb16-b549-439c-9138-dcbe2dca99c0"}, "cd5ff8b5-cd7e-4804-82ea-16ee49dd56d1": {"doc_hash": "122dc80ff06e479b4d89f78393078a0f3547217621f6dddd6a1fb0566584db96", "ref_doc_id": "3e243e36-20c9-4ecd-8b9b-cffb62d32eb6"}, "7c4bede4-75ae-457f-a157-3ff01b6d6282": {"doc_hash": "6ed2b7d03cdc9926ab509f2b7d9ddd272574dcd1d78c9b401d37128d787f0171", "ref_doc_id": "a24b5ce2-14d6-49a9-8ebb-c0f3d828830e"}, "31b283cb-c9c1-48f7-ba3a-4ec0fab1020f": {"doc_hash": "035901be8c7b6b533fc5471ada2c97e870b7de7ee8dde7118aba6825ec871aee", "ref_doc_id": "5c2d9799-5099-4430-9244-b3e62272fe40"}, "1a4f8f48-9a4f-4fd0-b9b9-6fea3a3780f3": {"doc_hash": "9ecd3c53eb21e9eefb014bec38511793c149c2a7b3893022b11593b6f8f99a52", "ref_doc_id": "37ac9e21-28d5-4e6c-8632-187cec50ef3b"}, "877860cb-6eb5-4f1a-a141-0e17af9b763f": {"doc_hash": "c567d836c5a4f8c9974ac0ec85ac42db01343ad69b755b30f1c36224a7215dbc", "ref_doc_id": "b4c7cdf6-3d8f-421a-ad1e-e02af1abdb9b"}, "26c90ccc-285c-47f4-8666-51aabf6550dd": {"doc_hash": "923857c6a857e8ed0ffe2928a06c6e1ff4e10f7fdc0a1bdaed69c699822a92a7", "ref_doc_id": "d44bd992-6ce4-40f7-ae55-7b28865993ab"}, "11682fed-6d09-48b0-86e0-5a1dde7b4733": {"doc_hash": "8c868587a6cf362861b2c89f137b3b0b64399a0eef33529cbe6df682ee676d50", "ref_doc_id": "d44bd992-6ce4-40f7-ae55-7b28865993ab"}, "d1c4300f-73ed-49bd-be00-ba6a0e0a18f7": {"doc_hash": "ccb0aa7737c229fbbd8a1451398cb2cc45d01fd3a0f5c71133dac6efa65e8759", "ref_doc_id": "23799d7c-22c2-480e-ae05-ff4ec90a60e5"}, "61d504e1-9a69-4c1c-88a1-a952e3e9e59c": {"doc_hash": "4b61977fcd4169228d6cae49024eb07fea563616ea61d1e32535379434793e57", "ref_doc_id": "23799d7c-22c2-480e-ae05-ff4ec90a60e5"}, "1b1ef0a5-8ca0-4c55-9fad-ec209b4db9dd": {"doc_hash": "3e2f9414ca44754db4fce3750582fb1062901d7d18052ba1d249f042811074a5", "ref_doc_id": "23799d7c-22c2-480e-ae05-ff4ec90a60e5"}, "fed6c76e-7e0c-4e4c-8dc2-6e48f4df0e2f": {"doc_hash": "c718a64f4fb362cd099b51ddd08e4f2edbeb9a003368fbd4a413257c132a01f8", "ref_doc_id": "0266c43c-8f5d-47fa-9597-4d31d98e5c50"}, "14ab5de3-8e58-47f3-9063-fce033c5b9da": {"doc_hash": "5236edbd3c57cfed57380870f711b960146ee508134f2e5940e2e1f5b0372b36", "ref_doc_id": "f9372f71-cf56-4421-b94b-ba81ef2c132c"}, "70f2aa1c-d8c2-45dd-9f59-f7ca7088654b": {"doc_hash": "bb20a55ecb0fc483840cb5b7fe4cc9e2148a72df71f0d7be133c2b19d07c549c", "ref_doc_id": "f9372f71-cf56-4421-b94b-ba81ef2c132c"}, "724a395a-dc03-412b-9572-e697902c6a5c": {"doc_hash": "de92d8e8d654a86518f3e7e0fc99fad7e881801b3cddf18c885cee17b83d8965", "ref_doc_id": "f9372f71-cf56-4421-b94b-ba81ef2c132c"}, "2477c90a-7e6a-4ffc-81f9-8942ab49f8e9": {"doc_hash": "3622b4df3634cf0197e81f38ecdda96cc98e173b54528ab029f6555f7e72e75b", "ref_doc_id": "1ea75db3-ccf0-490f-9fa0-7f528c129dc2"}, "82d59c41-dafb-4aae-abd0-88f8cd260700": {"doc_hash": "299e090a7f3db222dada8eed9a2363d588ca65ac1951bb44cad231c469c466e3", "ref_doc_id": "1ea75db3-ccf0-490f-9fa0-7f528c129dc2"}, "cdce9102-8e6a-4cfc-aa04-258a04a71219": {"doc_hash": "6a6fbccea1f6acb240bc85f3c58fdfd45e640aebfb5d6d12ae6a841abcfa3741", "ref_doc_id": "1ea75db3-ccf0-490f-9fa0-7f528c129dc2"}, "4e6a7fcb-5ccd-4ef6-83b6-ce73a987e15a": {"doc_hash": "9543e51d607cc91e09b8550d78691b41304c1e1c4e6698db065ff68d91fc3a22", "ref_doc_id": "1ea75db3-ccf0-490f-9fa0-7f528c129dc2"}, "77f18924-adc5-47c4-bc6b-2a5ec6aeffde": {"doc_hash": "e7897a4d56aecb905a21925ebd8feca5c94930d718c0400cee5cb67bce1eca1b", "ref_doc_id": "1ea75db3-ccf0-490f-9fa0-7f528c129dc2"}, "f8b64aea-132c-40b4-b925-d7753a67d6c2": {"doc_hash": "4966380086612bdeda3fbb7ce5ebed7f023a9f7794dd2b912017de8c9b632a05", "ref_doc_id": "5643dab0-45f8-4c41-b78a-fca414a354c6"}, "89e003f8-e791-4464-9ffa-6eacebdb5f94": {"doc_hash": "883cf1c918b33adddbc09de4759f2dd8093f8057264d14ad4f09cd60e02ff192", "ref_doc_id": "98fdd749-5a87-4246-9e2d-b9c2f7997d58"}, "11b7e9a9-11fd-4f96-acf4-4939c974ac2f": {"doc_hash": "b5ee2bda24adf120e6d81bfb814f751ef03f948f2943f40cfb0d8b59e188eadf", "ref_doc_id": "ac2489c1-6d3a-4391-90f3-5db4c484f169"}, "a1a25284-7106-470a-949c-50839f94ab3c": {"doc_hash": "8c3462d94f326806f162e05c0920989eeb4322c91526a1b6589e0570d3ce0e32", "ref_doc_id": "ac2489c1-6d3a-4391-90f3-5db4c484f169"}, "124435f4-5701-402d-862a-47a47217a8ac": {"doc_hash": "c64378b4fe770c0e5f8016f8095bf7f672b584d1bf6ef5a4eb0d01d86c468e6d", "ref_doc_id": "26c218d2-3074-4e2a-9772-4bd6ae4dc5fb"}, "0b4412da-676c-476f-94af-df70d44f29de": {"doc_hash": "0cbdcece89101fb45c468a0104e315e61dc25dcae657501ab14a7c8137b5043a", "ref_doc_id": "d7df79dc-de66-4319-8914-e9b72e5df240"}, "e2044897-6135-4bfa-b4fe-ea03cd6c9922": {"doc_hash": "52c4f0aa09ed720f91f0f99f65160eeb4051bcdfde9f030b9ea198d0b1fdacf6", "ref_doc_id": "d7df79dc-de66-4319-8914-e9b72e5df240"}, "d72cc094-ebab-44f8-81db-92b574bd3244": {"doc_hash": "fcd496ede12cfeaff8f4308bc1ddbf150168cb892f3a98189a9c57be4a922294", "ref_doc_id": "433ab2a3-5ecf-409e-ac00-682d56a21a64"}, "49d0e78b-8af4-4c08-b32e-2c5e2a51572b": {"doc_hash": "a6a510d71d944021baa4c62dbeaa54ce921e725972dca249fc80893a5ee48985", "ref_doc_id": "bfcafffd-c14c-49e3-bc43-7fd2a57124b3"}, "ebaa16d1-8c31-457e-90b6-e912c8414fde": {"doc_hash": "4506d9b1748bce38f5e2b2b44a13f36e71d4f9670c750b2dfd197667570a0b1e", "ref_doc_id": "66032114-aa83-410c-a4ea-b13cd1ac8f08"}, "4e253827-2c05-4c0b-91ce-82f9db3e36d6": {"doc_hash": "a4034384fe07001a05fc18424999ce0027701e9bce0adb6de16c05c6ce214577", "ref_doc_id": "1b5114c6-13e2-4479-946d-d8e868c8fc43"}, "cfc672c9-0db9-4c2b-ae02-3b017d00f511": {"doc_hash": "3f952f7f53a00afd4937855df1fa1aa69494737dbe6124a9d98c44bc975ca873", "ref_doc_id": "591b4637-9116-4e8b-83c3-154868eee270"}, "a5bc80a9-1439-4160-876c-624bb21367a3": {"doc_hash": "dc441e1885f613ae54a2a5405be8acf47beb46ee5ed24a4c132b8d552f4a6358", "ref_doc_id": "8c1db525-1b5d-4ce2-90ff-e70cfe87c4a1"}, "307a6ef7-2e63-41f0-9662-7ac9e0289bcb": {"doc_hash": "0912b55dd4afc7b2a18462951d9c028282d5be6f49db6b16e4aae242f20d33df", "ref_doc_id": "4fa9bee7-0cf6-4ec6-a89d-eb255aaeb26e"}, "d0348d51-019a-4f99-a9c8-5f4c1698aef5": {"doc_hash": "938d669d886f452a47e63452721b693be6d0283872ce330aa247a2bdd04150aa", "ref_doc_id": "00ff82b5-d559-4ef4-8119-3deb2f8f9feb"}, "696a9378-9277-4319-8067-5185c013aced": {"doc_hash": "9ff799155b40b2386c306ad49b01371067a12bf5a57b760f4e3076dcb9233884", "ref_doc_id": "412d6596-d33d-4645-9608-c6dea466fa43"}, "60bc89f8-d107-4216-99f7-5a3ed3c69400": {"doc_hash": "24cfb42effd162400a56e9b2f424adb16327fd7ecba0464acb02b89d00a5d348", "ref_doc_id": "1aba31d0-7e4c-4c00-92dd-8e52e83b03ba"}, "2bb0b62f-efc2-42fa-835f-c4f9bd4e307e": {"doc_hash": "b7e9e14237c6e86c02655da707d3bf59723e9b35ff6bd049f34ceacec7ba0a8a", "ref_doc_id": "6b01b50d-f743-464f-8591-ff57ce92874b"}, "583e20fa-797d-4063-9035-2ff6c215a5cb": {"doc_hash": "818b8b2483c7640a64cc890c3ecbce3c4bfb19603aa3c4d61386797fea7098db", "ref_doc_id": "a79f9fad-846d-42a7-a1ed-841576ea7cc7"}, "f2029156-4a07-4dba-b7fa-2ac17095c6f7": {"doc_hash": "3875abc27a03a5d7ae2a4ee10aa04b582a778d6247cac9b13f2cac1794d93fc6", "ref_doc_id": "e3d56383-8ec4-4f60-a1d6-55af0efb02da"}, "2ae03bcc-cfe6-41bc-9cad-1321dce29faf": {"doc_hash": "e4f1c264acc7efff1e525486ea10b7e9082161184690eb1792735fe5a0c5cc80", "ref_doc_id": "51ed9f1a-5cb1-4abe-8a10-6b80c989e0be"}, "81a8ad59-0214-493c-a562-d21ec84f393c": {"doc_hash": "2a0552dc6d49c966dd81929e5cef5f0f4ae0aec90f2c4a3a2e10e5622871a1c2", "ref_doc_id": "c3e48bdd-d448-4c6b-8eb0-9318f858698a"}, "f4f632a4-96cd-4add-a588-5af2bdd9f062": {"doc_hash": "e923e22cdd212700442d4f8f1170c7192275436f6cc29612c7fcd84b86e73857", "ref_doc_id": "4702d470-b5e3-423d-98b4-b8ce9496c83e"}, "352c48a0-8fda-44d2-8de7-781cea9bc56f": {"doc_hash": "0e439b51e2dfc5ee078d08ed6e911eb09380bce4dbfc7340c7caf22464a635ad", "ref_doc_id": "4702d470-b5e3-423d-98b4-b8ce9496c83e"}, "8378ca07-03b3-4bd5-85d2-2c017fc57bd8": {"doc_hash": "f4048867f6b96330ef422e6ecc4b43149453ba59889935adf399455073eb7cbe", "ref_doc_id": "23bfc72b-9aa6-429c-a479-4f297d928fdc"}, "a7a8c658-3b25-45ac-908b-4a4d99608463": {"doc_hash": "646524a19d01b15e4e5576e0f2b75f099a888e256be2c3a718ddb451102bc258", "ref_doc_id": "66cc2062-33de-4764-b8c6-e57609ddd7be"}, "effa620f-ffcb-41e7-9c3c-fd3b4001d9d1": {"doc_hash": "ebd5db53bea756afa0ef6874a601e58ebf43ef4da6ccf48e4545c805e8271b91", "ref_doc_id": "01473aef-6ebb-4465-8de0-bbdef5c0964f"}, "ba2dd8af-7a91-4c38-a6d2-d4f3d5ab4090": {"doc_hash": "ecbece3d2bc1d32a42e8b153c1bd556a358d1930709048e124e27eb21696c294", "ref_doc_id": "7c7fe7f9-a8a9-4aae-9e35-58d2e32568e0"}, "dab8d5be-21c9-4a78-b599-01e15649ab96": {"doc_hash": "5113a29c2d27f4620b5ecc63576c21cba9976f6f9a8f079ed0744a6cd8c57b34", "ref_doc_id": "2a2604b2-0de1-4e80-b035-0bfbba879412"}, "b285176c-bfd4-4d9f-a14e-92f8b102764e": {"doc_hash": "b9360c12045479b39c51bde4786b80ed1d245edd6d4b652e953faaa3db92a79d", "ref_doc_id": "ce8f1b4e-6cc0-4865-9ae3-88b8482ddb4e"}, "1e58e16c-0829-4ef3-812a-b296fff5d56b": {"doc_hash": "705722a968285202d91b53c382dcd2e3b1ff6d6e5a0b7687afc5cb49c3bd67e6", "ref_doc_id": "ce8f1b4e-6cc0-4865-9ae3-88b8482ddb4e"}, "1290e127-c2c0-480b-9a25-9ec9598b3cf0": {"doc_hash": "4a2903a8749d0522c737dd25ef5387ae63b68f959150bf20a57333a8c3dc7921", "ref_doc_id": "ce8f1b4e-6cc0-4865-9ae3-88b8482ddb4e"}, "ba9efcf4-99fd-4857-ac01-9535326e112b": {"doc_hash": "aa5aff7193a28435156eb082df13c23a4245296ab83be289ee9dca2096def04b", "ref_doc_id": "db1c1dd4-e446-4a36-bbeb-6f062184d226"}, "576cae6c-ea8a-438a-97b1-48378a4fa730": {"doc_hash": "11994865421cc5d3d2d62ae3791440aeec43af927efc621591d747707bd167b1", "ref_doc_id": "1935e98d-a918-4965-aa8c-42100ea35d84"}, "e255bed3-abfc-491a-8360-7f037dcd93b0": {"doc_hash": "9ca9648feaccf5f4d2e13e772425321213c7337707ecbf7107f0cbcb8cb46f2a", "ref_doc_id": "a117da46-3a36-43ae-ba92-2cd106769ebb"}, "d7c1ed8d-42ac-466a-88b5-b53ffdf3a1ad": {"doc_hash": "4b9685be83284b007fe784857f6a75ff59f717c5bd9b686e6deeb9a04dcf9532", "ref_doc_id": "a117da46-3a36-43ae-ba92-2cd106769ebb"}, "c48f4f8a-f3fb-469b-8256-4c6c789f28ef": {"doc_hash": "168f303cd75dd5b3ed59e4fbd45f0456d08dece349d7df4d384d35e3491c1f7e", "ref_doc_id": "4abdbf37-7742-4096-afdb-0dac6aef33d3"}, "63157a55-9fe6-4b76-bfdb-dad8893079e3": {"doc_hash": "5b8cb2491651de157f15bc62fdd179ab732139d64879a7eb90f3509e04db2d63", "ref_doc_id": "0ef2a7dd-3795-467d-b5d3-6d04b8b239c9"}, "e89b2379-ba7b-41f8-9105-6b7b0c46745b": {"doc_hash": "81bea59ace8d6ac31098ec9d6e9127f0160e7db99adf1ab06222aa6e0eb2c44a", "ref_doc_id": "a08d3dd5-68ad-4891-b394-d319d909c70c"}, "6a788492-a0a2-4470-8ef2-44554310a889": {"doc_hash": "a21738af2992cbbc5062cf1dc6f014ed26bdae89f006c66b501bfc9338a4e253", "ref_doc_id": "56e75de5-4d2b-4e1b-a4ab-978a1ae93d10"}, "3b2a14f9-d284-42da-ab8d-a7acc0f767dc": {"doc_hash": "a24518732766181539cbba24df02143ef1294b39a621ec71b436cfaa65a45422", "ref_doc_id": "2e8a5bb5-6e7a-45e5-9e14-0972f9d30772"}, "f7764192-f68e-4f6b-9f32-1be6e7fc23b1": {"doc_hash": "c74e86022393aa31593b37aed565920585397625acc9756bb6d23bf2bffce8e9", "ref_doc_id": "959b81b8-ef4f-4389-89e3-027ea2780c94"}, "fc8b4473-afdc-4c68-b503-e5d5fd355710": {"doc_hash": "89e4e290563221a5a82e9f41dc87737953e5baeca4bf0ce36864cfc41c048a04", "ref_doc_id": "959b81b8-ef4f-4389-89e3-027ea2780c94"}, "377808f0-1771-452a-a38a-24ec23b99988": {"doc_hash": "f7a2572d4df197a1a45f4da0e161b4b40dad2bb9b0f4136bd4b266a2d33eb61a", "ref_doc_id": "c5b1e32c-db86-4e4b-9bee-8e859bb390ae"}, "332d7869-5785-40ec-ad68-1d40d369be26": {"doc_hash": "004980a49b6b2e01c7fe1b9f6bedecac26f5711193e73f394a53b1f45fd7447a", "ref_doc_id": "9f263501-0017-4b4f-8785-7a61dddd3e72"}, "5fe08f27-8fcc-4d85-ba32-a009510eb810": {"doc_hash": "b5396b720b55e4818560f821f440bbfb3195c8c87ba8eb917ad613bf58d08565", "ref_doc_id": "9f263501-0017-4b4f-8785-7a61dddd3e72"}, "9dc94475-a6bd-427d-98ae-6f8b8e488e01": {"doc_hash": "36bcb19af5be93d546d3f12c27f5ed2894f5eb88df1aa817f6379f22f5c34c96", "ref_doc_id": "d7bf643d-235d-4a2f-a75b-e873a491dbf7"}, "131049c8-831a-4900-a463-2b9ea6c7cce4": {"doc_hash": "e56fcf20bc9fa2ac105d632139a47ae73f824b81ba48826fca48f715c89fa81d", "ref_doc_id": "d7bf643d-235d-4a2f-a75b-e873a491dbf7"}, "bc971bf8-7112-406c-884d-149e509337b0": {"doc_hash": "b00b085c0d29b4ad736f76506c5ba5282799b75f61088b497a46d4857b5a77a8", "ref_doc_id": "d7bf643d-235d-4a2f-a75b-e873a491dbf7"}, "f9f4c5a0-8a79-404f-b02d-7fdb43490628": {"doc_hash": "c92a1745c58120da4ebcae329502f0f4a638fe41a759d6cecc0f6e1602a9d46d", "ref_doc_id": "d7bf643d-235d-4a2f-a75b-e873a491dbf7"}, "7749f07e-fa8a-4393-9208-7e2017335135": {"doc_hash": "c2fa251d73ddaa39d3b8965e82a3fe9bc0a66bdde8420cfaf6791703e105508d", "ref_doc_id": "d7bf643d-235d-4a2f-a75b-e873a491dbf7"}, "b24154f2-2a02-49cc-bb2f-30d43e44d0b6": {"doc_hash": "c429f36803a39a27263449683417e1164f5b7f8d28d0e55ef9c99638156c30e6", "ref_doc_id": "7c8d4488-eb87-4860-b29b-b5b89fb20648"}, "af68c9d7-b876-4933-94a2-e2f06269304b": {"doc_hash": "d7b61518663ddb183ff55ac61605a2ba70cbd559b8b100128fce786c7a4c3d4e", "ref_doc_id": "602f5530-509c-4fcc-aa3f-c88265be5e34"}, "dc66ab2b-ab0f-496c-9942-aa4e8bde009c": {"doc_hash": "736fb4b140b185e6e07f7aa87ecf3b9375c89aa1c5fb28462e587e70589cc599", "ref_doc_id": "b2d6d84a-5f71-4edf-adfa-9ad02b15c391"}, "f18d7aa4-7b03-4185-9271-50379c7a331a": {"doc_hash": "7ffa0fea7b94e769001ecc297bee84c5785034ae7fad7661149a0883256d6419", "ref_doc_id": "ab8a1d89-290c-442d-bcec-6f85597bcb05"}, "8e83629c-5b77-4256-88fc-51b973dd64ca": {"doc_hash": "f3b3e926a5c811d4d453810bc4a9269d7150e45dd90b9017c0d3caa105e729a8", "ref_doc_id": "e42008b8-f2d0-4f7f-9bef-2726ab6e8774"}, "b332a5ed-e458-4928-890e-0cbd2164efc3": {"doc_hash": "1c45f082b44d86f439f94ee10fe901b0dbef375a792e05de62623bfa5c7f64bf", "ref_doc_id": "a7ed14a0-2fd9-4cfe-b0eb-ef3d8459d285"}, "63cd2d92-dfe7-4b81-9d8f-2a88c4636228": {"doc_hash": "8616bda44a3b5203b70c662899b55d0f5637b4e827bd9ad334defa1feb47d907", "ref_doc_id": "caa94eed-711c-481b-8ef0-1ca1636f6ff5"}, "bb0cc5e0-a490-4853-ac65-4cf35b4810d6": {"doc_hash": "40aef00347bc8d7b2e7961e084d648f96c068e5565de95a90bb0395b9243c0fc", "ref_doc_id": "dc5e4917-dfc6-464f-bd61-4f49fd1aef98"}, "ba274e0a-cb33-4acc-b71f-7243301cdf10": {"doc_hash": "7e549b714802311d329f2dc74e280edbcc279801044c1a68f5c687e4a75d351e", "ref_doc_id": "956a5115-cce5-4de4-9c62-aa6fa3b399d3"}, "8494e05b-2944-486a-8016-3493332c19db": {"doc_hash": "43c2829dce24ddb84161ff3bd10578db2f2d28f15a6fef88bd92c5c75c131a18", "ref_doc_id": "8f62a157-0cf3-4f1f-89a8-79e7c9baab88"}, "64b45a3c-7c71-4332-8eaf-8001094f7c2e": {"doc_hash": "a6262a770638142d2c7054a241e28dd80e1011bf19ef45b08805b2a0d222eb79", "ref_doc_id": "10507fa1-9b3e-423c-a097-6704ad6dbf00"}, "f2f9f571-7f9f-4630-b433-e64566a577e4": {"doc_hash": "605d419887f39eca47fc528d1eb9a712eddb6f1b45416eb087ecd9fa8b824602", "ref_doc_id": "10507fa1-9b3e-423c-a097-6704ad6dbf00"}, "3d949099-99e4-40d5-9993-b40571a91910": {"doc_hash": "2eed583a804d91735cbce141f8c566cc95ea932d560899cd387824b331939675", "ref_doc_id": "51d3239f-b8a4-47d4-bf6a-60311009920a"}, "792dbdcd-b20b-463b-9d84-f672bf7de6b0": {"doc_hash": "8d5202dbfb8671bdcffb2c55ce8cff77a082e7e8fa8b97ea344c0938d39227d6", "ref_doc_id": "95eae29a-cc96-4b4c-8e6e-30b4c6a4ab5d"}, "af50a720-637e-4f2a-af24-086c1d19e15b": {"doc_hash": "7041398afb598f1749bde06db85dfe7a119efe129d76faaf3ba410ae506fa0d8", "ref_doc_id": "95eae29a-cc96-4b4c-8e6e-30b4c6a4ab5d"}, "1fe50337-9315-46f0-a46a-3f31e2d56b28": {"doc_hash": "df9e18dd6fe7b5864551be5523feaea92e6e1fa8fdf862dba70f537c9e47925c", "ref_doc_id": "7b1ec6a5-a75b-47ec-9e66-f73a87b0083e"}, "93765477-4e06-4799-af5e-f6de66fe639a": {"doc_hash": "d3d92219d4d32b239f1d4d3c2cd9b6f83a617dd38eea256cce8103515cd298ae", "ref_doc_id": "c93701a2-a156-450e-a8d1-92e39416a595"}, "4e860305-eff2-4fa6-a0f4-a44c64d4eb2d": {"doc_hash": "902f6fb961ca6cec6f99215327ea4f89ee1bd49cab4ff097d67b966e06ec1ad1", "ref_doc_id": "09ec149a-3e21-409a-8651-57a52d3530ee"}, "b7f36b73-9f56-40ea-8f6d-f324d8d19565": {"doc_hash": "6b8a503ebe88200ad02c1b081a67479c1f780586ca880ff9d59e49c5ae5e026b", "ref_doc_id": "09ec149a-3e21-409a-8651-57a52d3530ee"}, "0e26de10-885c-4310-8460-3a23312ec452": {"doc_hash": "9fc77fcb61f464ac2fe5e15cf67befe48ef94a717af1d04fec146a5f67bdd89e", "ref_doc_id": "09ec149a-3e21-409a-8651-57a52d3530ee"}, "042a2091-7b01-404a-bb08-dbc24b7c8dbe": {"doc_hash": "27cdfc5422f655be1bf695ad4cc58b0306fae9826a09eead2f237d535624aaf2", "ref_doc_id": "60b5ba83-0e9a-4e8d-8502-53cdc5db4df4"}, "ce3f04da-e475-4100-9ea5-63513b6c945a": {"doc_hash": "7502c0baaebc29e765c1528e17f6c468a4a421a3fcb96f4fcfeaf6289b0e4b6a", "ref_doc_id": "b0cbb453-9d7f-48aa-a87c-3b71bb8db6b8"}, "e6c6648a-fd25-492a-9231-27fd07ee7467": {"doc_hash": "e00de30403ff0a6261d9510f8749612848daf89f37ea94656b8b133e5fa0823b", "ref_doc_id": "b0cbb453-9d7f-48aa-a87c-3b71bb8db6b8"}, "e3756285-316d-4169-af73-7cf91b109b87": {"doc_hash": "e68a8eb8dc47c272049afc2af772d7fee3f375755a184860cd0ff44bd8b46cc3", "ref_doc_id": "a9af4860-3709-4426-98e6-a13c1e1d66cd"}, "24b9cb94-0312-42a8-99c1-116027148a56": {"doc_hash": "fe24919bf852b4c5ece2388565f6b21ad95fc662c221e43d96b450dfe58f4c99", "ref_doc_id": "61259ec3-cd95-4e4d-b215-b73e25366f15"}, "83fc7e65-a33b-4a96-8a97-24433ce0cd12": {"doc_hash": "4b029995738e4eeb18f62c49e6839284425342bf0536a261913a35eaafe0f96c", "ref_doc_id": "bfd9ac9a-cc40-43ea-a592-12dcac061a38"}, "fa4799e7-d420-4148-afaf-ef6211988516": {"doc_hash": "4d5f5e0ce88225c57231a7e2e489e02f7437a0c0184dc7ce7d2a8cef2575a672", "ref_doc_id": "888173d7-1fb9-404d-9f59-bea71addb73a"}, "facb9b5c-ee05-4853-b307-0d111ec63245": {"doc_hash": "82d80fbdeb6ac2cb8c393fa9ccc42911118eb6303030028894d58fee993c7489", "ref_doc_id": "3d3248c5-f501-4acb-8c53-1f291fb9328c"}, "0300e3bc-6d7e-406e-a6bd-fb265f1f521f": {"doc_hash": "c20dbb1b7892948fd26e826ab59e7d4fedfc9c51b11ca57cc751d10ca8f550d8", "ref_doc_id": "a4024c57-c722-4f9b-8eda-17ce04be1d15"}, "4315ed6f-6d93-4f56-bfd0-432b1ed6e8ca": {"doc_hash": "5d1d230a5018025cc13e6e103551bd102ec393195e2b51c21312996b0085a605", "ref_doc_id": "a4024c57-c722-4f9b-8eda-17ce04be1d15"}, "13f0c1d0-d581-48eb-85b5-04c291fad720": {"doc_hash": "e179f46a7264e623c41ced5f82c0fce19d6f58cafc194bd2c42dadbab8eb55b0", "ref_doc_id": "f72281f2-9b23-49b2-b048-17227125f7e0"}, "b240fd01-4306-48b1-bf59-0a7139afdea9": {"doc_hash": "ef3448ef9c648f147bfe602fe16bd066c7519e605328e28e2b184f689713a94d", "ref_doc_id": "0bb7f586-e48e-49ba-a87e-f970df9d294f"}, "d4b8ec1d-afcc-4a0f-b3cb-a663c9ba07f3": {"doc_hash": "e0b0c61f9a2dafd7bc2b827f849e9f700d3e4babbff6192b43d9dd502ce6bb6f", "ref_doc_id": "a6af3722-6c3b-441d-ac6c-75944529afe7"}, "0f7496f4-e9cf-46d1-8666-84664a886a79": {"doc_hash": "c2b99149d51a7346b8ef2c81223955c55c096fdb2418abed23a9b45e1dc682c0", "ref_doc_id": "d885c313-e146-4f85-b967-2c7c5d088fef"}}}